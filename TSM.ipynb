{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6a92ba86a8b4369a0b75215a7ff65f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60809f0c1ce2489cad27958981d6014a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17d9dec2d7ac42cdbd9ad9c67ff7ee98",
              "IPY_MODEL_f3a6ec373eb7454ba0861fd4ea572605"
            ]
          }
        },
        "60809f0c1ce2489cad27958981d6014a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17d9dec2d7ac42cdbd9ad9c67ff7ee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f729b38e31940f686a95823ce29d9a0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 45322792,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 45322792,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1098d3eb2d394554b27a73451b3962f6"
          }
        },
        "f3a6ec373eb7454ba0861fd4ea572605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f43cd04db0144679877eb113674dd997",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 43.2M/43.2M [00:00&lt;00:00, 46.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e6ffe16b4ba4d05925dfc5c1751716b"
          }
        },
        "5f729b38e31940f686a95823ce29d9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1098d3eb2d394554b27a73451b3962f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f43cd04db0144679877eb113674dd997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e6ffe16b4ba4d05925dfc5c1751716b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "863b7aeef88f4213b4ae67f0ba1a5c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd35866ca0fd4885b7c484cd1a08e90c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_610edb787f8d4bde9e5c28bb19a12165",
              "IPY_MODEL_4429f56faa1c4f0a85746f49e3083cc2"
            ]
          }
        },
        "cd35866ca0fd4885b7c484cd1a08e90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "610edb787f8d4bde9e5c28bb19a12165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d79d39501b054f008cc3f8ad2e898468",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14196051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14196051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b72132e1a404409b49624dc84f00130"
          }
        },
        "4429f56faa1c4f0a85746f49e3083cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84bdb83f0d1b436a8216a7c54dddcb45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13.5M/13.5M [00:06&lt;00:00, 2.12MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc0a1b0a233d4f6397607eb58cb16add"
          }
        },
        "d79d39501b054f008cc3f8ad2e898468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b72132e1a404409b49624dc84f00130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84bdb83f0d1b436a8216a7c54dddcb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc0a1b0a233d4f6397607eb58cb16add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qo9u30Nk_b_",
        "outputId": "c5c5b29c-b483-4876-9abd-465de9e42723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s1uH6yqlb2d"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Samsung')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFROpwJC1YZO",
        "outputId": "4aa7d968-713d-497e-80ba-80614e521f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frames\tlabels\ttestdata  test_frames  traindata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGhS7SKql1pc",
        "outputId": "62fdf736-4fde-49e6-ff40-028fb077c8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from multiprocessing import Pool\n",
        "from tqdm import tqdm\n",
        "\n",
        "n_thread = 100\n",
        "\n",
        "\n",
        "def vid2jpg(file_name, class_path, dst_class_path):\n",
        "    if '.mp4' not in file_name:\n",
        "        return\n",
        "    name, ext = os.path.splitext(file_name)\n",
        "    dst_directory_path = os.path.join(dst_class_path, name)\n",
        "\n",
        "    video_file_path = os.path.join(class_path, file_name)\n",
        "    try:\n",
        "        if os.path.exists(dst_directory_path):\n",
        "            if not os.path.exists(os.path.join(dst_directory_path, 'img_00001.jpg')):\n",
        "                subprocess.call('rm -r \\\"{}\\\"'.format(dst_directory_path), shell=True)\n",
        "                print('remove {}'.format(dst_directory_path))\n",
        "                os.mkdir(dst_directory_path)\n",
        "            else:\n",
        "                print('*** convert has been done: {}'.format(dst_directory_path))\n",
        "                return\n",
        "        else:\n",
        "            os.mkdir(dst_directory_path)\n",
        "    except:\n",
        "        print(dst_directory_path)\n",
        "        return\n",
        "    cmd = 'ffmpeg -i \\\"{}\\\" -threads 1 -vf scale=-1:331 -q:v 0 \\\"{}/img_%05d.jpg\\\"'.format(video_file_path, dst_directory_path)\n",
        "    # print(cmd)\n",
        "    subprocess.call(cmd, shell=True,\n",
        "                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "\n",
        "def class_process(dir_path, dst_dir_path, class_name):\n",
        "    print('*' * 20, class_name, '*'*20)\n",
        "    class_path = os.path.join(dir_path, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        print('*** is not a dir {}'.format(class_path))\n",
        "        return\n",
        "\n",
        "    dst_class_path = os.path.join(dst_dir_path, class_name)\n",
        "    if not os.path.exists(dst_class_path):\n",
        "        os.mkdir(dst_class_path)\n",
        "\n",
        "    vid_list = os.listdir(class_path)\n",
        "    vid_list.sort()\n",
        "    p = Pool(n_thread)\n",
        "    from functools import partial\n",
        "    worker = partial(vid2jpg, class_path=class_path, dst_class_path=dst_class_path)\n",
        "    for _ in tqdm(p.imap_unordered(worker, vid_list), total=len(vid_list)):\n",
        "        pass\n",
        "    # p.map(worker, vid_list)\n",
        "    p.close()\n",
        "    p.join()\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dir_path = \"/content/drive/My Drive/Samsung/traindata/\"\n",
        "    dst_dir_path = \"/content/drive/My Drive/Samsung/frames/\"\n",
        "\n",
        "    class_list = os.listdir(dir_path)\n",
        "    class_list.sort()\n",
        "    for class_name in class_list:\n",
        "        class_process(dir_path, dst_dir_path, class_name)\n",
        "\n",
        "    #class_name = 'test'\n",
        "    #class_process(dir_path, dst_dir_path, class_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************** blowing_candles ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/310 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/310 [00:05<27:12,  5.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/164\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/169\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 4/310 [00:05<18:55,  3.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 5/310 [00:05<13:28,  2.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/176\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 7/310 [00:05<09:32,  1.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/110\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/123\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 10/310 [00:06<06:45,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/141\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/186\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 13/310 [00:06<04:44,  1.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/118\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 15/310 [00:06<03:24,  1.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/147\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 17/310 [00:06<02:27,  1.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/162\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 19/310 [00:06<01:50,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/111\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/178\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 22/310 [00:06<01:20,  3.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/114\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 24/310 [00:07<01:09,  4.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/166\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/105\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 27/310 [00:07<00:56,  5.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/152\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/127\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 30/310 [00:07<00:42,  6.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/104\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 32/310 [00:07<00:36,  7.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/120\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/112\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 35/310 [00:07<00:31,  8.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/187\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/113\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 38/310 [00:08<00:31,  8.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/109\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 40/310 [00:08<00:31,  8.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/134\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 42/310 [00:08<00:27,  9.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/124\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 44/310 [00:08<00:27,  9.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/145\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 46/310 [00:09<00:29,  9.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/149\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/119\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 49/310 [00:09<00:28,  9.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/126\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/131\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/167\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 53/310 [00:09<00:25, 10.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/107\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/18\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 56/310 [00:10<00:24, 10.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/10\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/191\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 59/310 [00:10<00:24, 10.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/177\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/180\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 62/310 [00:10<00:24, 10.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/181\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/130\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 65/310 [00:10<00:25,  9.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/170\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 67/310 [00:11<00:27,  8.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/148\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/115\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 70/310 [00:11<00:26,  8.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/161\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 72/310 [00:11<00:28,  8.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/143\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/146\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 75/310 [00:12<00:27,  8.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/138\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 77/310 [00:12<00:32,  7.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/128\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 79/310 [00:12<00:35,  6.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/150\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/153\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 82/310 [00:13<00:34,  6.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/172\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 84/310 [00:13<00:36,  6.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/192\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/108\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 87/310 [00:14<00:34,  6.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/19\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 89/310 [00:14<00:34,  6.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/155\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 91/310 [00:14<00:36,  5.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/160\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 93/310 [00:15<00:38,  5.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/15\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 95/310 [00:15<00:39,  5.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/194\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 97/310 [00:16<00:39,  5.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/16\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 99/310 [00:16<00:40,  5.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/165\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 101/310 [00:16<00:40,  5.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/122\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 103/310 [00:17<00:40,  5.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/208\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/205\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 106/310 [00:17<00:36,  5.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/197\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 108/310 [00:17<00:33,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/210\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/21\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 111/310 [00:18<00:31,  6.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/200\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 113/310 [00:18<00:30,  6.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/17\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 115/310 [00:19<00:32,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/212\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/213\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 118/310 [00:19<00:30,  6.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/201\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▊      | 120/310 [00:19<00:32,  5.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/216\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 122/310 [00:20<00:33,  5.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/11\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 124/310 [00:20<00:34,  5.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/218\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 126/310 [00:21<00:35,  5.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/204\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 128/310 [00:21<00:35,  5.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/214\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 130/310 [00:21<00:32,  5.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/220\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 132/310 [00:22<00:33,  5.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/2\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 134/310 [00:22<00:35,  4.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/226\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/225\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 137/310 [00:23<00:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/228\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 139/310 [00:23<00:31,  5.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/222\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 141/310 [00:23<00:34,  4.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/230\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 143/310 [00:24<00:31,  5.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/232\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 145/310 [00:24<00:31,  5.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/233\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 147/310 [00:25<00:34,  4.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/235\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 149/310 [00:25<00:30,  5.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 150/310 [00:25<00:45,  3.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/237\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/238\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 153/310 [00:26<00:37,  4.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/240\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 155/310 [00:26<00:33,  4.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/243\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 157/310 [00:27<00:32,  4.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/244\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 159/310 [00:27<00:28,  5.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 160/310 [00:27<00:42,  3.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/242\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 162/310 [00:28<00:37,  3.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/250\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 164/310 [00:28<00:34,  4.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/251\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 166/310 [00:29<00:34,  4.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/252\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 168/310 [00:29<00:30,  4.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/254\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 170/310 [00:29<00:31,  4.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/255\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 172/310 [00:30<00:28,  4.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/259\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 174/310 [00:30<00:29,  4.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/257\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 176/310 [00:31<00:30,  4.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/261\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 178/310 [00:31<00:30,  4.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/262\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 180/310 [00:32<00:34,  3.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 181/310 [00:32<00:40,  3.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/26\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 183/310 [00:33<00:38,  3.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 184/310 [00:33<00:40,  3.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/269\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 186/310 [00:34<00:35,  3.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/271\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 188/310 [00:34<00:33,  3.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/272\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████▏   | 190/310 [00:35<00:32,  3.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/273\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 192/310 [00:35<00:31,  3.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/276\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 194/310 [00:36<00:29,  3.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/278\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 196/310 [00:36<00:29,  3.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/280\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 198/310 [00:37<00:26,  4.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/282\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 200/310 [00:37<00:26,  4.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/283\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 202/310 [00:38<00:26,  4.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/285\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 204/310 [00:38<00:25,  4.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/287\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 206/310 [00:39<00:25,  4.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/288\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 208/310 [00:39<00:25,  4.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/97\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/98\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/99\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/290\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▊   | 213/310 [00:40<00:19,  4.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/291\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 215/310 [00:40<00:20,  4.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/268\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 217/310 [00:40<00:19,  4.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/293\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 219/310 [00:41<00:20,  4.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/292\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 221/310 [00:41<00:20,  4.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/295\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 223/310 [00:42<00:20,  4.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/299\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 225/310 [00:42<00:20,  4.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/300\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 227/310 [00:43<00:20,  4.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/30\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 229/310 [00:43<00:20,  4.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 230/310 [00:44<00:22,  3.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/33\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 232/310 [00:44<00:21,  3.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/349\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 234/310 [00:45<00:20,  3.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/96\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 236/310 [00:45<00:19,  3.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 237/310 [00:46<00:25,  2.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/35\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 239/310 [00:46<00:23,  3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 240/310 [00:47<00:24,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/390\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 242/310 [00:47<00:22,  3.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/42\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 244/310 [00:48<00:20,  3.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/40\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 246/310 [00:48<00:18,  3.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 247/310 [00:49<00:23,  2.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/457\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 249/310 [00:50<00:20,  2.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/47\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 251/310 [00:50<00:20,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/95\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 253/310 [00:51<00:17,  3.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/482\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 255/310 [00:51<00:17,  3.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/478\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 257/310 [00:52<00:14,  3.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 258/310 [00:52<00:19,  2.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▎ | 259/310 [00:53<00:20,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/490\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 261/310 [00:54<00:19,  2.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/51\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 263/310 [00:54<00:17,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 264/310 [00:55<00:18,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 265/310 [00:55<00:21,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/54\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 267/310 [00:56<00:17,  2.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▋ | 268/310 [00:56<00:19,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/57\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 270/310 [00:57<00:16,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 271/310 [00:58<00:17,  2.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/60\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 273/310 [00:58<00:15,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/61\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▊ | 275/310 [00:59<00:12,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/62\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 277/310 [00:59<00:11,  2.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/67\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 279/310 [01:00<00:09,  3.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 280/310 [01:00<00:11,  2.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/69\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 282/310 [01:01<00:10,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/68\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/71\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 284/310 [01:01<00:08,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/70\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 286/310 [01:02<00:08,  2.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 287/310 [01:03<00:09,  2.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 288/310 [01:03<00:08,  2.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/76\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▎| 290/310 [01:04<00:07,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/74\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 292/310 [01:04<00:06,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▍| 293/310 [01:05<00:07,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/77\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/79\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 295/310 [01:05<00:05,  2.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 296/310 [01:06<00:06,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/81\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 298/310 [01:07<00:04,  2.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/82\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▋| 299/310 [01:07<00:05,  2.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/85\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 301/310 [01:08<00:03,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 302/310 [01:08<00:03,  2.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/89\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 304/310 [01:09<00:02,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 305/310 [01:09<00:02,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/90\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 307/310 [01:10<00:01,  2.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 308/310 [01:11<00:00,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 309/310 [01:11<00:00,  1.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/blowing_candles/92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 310/310 [01:12<00:00,  4.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "******************** cake_cutting ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/309 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/309 [00:04<22:46,  4.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/309 [00:04<16:43,  3.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/301\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 4/309 [00:05<12:01,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/304\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 6/309 [00:05<08:43,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/310\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 8/309 [00:06<06:31,  1.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/330\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 10/309 [00:07<04:59,  1.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/322\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 12/309 [00:07<03:54,  1.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/314\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/375\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 15/309 [00:08<02:57,  1.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 16/309 [00:08<02:36,  1.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/320\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 18/309 [00:09<02:15,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/329\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 20/309 [00:09<02:00,  2.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/319\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 22/309 [00:10<01:49,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/369\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 24/309 [00:10<01:37,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/370\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/374\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 27/309 [00:11<01:22,  3.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 28/309 [00:11<01:29,  3.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/354\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 30/309 [00:12<01:23,  3.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/325\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 32/309 [00:12<01:22,  3.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/380\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 34/309 [00:13<01:17,  3.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/353\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 36/309 [00:13<01:14,  3.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/303\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 38/309 [00:14<01:16,  3.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/359\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 40/309 [00:15<01:17,  3.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/331\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 42/309 [00:15<01:21,  3.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 43/309 [00:16<01:44,  2.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/363\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 45/309 [00:16<01:32,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/352\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 47/309 [00:17<01:24,  3.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/360\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 49/309 [00:18<01:21,  3.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/358\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 51/309 [00:18<01:20,  3.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/389\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 53/309 [00:19<01:18,  3.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/349\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 55/309 [00:19<01:17,  3.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/356\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/372\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 58/309 [00:20<01:06,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/385\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 60/309 [00:20<01:07,  3.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/373\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 62/309 [00:21<01:05,  3.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/348\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 64/309 [00:21<01:04,  3.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/383\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 66/309 [00:22<01:02,  3.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/397\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 68/309 [00:23<01:05,  3.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/346\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 70/309 [00:23<01:07,  3.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/347\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 72/309 [00:24<01:04,  3.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/365\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 74/309 [00:24<01:05,  3.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/367\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 76/309 [00:25<01:06,  3.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/336\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 78/309 [00:25<01:07,  3.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/393\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 80/309 [00:26<01:06,  3.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/337\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 82/309 [00:27<01:07,  3.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/334\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 84/309 [00:27<01:06,  3.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/338\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 86/309 [00:28<01:06,  3.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/401\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 88/309 [00:29<01:07,  3.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 89/309 [00:29<01:23,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/402\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 91/309 [00:30<01:14,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 92/309 [00:30<01:24,  2.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 93/309 [00:31<01:37,  2.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/404\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 95/309 [00:31<01:30,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/343\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 97/309 [00:32<01:18,  2.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/341\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 99/309 [00:32<01:13,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/364\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 101/309 [00:33<01:09,  3.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/392\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 103/309 [00:34<01:06,  3.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/335\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 105/309 [00:34<01:07,  3.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/409\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 107/309 [00:35<01:05,  3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 108/309 [00:36<01:26,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/411\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 110/309 [00:36<01:18,  2.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 111/309 [00:37<01:35,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/376\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 113/309 [00:38<01:24,  2.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 114/309 [00:40<03:03,  1.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/416\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 116/309 [00:40<02:23,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 117/309 [00:41<02:08,  1.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 118/309 [00:41<02:03,  1.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▊      | 119/309 [00:42<01:54,  1.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 120/309 [00:43<01:57,  1.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/421\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 122/309 [00:43<01:39,  1.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 123/309 [00:44<01:40,  1.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/425\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 125/309 [00:44<01:24,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 126/309 [00:45<01:30,  2.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/427\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 128/309 [00:46<01:21,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/429\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 130/309 [00:46<01:15,  2.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/432\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 132/309 [00:47<01:07,  2.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/434\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 134/309 [00:47<01:02,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/435\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 136/309 [00:48<00:59,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/438\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 138/309 [00:49<00:56,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/439\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 140/309 [00:49<00:51,  3.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 141/309 [00:50<01:12,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/443\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 143/309 [00:51<01:05,  2.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 144/309 [00:51<01:18,  2.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/445\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 146/309 [00:52<01:06,  2.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 147/309 [00:52<01:04,  2.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/446\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 149/309 [00:53<01:00,  2.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▊     | 150/309 [00:53<01:04,  2.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/451\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 152/309 [00:54<00:58,  2.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 153/309 [00:54<01:08,  2.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/453\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 155/309 [00:55<01:01,  2.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/454\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 157/309 [00:56<00:55,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/457\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 159/309 [00:56<00:54,  2.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/459\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 161/309 [00:57<00:53,  2.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/460\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 163/309 [00:58<00:49,  2.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/462\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 165/309 [00:58<00:36,  3.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 166/309 [00:58<00:47,  3.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 167/309 [00:59<00:53,  2.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/465\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 169/309 [00:59<00:49,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/468\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 171/309 [01:00<00:46,  2.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/469\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 173/309 [01:00<00:44,  3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/472\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/476\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 176/309 [01:01<00:37,  3.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 177/309 [01:01<00:40,  3.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/475\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/480\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 180/309 [01:02<00:33,  3.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 181/309 [01:02<00:41,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/479\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 183/309 [01:03<00:40,  3.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/482\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 185/309 [01:03<00:38,  3.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/484\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 187/309 [01:04<00:39,  3.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/486\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 189/309 [01:05<00:39,  3.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/488\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 191/309 [01:05<00:37,  3.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 192/309 [01:06<00:44,  2.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 193/309 [01:07<00:50,  2.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/493\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 195/309 [01:07<00:47,  2.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/494\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 197/309 [01:08<00:44,  2.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/496\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 199/309 [01:09<00:41,  2.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/498\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 201/309 [01:09<00:38,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/500\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 203/309 [01:10<00:35,  2.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/502\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 205/309 [01:11<00:35,  2.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/504\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/68\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 208/309 [01:11<00:31,  3.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/91\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/96\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/506\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▊   | 212/309 [01:12<00:26,  3.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/509\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 214/309 [01:13<00:26,  3.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/510\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 216/309 [01:13<00:26,  3.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/511\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 218/309 [01:14<00:27,  3.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/514\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 220/309 [01:15<00:28,  3.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/516\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 222/309 [01:15<00:28,  3.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/518\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 224/309 [01:17<00:41,  2.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 225/309 [01:18<00:45,  1.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/521\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 227/309 [01:18<00:39,  2.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/523\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 229/309 [01:19<00:34,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/526\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 231/309 [01:20<00:30,  2.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/527\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 233/309 [01:20<00:28,  2.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/529\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 235/309 [01:21<00:27,  2.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/530\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 237/309 [01:22<00:26,  2.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/533\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 239/309 [01:22<00:25,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/536\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 241/309 [01:23<00:23,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/535\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▊  | 243/309 [01:24<00:22,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/600\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 245/309 [01:24<00:21,  3.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/540\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 247/309 [01:25<00:20,  2.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/538\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 249/309 [01:26<00:20,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/544\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 251/309 [01:26<00:19,  2.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/546\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 253/309 [01:27<00:16,  3.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 254/309 [01:27<00:19,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/549\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 256/309 [01:28<00:18,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/551\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 258/309 [01:29<00:18,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/552\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 260/309 [01:29<00:17,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/554\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▍ | 262/309 [01:31<00:21,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 263/309 [01:31<00:24,  1.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/559\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 265/309 [01:32<00:20,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/558\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▋ | 267/309 [01:33<00:18,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/563\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 269/309 [01:33<00:15,  2.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 270/309 [01:34<00:18,  2.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 271/309 [01:35<00:19,  1.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/566\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 273/309 [01:35<00:16,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▊ | 274/309 [01:36<00:18,  1.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/570\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 276/309 [01:37<00:15,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 277/309 [01:37<00:16,  1.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/572\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 279/309 [01:38<00:13,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 280/309 [01:38<00:13,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/543\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 282/309 [01:39<00:11,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 283/309 [01:40<00:12,  2.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/576\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 285/309 [01:40<00:10,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 286/309 [01:41<00:10,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 287/309 [01:41<00:10,  2.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/580\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▎| 289/309 [01:42<00:08,  2.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 290/309 [01:43<00:09,  2.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 291/309 [01:43<00:09,  1.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 292/309 [01:44<00:09,  1.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/577\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 294/309 [01:45<00:07,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/599\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 296/309 [01:45<00:05,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/588\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▋| 298/309 [01:46<00:04,  2.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/590\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 300/309 [01:46<00:03,  2.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/593\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 302/309 [01:47<00:02,  2.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/595\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 304/309 [01:47<00:01,  3.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/597\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 306/309 [01:48<00:00,  3.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/cake_cutting/598\n",
            "remove /content/drive/My Drive/Samsung/frames/cake_cutting/311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 308/309 [03:26<00:14, 14.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "remove /content/drive/My Drive/Samsung/frames/cake_cutting/79\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 309/309 [05:16<00:00,  1.02s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "******************** hugging ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/216 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/216 [00:02<08:49,  2.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/216 [00:03<06:51,  1.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/254\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/216 [00:03<05:08,  1.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/235\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/611\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 7/216 [00:04<03:49,  1.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/612 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/216 [00:05<03:04,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/689\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 11/216 [00:06<02:29,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 12/216 [00:06<02:26,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/247\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 14/216 [00:07<02:08,  1.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/619\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 16/216 [00:08<01:55,  1.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/627\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 18/216 [00:09<01:47,  1.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/609\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 20/216 [00:10<01:37,  2.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/616\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/605 (1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 22/216 [00:11<01:33,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 23/216 [00:11<01:39,  1.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/663\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 25/216 [00:12<01:32,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/641\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 27/216 [00:13<01:29,  2.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/608\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 29/216 [00:14<01:30,  2.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 30/216 [00:15<01:40,  1.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 31/216 [00:15<01:38,  1.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/676\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 33/216 [00:16<01:30,  2.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/661\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 35/216 [00:17<01:24,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/640\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 37/216 [00:18<01:16,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 38/216 [00:18<01:31,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/643 (1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 39/216 [00:19<01:29,  1.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/664\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 41/216 [00:20<01:26,  2.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 42/216 [00:20<01:30,  1.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/694\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/693\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 45/216 [00:21<01:14,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/667\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 47/216 [00:22<01:11,  2.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 48/216 [00:22<01:13,  2.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/618\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 50/216 [00:23<01:06,  2.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/686\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 52/216 [00:24<01:03,  2.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 53/216 [00:24<01:08,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/695\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 55/216 [00:25<01:01,  2.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/698 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 57/216 [00:25<00:57,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/633\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 59/216 [00:26<00:55,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/697\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 61/216 [00:26<00:50,  3.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/657\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 63/216 [00:27<00:48,  3.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/658\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 65/216 [00:28<00:51,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/692\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 67/216 [00:29<00:51,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/629\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 69/216 [00:29<00:53,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/650\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/657 (1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 71/216 [00:30<00:54,  2.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/672\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 73/216 [00:31<00:54,  2.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/617\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 75/216 [00:32<00:56,  2.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 76/216 [00:32<01:03,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/675\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 78/216 [00:33<01:02,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/624\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 80/216 [00:34<00:59,  2.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/636\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 82/216 [00:35<00:57,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/634\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 84/216 [00:36<00:53,  2.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/666\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 86/216 [00:37<00:54,  2.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/647\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 88/216 [00:37<00:52,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/673\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 90/216 [00:38<00:53,  2.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/653\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 92/216 [00:39<00:53,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/648\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 94/216 [00:40<00:49,  2.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/679\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 96/216 [00:41<00:50,  2.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/638\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 98/216 [00:42<00:50,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/630\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/699\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 101/216 [00:43<00:44,  2.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/700\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 103/216 [00:43<00:39,  2.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/652\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▊     | 105/216 [00:44<00:42,  2.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/688\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 107/216 [00:45<00:43,  2.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/678 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 109/216 [00:46<00:46,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/682\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████▏    | 111/216 [00:47<00:47,  2.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/701\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/702\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/698\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/704\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 116/216 [00:47<00:34,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/705\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/706\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/707\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/708\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 121/216 [00:49<00:32,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/710\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/712 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/712\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/713\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/711\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 127/216 [00:49<00:22,  3.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/715\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/718\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/717\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 131/216 [00:50<00:19,  4.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/719\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/720\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/722\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/721\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/723\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/724 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/725\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/724\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 140/216 [00:50<00:12,  6.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/729\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/727\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/728\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 144/216 [00:50<00:10,  7.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/730\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/732\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/734\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/738\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/737\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/742 (1)\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 150/216 [00:51<00:06,  9.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/744\n",
            "*** convert has been done: /content/drive/My Drive/Samsung/frames/hugging/745\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/758\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/757\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/716\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/756\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/733\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/735\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/739\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/740\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/736\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/741\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/743\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/748\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/750\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/746\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/747\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/749\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/751\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/753\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/755\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/752\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/754\n",
            "remove /content/drive/My Drive/Samsung/frames/hugging/759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 216/216 [03:52<00:00,  1.08s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "******************** laughing ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 308/308 [13:55<00:00,  2.71s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "******************** screaming ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [16:00<00:00,  3.05s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpKNwLuHRE6S",
        "outputId": "d935c327-bffd-4873-ff4b-a934124fb4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "arr=os.listdir('./frames/screaming/')\n",
        "print(len(arr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KjW64c9iAFn",
        "outputId": "7355a5ef-0891-471c-ffe3-3bf0f42da44f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/Samsung/frames/'\n",
        "label_path = '/content/drive/My Drive/Samsung/labels'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    categories=['cake_cutting','blowing_candles','hugging','laughing','screaming']\n",
        "    assert len(set(categories)) == 5\n",
        "    dict_categories = {}\n",
        "    for i, category in enumerate(categories):\n",
        "        dict_categories[category] = i\n",
        "\n",
        "    print(dict_categories)\n",
        "\n",
        "    files_input = ['train.csv','validation.csv']\n",
        "    files_output = ['train_videofolder.txt','val_videofolder.txt']\n",
        "    for (filename_input, filename_output) in zip(files_input, files_output):\n",
        "        count_cat = {k: 0 for k in dict_categories.keys()}\n",
        "        with open(os.path.join(label_path, filename_input)) as f:\n",
        "            lines = f.readlines()\n",
        "        folders = []\n",
        "        idx_categories = []\n",
        "        categories_list = []\n",
        "        for line in lines:\n",
        "            line = line.rstrip()\n",
        "            items = line.split(',')\n",
        "            folders.append(items[0].split('.')[0])\n",
        "            this_catergory = items[1]\n",
        "            categories_list.append(this_catergory)\n",
        "            idx_categories.append(dict_categories[this_catergory])\n",
        "            count_cat[this_catergory] += 1\n",
        "        print(max(count_cat.values()))\n",
        "\n",
        "        assert len(idx_categories) == len(folders)\n",
        "        missing_folders = []\n",
        "        output = []\n",
        "        for i in range(len(folders)):\n",
        "            curFolder = folders[i]\n",
        "            curIDX = idx_categories[i]\n",
        "            # counting the number of frames in each video folders\n",
        "            img_dir = os.path.join(dataset_path, categories_list[i], curFolder)\n",
        "            if not os.path.exists(img_dir):\n",
        "                missing_folders.append(img_dir)\n",
        "                # print(missing_folders)\n",
        "            else:\n",
        "                dir_files = os.listdir(img_dir)\n",
        "                output.append('%s %d %d'%(os.path.join(categories_list[i], curFolder), len(dir_files), curIDX))\n",
        "            print('%d/%d, missing %d'%(i, len(folders), len(missing_folders)))\n",
        "        with open(os.path.join(label_path, filename_output),'w') as f:\n",
        "            f.write('\\n'.join(output))\n",
        "        with open(os.path.join(label_path, 'missing_' + filename_output),'w') as f:\n",
        "            f.write('\\n'.join(missing_folders))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'cake_cutting': 0, 'blowing_candles': 1, 'hugging': 2, 'laughing': 3, 'screaming': 4}\n",
            "300\n",
            "0/1400, missing 0\n",
            "1/1400, missing 0\n",
            "2/1400, missing 0\n",
            "3/1400, missing 0\n",
            "4/1400, missing 0\n",
            "5/1400, missing 0\n",
            "6/1400, missing 0\n",
            "7/1400, missing 0\n",
            "8/1400, missing 0\n",
            "9/1400, missing 0\n",
            "10/1400, missing 0\n",
            "11/1400, missing 0\n",
            "12/1400, missing 0\n",
            "13/1400, missing 0\n",
            "14/1400, missing 0\n",
            "15/1400, missing 0\n",
            "16/1400, missing 0\n",
            "17/1400, missing 0\n",
            "18/1400, missing 0\n",
            "19/1400, missing 0\n",
            "20/1400, missing 0\n",
            "21/1400, missing 0\n",
            "22/1400, missing 0\n",
            "23/1400, missing 0\n",
            "24/1400, missing 0\n",
            "25/1400, missing 0\n",
            "26/1400, missing 0\n",
            "27/1400, missing 0\n",
            "28/1400, missing 0\n",
            "29/1400, missing 0\n",
            "30/1400, missing 0\n",
            "31/1400, missing 0\n",
            "32/1400, missing 0\n",
            "33/1400, missing 0\n",
            "34/1400, missing 0\n",
            "35/1400, missing 0\n",
            "36/1400, missing 0\n",
            "37/1400, missing 0\n",
            "38/1400, missing 0\n",
            "39/1400, missing 0\n",
            "40/1400, missing 0\n",
            "41/1400, missing 0\n",
            "42/1400, missing 0\n",
            "43/1400, missing 0\n",
            "44/1400, missing 0\n",
            "45/1400, missing 0\n",
            "46/1400, missing 0\n",
            "47/1400, missing 0\n",
            "48/1400, missing 0\n",
            "49/1400, missing 0\n",
            "50/1400, missing 0\n",
            "51/1400, missing 0\n",
            "52/1400, missing 0\n",
            "53/1400, missing 0\n",
            "54/1400, missing 0\n",
            "55/1400, missing 0\n",
            "56/1400, missing 0\n",
            "57/1400, missing 0\n",
            "58/1400, missing 0\n",
            "59/1400, missing 0\n",
            "60/1400, missing 0\n",
            "61/1400, missing 0\n",
            "62/1400, missing 0\n",
            "63/1400, missing 0\n",
            "64/1400, missing 0\n",
            "65/1400, missing 0\n",
            "66/1400, missing 0\n",
            "67/1400, missing 0\n",
            "68/1400, missing 0\n",
            "69/1400, missing 0\n",
            "70/1400, missing 0\n",
            "71/1400, missing 0\n",
            "72/1400, missing 0\n",
            "73/1400, missing 0\n",
            "74/1400, missing 0\n",
            "75/1400, missing 0\n",
            "76/1400, missing 0\n",
            "77/1400, missing 0\n",
            "78/1400, missing 0\n",
            "79/1400, missing 0\n",
            "80/1400, missing 0\n",
            "81/1400, missing 0\n",
            "82/1400, missing 0\n",
            "83/1400, missing 0\n",
            "84/1400, missing 0\n",
            "85/1400, missing 0\n",
            "86/1400, missing 0\n",
            "87/1400, missing 0\n",
            "88/1400, missing 0\n",
            "89/1400, missing 0\n",
            "90/1400, missing 0\n",
            "91/1400, missing 0\n",
            "92/1400, missing 0\n",
            "93/1400, missing 0\n",
            "94/1400, missing 0\n",
            "95/1400, missing 0\n",
            "96/1400, missing 0\n",
            "97/1400, missing 0\n",
            "98/1400, missing 0\n",
            "99/1400, missing 0\n",
            "100/1400, missing 0\n",
            "101/1400, missing 0\n",
            "102/1400, missing 0\n",
            "103/1400, missing 0\n",
            "104/1400, missing 0\n",
            "105/1400, missing 0\n",
            "106/1400, missing 0\n",
            "107/1400, missing 0\n",
            "108/1400, missing 0\n",
            "109/1400, missing 0\n",
            "110/1400, missing 0\n",
            "111/1400, missing 0\n",
            "112/1400, missing 0\n",
            "113/1400, missing 0\n",
            "114/1400, missing 0\n",
            "115/1400, missing 0\n",
            "116/1400, missing 0\n",
            "117/1400, missing 0\n",
            "118/1400, missing 0\n",
            "119/1400, missing 0\n",
            "120/1400, missing 0\n",
            "121/1400, missing 0\n",
            "122/1400, missing 0\n",
            "123/1400, missing 0\n",
            "124/1400, missing 0\n",
            "125/1400, missing 0\n",
            "126/1400, missing 0\n",
            "127/1400, missing 0\n",
            "128/1400, missing 0\n",
            "129/1400, missing 0\n",
            "130/1400, missing 0\n",
            "131/1400, missing 0\n",
            "132/1400, missing 0\n",
            "133/1400, missing 0\n",
            "134/1400, missing 0\n",
            "135/1400, missing 0\n",
            "136/1400, missing 0\n",
            "137/1400, missing 0\n",
            "138/1400, missing 0\n",
            "139/1400, missing 0\n",
            "140/1400, missing 0\n",
            "141/1400, missing 0\n",
            "142/1400, missing 0\n",
            "143/1400, missing 0\n",
            "144/1400, missing 0\n",
            "145/1400, missing 0\n",
            "146/1400, missing 0\n",
            "147/1400, missing 0\n",
            "148/1400, missing 0\n",
            "149/1400, missing 0\n",
            "150/1400, missing 0\n",
            "151/1400, missing 0\n",
            "152/1400, missing 0\n",
            "153/1400, missing 0\n",
            "154/1400, missing 0\n",
            "155/1400, missing 0\n",
            "156/1400, missing 0\n",
            "157/1400, missing 0\n",
            "158/1400, missing 0\n",
            "159/1400, missing 0\n",
            "160/1400, missing 0\n",
            "161/1400, missing 0\n",
            "162/1400, missing 0\n",
            "163/1400, missing 0\n",
            "164/1400, missing 0\n",
            "165/1400, missing 0\n",
            "166/1400, missing 0\n",
            "167/1400, missing 0\n",
            "168/1400, missing 0\n",
            "169/1400, missing 0\n",
            "170/1400, missing 0\n",
            "171/1400, missing 0\n",
            "172/1400, missing 0\n",
            "173/1400, missing 0\n",
            "174/1400, missing 0\n",
            "175/1400, missing 0\n",
            "176/1400, missing 0\n",
            "177/1400, missing 0\n",
            "178/1400, missing 0\n",
            "179/1400, missing 0\n",
            "180/1400, missing 0\n",
            "181/1400, missing 0\n",
            "182/1400, missing 0\n",
            "183/1400, missing 0\n",
            "184/1400, missing 0\n",
            "185/1400, missing 0\n",
            "186/1400, missing 0\n",
            "187/1400, missing 0\n",
            "188/1400, missing 0\n",
            "189/1400, missing 0\n",
            "190/1400, missing 0\n",
            "191/1400, missing 0\n",
            "192/1400, missing 0\n",
            "193/1400, missing 0\n",
            "194/1400, missing 0\n",
            "195/1400, missing 0\n",
            "196/1400, missing 0\n",
            "197/1400, missing 0\n",
            "198/1400, missing 0\n",
            "199/1400, missing 0\n",
            "200/1400, missing 0\n",
            "201/1400, missing 0\n",
            "202/1400, missing 0\n",
            "203/1400, missing 0\n",
            "204/1400, missing 0\n",
            "205/1400, missing 0\n",
            "206/1400, missing 0\n",
            "207/1400, missing 0\n",
            "208/1400, missing 0\n",
            "209/1400, missing 0\n",
            "210/1400, missing 0\n",
            "211/1400, missing 0\n",
            "212/1400, missing 0\n",
            "213/1400, missing 0\n",
            "214/1400, missing 0\n",
            "215/1400, missing 0\n",
            "216/1400, missing 0\n",
            "217/1400, missing 0\n",
            "218/1400, missing 0\n",
            "219/1400, missing 0\n",
            "220/1400, missing 0\n",
            "221/1400, missing 0\n",
            "222/1400, missing 0\n",
            "223/1400, missing 0\n",
            "224/1400, missing 0\n",
            "225/1400, missing 0\n",
            "226/1400, missing 0\n",
            "227/1400, missing 0\n",
            "228/1400, missing 0\n",
            "229/1400, missing 0\n",
            "230/1400, missing 0\n",
            "231/1400, missing 0\n",
            "232/1400, missing 0\n",
            "233/1400, missing 0\n",
            "234/1400, missing 0\n",
            "235/1400, missing 0\n",
            "236/1400, missing 0\n",
            "237/1400, missing 0\n",
            "238/1400, missing 0\n",
            "239/1400, missing 0\n",
            "240/1400, missing 0\n",
            "241/1400, missing 0\n",
            "242/1400, missing 0\n",
            "243/1400, missing 0\n",
            "244/1400, missing 0\n",
            "245/1400, missing 0\n",
            "246/1400, missing 0\n",
            "247/1400, missing 0\n",
            "248/1400, missing 0\n",
            "249/1400, missing 0\n",
            "250/1400, missing 0\n",
            "251/1400, missing 0\n",
            "252/1400, missing 0\n",
            "253/1400, missing 0\n",
            "254/1400, missing 0\n",
            "255/1400, missing 0\n",
            "256/1400, missing 0\n",
            "257/1400, missing 0\n",
            "258/1400, missing 0\n",
            "259/1400, missing 0\n",
            "260/1400, missing 0\n",
            "261/1400, missing 0\n",
            "262/1400, missing 0\n",
            "263/1400, missing 0\n",
            "264/1400, missing 0\n",
            "265/1400, missing 0\n",
            "266/1400, missing 0\n",
            "267/1400, missing 0\n",
            "268/1400, missing 0\n",
            "269/1400, missing 0\n",
            "270/1400, missing 0\n",
            "271/1400, missing 0\n",
            "272/1400, missing 0\n",
            "273/1400, missing 0\n",
            "274/1400, missing 0\n",
            "275/1400, missing 0\n",
            "276/1400, missing 0\n",
            "277/1400, missing 0\n",
            "278/1400, missing 0\n",
            "279/1400, missing 0\n",
            "280/1400, missing 0\n",
            "281/1400, missing 0\n",
            "282/1400, missing 0\n",
            "283/1400, missing 0\n",
            "284/1400, missing 0\n",
            "285/1400, missing 0\n",
            "286/1400, missing 0\n",
            "287/1400, missing 0\n",
            "288/1400, missing 0\n",
            "289/1400, missing 0\n",
            "290/1400, missing 0\n",
            "291/1400, missing 0\n",
            "292/1400, missing 0\n",
            "293/1400, missing 0\n",
            "294/1400, missing 0\n",
            "295/1400, missing 0\n",
            "296/1400, missing 0\n",
            "297/1400, missing 0\n",
            "298/1400, missing 0\n",
            "299/1400, missing 0\n",
            "300/1400, missing 0\n",
            "301/1400, missing 0\n",
            "302/1400, missing 0\n",
            "303/1400, missing 0\n",
            "304/1400, missing 0\n",
            "305/1400, missing 0\n",
            "306/1400, missing 0\n",
            "307/1400, missing 0\n",
            "308/1400, missing 0\n",
            "309/1400, missing 0\n",
            "310/1400, missing 0\n",
            "311/1400, missing 0\n",
            "312/1400, missing 0\n",
            "313/1400, missing 0\n",
            "314/1400, missing 0\n",
            "315/1400, missing 0\n",
            "316/1400, missing 0\n",
            "317/1400, missing 0\n",
            "318/1400, missing 0\n",
            "319/1400, missing 0\n",
            "320/1400, missing 1\n",
            "321/1400, missing 1\n",
            "322/1400, missing 1\n",
            "323/1400, missing 1\n",
            "324/1400, missing 1\n",
            "325/1400, missing 1\n",
            "326/1400, missing 1\n",
            "327/1400, missing 1\n",
            "328/1400, missing 1\n",
            "329/1400, missing 1\n",
            "330/1400, missing 1\n",
            "331/1400, missing 1\n",
            "332/1400, missing 1\n",
            "333/1400, missing 1\n",
            "334/1400, missing 1\n",
            "335/1400, missing 1\n",
            "336/1400, missing 1\n",
            "337/1400, missing 1\n",
            "338/1400, missing 1\n",
            "339/1400, missing 1\n",
            "340/1400, missing 1\n",
            "341/1400, missing 1\n",
            "342/1400, missing 1\n",
            "343/1400, missing 1\n",
            "344/1400, missing 1\n",
            "345/1400, missing 1\n",
            "346/1400, missing 1\n",
            "347/1400, missing 1\n",
            "348/1400, missing 1\n",
            "349/1400, missing 1\n",
            "350/1400, missing 1\n",
            "351/1400, missing 1\n",
            "352/1400, missing 1\n",
            "353/1400, missing 1\n",
            "354/1400, missing 1\n",
            "355/1400, missing 1\n",
            "356/1400, missing 1\n",
            "357/1400, missing 1\n",
            "358/1400, missing 1\n",
            "359/1400, missing 1\n",
            "360/1400, missing 1\n",
            "361/1400, missing 1\n",
            "362/1400, missing 1\n",
            "363/1400, missing 1\n",
            "364/1400, missing 1\n",
            "365/1400, missing 1\n",
            "366/1400, missing 1\n",
            "367/1400, missing 1\n",
            "368/1400, missing 1\n",
            "369/1400, missing 1\n",
            "370/1400, missing 1\n",
            "371/1400, missing 1\n",
            "372/1400, missing 1\n",
            "373/1400, missing 1\n",
            "374/1400, missing 1\n",
            "375/1400, missing 1\n",
            "376/1400, missing 1\n",
            "377/1400, missing 1\n",
            "378/1400, missing 1\n",
            "379/1400, missing 1\n",
            "380/1400, missing 1\n",
            "381/1400, missing 1\n",
            "382/1400, missing 1\n",
            "383/1400, missing 1\n",
            "384/1400, missing 1\n",
            "385/1400, missing 1\n",
            "386/1400, missing 1\n",
            "387/1400, missing 1\n",
            "388/1400, missing 1\n",
            "389/1400, missing 1\n",
            "390/1400, missing 1\n",
            "391/1400, missing 1\n",
            "392/1400, missing 1\n",
            "393/1400, missing 1\n",
            "394/1400, missing 1\n",
            "395/1400, missing 1\n",
            "396/1400, missing 1\n",
            "397/1400, missing 1\n",
            "398/1400, missing 1\n",
            "399/1400, missing 1\n",
            "400/1400, missing 1\n",
            "401/1400, missing 1\n",
            "402/1400, missing 1\n",
            "403/1400, missing 1\n",
            "404/1400, missing 1\n",
            "405/1400, missing 1\n",
            "406/1400, missing 1\n",
            "407/1400, missing 1\n",
            "408/1400, missing 1\n",
            "409/1400, missing 1\n",
            "410/1400, missing 1\n",
            "411/1400, missing 1\n",
            "412/1400, missing 1\n",
            "413/1400, missing 1\n",
            "414/1400, missing 1\n",
            "415/1400, missing 1\n",
            "416/1400, missing 1\n",
            "417/1400, missing 1\n",
            "418/1400, missing 1\n",
            "419/1400, missing 1\n",
            "420/1400, missing 1\n",
            "421/1400, missing 1\n",
            "422/1400, missing 1\n",
            "423/1400, missing 1\n",
            "424/1400, missing 1\n",
            "425/1400, missing 1\n",
            "426/1400, missing 1\n",
            "427/1400, missing 1\n",
            "428/1400, missing 1\n",
            "429/1400, missing 1\n",
            "430/1400, missing 1\n",
            "431/1400, missing 1\n",
            "432/1400, missing 1\n",
            "433/1400, missing 1\n",
            "434/1400, missing 1\n",
            "435/1400, missing 1\n",
            "436/1400, missing 1\n",
            "437/1400, missing 1\n",
            "438/1400, missing 1\n",
            "439/1400, missing 1\n",
            "440/1400, missing 1\n",
            "441/1400, missing 1\n",
            "442/1400, missing 1\n",
            "443/1400, missing 1\n",
            "444/1400, missing 1\n",
            "445/1400, missing 1\n",
            "446/1400, missing 1\n",
            "447/1400, missing 1\n",
            "448/1400, missing 1\n",
            "449/1400, missing 1\n",
            "450/1400, missing 1\n",
            "451/1400, missing 1\n",
            "452/1400, missing 1\n",
            "453/1400, missing 1\n",
            "454/1400, missing 1\n",
            "455/1400, missing 1\n",
            "456/1400, missing 1\n",
            "457/1400, missing 1\n",
            "458/1400, missing 1\n",
            "459/1400, missing 1\n",
            "460/1400, missing 1\n",
            "461/1400, missing 1\n",
            "462/1400, missing 1\n",
            "463/1400, missing 1\n",
            "464/1400, missing 1\n",
            "465/1400, missing 1\n",
            "466/1400, missing 1\n",
            "467/1400, missing 1\n",
            "468/1400, missing 1\n",
            "469/1400, missing 1\n",
            "470/1400, missing 1\n",
            "471/1400, missing 1\n",
            "472/1400, missing 1\n",
            "473/1400, missing 1\n",
            "474/1400, missing 1\n",
            "475/1400, missing 1\n",
            "476/1400, missing 1\n",
            "477/1400, missing 1\n",
            "478/1400, missing 1\n",
            "479/1400, missing 1\n",
            "480/1400, missing 1\n",
            "481/1400, missing 1\n",
            "482/1400, missing 1\n",
            "483/1400, missing 1\n",
            "484/1400, missing 1\n",
            "485/1400, missing 1\n",
            "486/1400, missing 1\n",
            "487/1400, missing 1\n",
            "488/1400, missing 1\n",
            "489/1400, missing 1\n",
            "490/1400, missing 1\n",
            "491/1400, missing 1\n",
            "492/1400, missing 1\n",
            "493/1400, missing 1\n",
            "494/1400, missing 1\n",
            "495/1400, missing 1\n",
            "496/1400, missing 1\n",
            "497/1400, missing 1\n",
            "498/1400, missing 1\n",
            "499/1400, missing 1\n",
            "500/1400, missing 1\n",
            "501/1400, missing 1\n",
            "502/1400, missing 1\n",
            "503/1400, missing 1\n",
            "504/1400, missing 1\n",
            "505/1400, missing 1\n",
            "506/1400, missing 1\n",
            "507/1400, missing 1\n",
            "508/1400, missing 1\n",
            "509/1400, missing 1\n",
            "510/1400, missing 1\n",
            "511/1400, missing 1\n",
            "512/1400, missing 1\n",
            "513/1400, missing 1\n",
            "514/1400, missing 1\n",
            "515/1400, missing 1\n",
            "516/1400, missing 1\n",
            "517/1400, missing 1\n",
            "518/1400, missing 1\n",
            "519/1400, missing 1\n",
            "520/1400, missing 1\n",
            "521/1400, missing 1\n",
            "522/1400, missing 1\n",
            "523/1400, missing 1\n",
            "524/1400, missing 1\n",
            "525/1400, missing 1\n",
            "526/1400, missing 1\n",
            "527/1400, missing 1\n",
            "528/1400, missing 1\n",
            "529/1400, missing 1\n",
            "530/1400, missing 1\n",
            "531/1400, missing 1\n",
            "532/1400, missing 1\n",
            "533/1400, missing 1\n",
            "534/1400, missing 1\n",
            "535/1400, missing 1\n",
            "536/1400, missing 1\n",
            "537/1400, missing 1\n",
            "538/1400, missing 1\n",
            "539/1400, missing 1\n",
            "540/1400, missing 1\n",
            "541/1400, missing 1\n",
            "542/1400, missing 1\n",
            "543/1400, missing 1\n",
            "544/1400, missing 1\n",
            "545/1400, missing 1\n",
            "546/1400, missing 1\n",
            "547/1400, missing 1\n",
            "548/1400, missing 1\n",
            "549/1400, missing 1\n",
            "550/1400, missing 1\n",
            "551/1400, missing 1\n",
            "552/1400, missing 1\n",
            "553/1400, missing 1\n",
            "554/1400, missing 1\n",
            "555/1400, missing 1\n",
            "556/1400, missing 1\n",
            "557/1400, missing 1\n",
            "558/1400, missing 1\n",
            "559/1400, missing 1\n",
            "560/1400, missing 1\n",
            "561/1400, missing 1\n",
            "562/1400, missing 1\n",
            "563/1400, missing 1\n",
            "564/1400, missing 1\n",
            "565/1400, missing 1\n",
            "566/1400, missing 1\n",
            "567/1400, missing 1\n",
            "568/1400, missing 1\n",
            "569/1400, missing 1\n",
            "570/1400, missing 1\n",
            "571/1400, missing 1\n",
            "572/1400, missing 1\n",
            "573/1400, missing 1\n",
            "574/1400, missing 1\n",
            "575/1400, missing 1\n",
            "576/1400, missing 1\n",
            "577/1400, missing 1\n",
            "578/1400, missing 1\n",
            "579/1400, missing 1\n",
            "580/1400, missing 1\n",
            "581/1400, missing 1\n",
            "582/1400, missing 1\n",
            "583/1400, missing 1\n",
            "584/1400, missing 1\n",
            "585/1400, missing 1\n",
            "586/1400, missing 1\n",
            "587/1400, missing 1\n",
            "588/1400, missing 1\n",
            "589/1400, missing 1\n",
            "590/1400, missing 1\n",
            "591/1400, missing 1\n",
            "592/1400, missing 1\n",
            "593/1400, missing 1\n",
            "594/1400, missing 1\n",
            "595/1400, missing 1\n",
            "596/1400, missing 1\n",
            "597/1400, missing 1\n",
            "598/1400, missing 1\n",
            "599/1400, missing 1\n",
            "600/1400, missing 1\n",
            "601/1400, missing 1\n",
            "602/1400, missing 1\n",
            "603/1400, missing 1\n",
            "604/1400, missing 1\n",
            "605/1400, missing 1\n",
            "606/1400, missing 1\n",
            "607/1400, missing 1\n",
            "608/1400, missing 1\n",
            "609/1400, missing 1\n",
            "610/1400, missing 1\n",
            "611/1400, missing 1\n",
            "612/1400, missing 1\n",
            "613/1400, missing 1\n",
            "614/1400, missing 1\n",
            "615/1400, missing 1\n",
            "616/1400, missing 1\n",
            "617/1400, missing 1\n",
            "618/1400, missing 1\n",
            "619/1400, missing 1\n",
            "620/1400, missing 1\n",
            "621/1400, missing 1\n",
            "622/1400, missing 1\n",
            "623/1400, missing 1\n",
            "624/1400, missing 1\n",
            "625/1400, missing 1\n",
            "626/1400, missing 1\n",
            "627/1400, missing 1\n",
            "628/1400, missing 1\n",
            "629/1400, missing 1\n",
            "630/1400, missing 1\n",
            "631/1400, missing 1\n",
            "632/1400, missing 1\n",
            "633/1400, missing 1\n",
            "634/1400, missing 1\n",
            "635/1400, missing 1\n",
            "636/1400, missing 1\n",
            "637/1400, missing 1\n",
            "638/1400, missing 1\n",
            "639/1400, missing 1\n",
            "640/1400, missing 1\n",
            "641/1400, missing 1\n",
            "642/1400, missing 1\n",
            "643/1400, missing 1\n",
            "644/1400, missing 1\n",
            "645/1400, missing 1\n",
            "646/1400, missing 1\n",
            "647/1400, missing 1\n",
            "648/1400, missing 1\n",
            "649/1400, missing 1\n",
            "650/1400, missing 1\n",
            "651/1400, missing 1\n",
            "652/1400, missing 1\n",
            "653/1400, missing 1\n",
            "654/1400, missing 1\n",
            "655/1400, missing 1\n",
            "656/1400, missing 1\n",
            "657/1400, missing 1\n",
            "658/1400, missing 1\n",
            "659/1400, missing 1\n",
            "660/1400, missing 1\n",
            "661/1400, missing 1\n",
            "662/1400, missing 1\n",
            "663/1400, missing 1\n",
            "664/1400, missing 1\n",
            "665/1400, missing 1\n",
            "666/1400, missing 1\n",
            "667/1400, missing 1\n",
            "668/1400, missing 1\n",
            "669/1400, missing 1\n",
            "670/1400, missing 1\n",
            "671/1400, missing 1\n",
            "672/1400, missing 1\n",
            "673/1400, missing 1\n",
            "674/1400, missing 1\n",
            "675/1400, missing 1\n",
            "676/1400, missing 1\n",
            "677/1400, missing 1\n",
            "678/1400, missing 1\n",
            "679/1400, missing 1\n",
            "680/1400, missing 1\n",
            "681/1400, missing 1\n",
            "682/1400, missing 1\n",
            "683/1400, missing 1\n",
            "684/1400, missing 1\n",
            "685/1400, missing 1\n",
            "686/1400, missing 1\n",
            "687/1400, missing 1\n",
            "688/1400, missing 1\n",
            "689/1400, missing 1\n",
            "690/1400, missing 1\n",
            "691/1400, missing 1\n",
            "692/1400, missing 1\n",
            "693/1400, missing 1\n",
            "694/1400, missing 1\n",
            "695/1400, missing 1\n",
            "696/1400, missing 1\n",
            "697/1400, missing 1\n",
            "698/1400, missing 1\n",
            "699/1400, missing 1\n",
            "700/1400, missing 1\n",
            "701/1400, missing 1\n",
            "702/1400, missing 1\n",
            "703/1400, missing 1\n",
            "704/1400, missing 1\n",
            "705/1400, missing 1\n",
            "706/1400, missing 1\n",
            "707/1400, missing 1\n",
            "708/1400, missing 1\n",
            "709/1400, missing 1\n",
            "710/1400, missing 1\n",
            "711/1400, missing 1\n",
            "712/1400, missing 1\n",
            "713/1400, missing 1\n",
            "714/1400, missing 1\n",
            "715/1400, missing 1\n",
            "716/1400, missing 1\n",
            "717/1400, missing 1\n",
            "718/1400, missing 1\n",
            "719/1400, missing 1\n",
            "720/1400, missing 1\n",
            "721/1400, missing 1\n",
            "722/1400, missing 1\n",
            "723/1400, missing 1\n",
            "724/1400, missing 1\n",
            "725/1400, missing 1\n",
            "726/1400, missing 1\n",
            "727/1400, missing 1\n",
            "728/1400, missing 1\n",
            "729/1400, missing 1\n",
            "730/1400, missing 1\n",
            "731/1400, missing 1\n",
            "732/1400, missing 1\n",
            "733/1400, missing 1\n",
            "734/1400, missing 1\n",
            "735/1400, missing 1\n",
            "736/1400, missing 1\n",
            "737/1400, missing 1\n",
            "738/1400, missing 1\n",
            "739/1400, missing 1\n",
            "740/1400, missing 1\n",
            "741/1400, missing 1\n",
            "742/1400, missing 1\n",
            "743/1400, missing 1\n",
            "744/1400, missing 1\n",
            "745/1400, missing 1\n",
            "746/1400, missing 1\n",
            "747/1400, missing 1\n",
            "748/1400, missing 1\n",
            "749/1400, missing 1\n",
            "750/1400, missing 1\n",
            "751/1400, missing 1\n",
            "752/1400, missing 1\n",
            "753/1400, missing 1\n",
            "754/1400, missing 1\n",
            "755/1400, missing 1\n",
            "756/1400, missing 1\n",
            "757/1400, missing 1\n",
            "758/1400, missing 1\n",
            "759/1400, missing 1\n",
            "760/1400, missing 1\n",
            "761/1400, missing 1\n",
            "762/1400, missing 1\n",
            "763/1400, missing 1\n",
            "764/1400, missing 1\n",
            "765/1400, missing 1\n",
            "766/1400, missing 1\n",
            "767/1400, missing 1\n",
            "768/1400, missing 1\n",
            "769/1400, missing 1\n",
            "770/1400, missing 1\n",
            "771/1400, missing 1\n",
            "772/1400, missing 1\n",
            "773/1400, missing 1\n",
            "774/1400, missing 1\n",
            "775/1400, missing 1\n",
            "776/1400, missing 1\n",
            "777/1400, missing 1\n",
            "778/1400, missing 1\n",
            "779/1400, missing 1\n",
            "780/1400, missing 1\n",
            "781/1400, missing 1\n",
            "782/1400, missing 1\n",
            "783/1400, missing 1\n",
            "784/1400, missing 1\n",
            "785/1400, missing 1\n",
            "786/1400, missing 1\n",
            "787/1400, missing 1\n",
            "788/1400, missing 1\n",
            "789/1400, missing 1\n",
            "790/1400, missing 1\n",
            "791/1400, missing 1\n",
            "792/1400, missing 1\n",
            "793/1400, missing 1\n",
            "794/1400, missing 1\n",
            "795/1400, missing 1\n",
            "796/1400, missing 1\n",
            "797/1400, missing 1\n",
            "798/1400, missing 1\n",
            "799/1400, missing 1\n",
            "800/1400, missing 1\n",
            "801/1400, missing 1\n",
            "802/1400, missing 1\n",
            "803/1400, missing 1\n",
            "804/1400, missing 1\n",
            "805/1400, missing 1\n",
            "806/1400, missing 1\n",
            "807/1400, missing 1\n",
            "808/1400, missing 1\n",
            "809/1400, missing 1\n",
            "810/1400, missing 1\n",
            "811/1400, missing 1\n",
            "812/1400, missing 1\n",
            "813/1400, missing 1\n",
            "814/1400, missing 1\n",
            "815/1400, missing 1\n",
            "816/1400, missing 1\n",
            "817/1400, missing 1\n",
            "818/1400, missing 1\n",
            "819/1400, missing 1\n",
            "820/1400, missing 1\n",
            "821/1400, missing 1\n",
            "822/1400, missing 1\n",
            "823/1400, missing 1\n",
            "824/1400, missing 1\n",
            "825/1400, missing 1\n",
            "826/1400, missing 1\n",
            "827/1400, missing 1\n",
            "828/1400, missing 1\n",
            "829/1400, missing 1\n",
            "830/1400, missing 1\n",
            "831/1400, missing 1\n",
            "832/1400, missing 1\n",
            "833/1400, missing 1\n",
            "834/1400, missing 1\n",
            "835/1400, missing 1\n",
            "836/1400, missing 1\n",
            "837/1400, missing 1\n",
            "838/1400, missing 1\n",
            "839/1400, missing 1\n",
            "840/1400, missing 1\n",
            "841/1400, missing 1\n",
            "842/1400, missing 1\n",
            "843/1400, missing 1\n",
            "844/1400, missing 1\n",
            "845/1400, missing 1\n",
            "846/1400, missing 1\n",
            "847/1400, missing 1\n",
            "848/1400, missing 1\n",
            "849/1400, missing 1\n",
            "850/1400, missing 1\n",
            "851/1400, missing 1\n",
            "852/1400, missing 1\n",
            "853/1400, missing 1\n",
            "854/1400, missing 1\n",
            "855/1400, missing 1\n",
            "856/1400, missing 1\n",
            "857/1400, missing 1\n",
            "858/1400, missing 1\n",
            "859/1400, missing 1\n",
            "860/1400, missing 1\n",
            "861/1400, missing 1\n",
            "862/1400, missing 1\n",
            "863/1400, missing 1\n",
            "864/1400, missing 1\n",
            "865/1400, missing 1\n",
            "866/1400, missing 1\n",
            "867/1400, missing 1\n",
            "868/1400, missing 1\n",
            "869/1400, missing 1\n",
            "870/1400, missing 1\n",
            "871/1400, missing 1\n",
            "872/1400, missing 1\n",
            "873/1400, missing 1\n",
            "874/1400, missing 1\n",
            "875/1400, missing 1\n",
            "876/1400, missing 1\n",
            "877/1400, missing 1\n",
            "878/1400, missing 1\n",
            "879/1400, missing 1\n",
            "880/1400, missing 1\n",
            "881/1400, missing 1\n",
            "882/1400, missing 1\n",
            "883/1400, missing 1\n",
            "884/1400, missing 1\n",
            "885/1400, missing 1\n",
            "886/1400, missing 1\n",
            "887/1400, missing 1\n",
            "888/1400, missing 1\n",
            "889/1400, missing 1\n",
            "890/1400, missing 1\n",
            "891/1400, missing 1\n",
            "892/1400, missing 1\n",
            "893/1400, missing 1\n",
            "894/1400, missing 1\n",
            "895/1400, missing 1\n",
            "896/1400, missing 1\n",
            "897/1400, missing 1\n",
            "898/1400, missing 1\n",
            "899/1400, missing 1\n",
            "900/1400, missing 1\n",
            "901/1400, missing 1\n",
            "902/1400, missing 1\n",
            "903/1400, missing 1\n",
            "904/1400, missing 1\n",
            "905/1400, missing 1\n",
            "906/1400, missing 1\n",
            "907/1400, missing 1\n",
            "908/1400, missing 1\n",
            "909/1400, missing 1\n",
            "910/1400, missing 1\n",
            "911/1400, missing 1\n",
            "912/1400, missing 1\n",
            "913/1400, missing 1\n",
            "914/1400, missing 1\n",
            "915/1400, missing 1\n",
            "916/1400, missing 1\n",
            "917/1400, missing 1\n",
            "918/1400, missing 1\n",
            "919/1400, missing 1\n",
            "920/1400, missing 1\n",
            "921/1400, missing 1\n",
            "922/1400, missing 1\n",
            "923/1400, missing 1\n",
            "924/1400, missing 1\n",
            "925/1400, missing 1\n",
            "926/1400, missing 1\n",
            "927/1400, missing 1\n",
            "928/1400, missing 1\n",
            "929/1400, missing 1\n",
            "930/1400, missing 1\n",
            "931/1400, missing 1\n",
            "932/1400, missing 1\n",
            "933/1400, missing 1\n",
            "934/1400, missing 1\n",
            "935/1400, missing 1\n",
            "936/1400, missing 1\n",
            "937/1400, missing 1\n",
            "938/1400, missing 1\n",
            "939/1400, missing 1\n",
            "940/1400, missing 1\n",
            "941/1400, missing 1\n",
            "942/1400, missing 1\n",
            "943/1400, missing 1\n",
            "944/1400, missing 1\n",
            "945/1400, missing 1\n",
            "946/1400, missing 1\n",
            "947/1400, missing 1\n",
            "948/1400, missing 1\n",
            "949/1400, missing 1\n",
            "950/1400, missing 1\n",
            "951/1400, missing 1\n",
            "952/1400, missing 1\n",
            "953/1400, missing 1\n",
            "954/1400, missing 1\n",
            "955/1400, missing 1\n",
            "956/1400, missing 1\n",
            "957/1400, missing 1\n",
            "958/1400, missing 1\n",
            "959/1400, missing 1\n",
            "960/1400, missing 1\n",
            "961/1400, missing 1\n",
            "962/1400, missing 1\n",
            "963/1400, missing 1\n",
            "964/1400, missing 1\n",
            "965/1400, missing 1\n",
            "966/1400, missing 1\n",
            "967/1400, missing 1\n",
            "968/1400, missing 1\n",
            "969/1400, missing 1\n",
            "970/1400, missing 1\n",
            "971/1400, missing 1\n",
            "972/1400, missing 1\n",
            "973/1400, missing 1\n",
            "974/1400, missing 1\n",
            "975/1400, missing 1\n",
            "976/1400, missing 1\n",
            "977/1400, missing 1\n",
            "978/1400, missing 1\n",
            "979/1400, missing 1\n",
            "980/1400, missing 1\n",
            "981/1400, missing 1\n",
            "982/1400, missing 1\n",
            "983/1400, missing 1\n",
            "984/1400, missing 1\n",
            "985/1400, missing 1\n",
            "986/1400, missing 1\n",
            "987/1400, missing 1\n",
            "988/1400, missing 1\n",
            "989/1400, missing 1\n",
            "990/1400, missing 1\n",
            "991/1400, missing 1\n",
            "992/1400, missing 1\n",
            "993/1400, missing 1\n",
            "994/1400, missing 1\n",
            "995/1400, missing 1\n",
            "996/1400, missing 1\n",
            "997/1400, missing 1\n",
            "998/1400, missing 1\n",
            "999/1400, missing 1\n",
            "1000/1400, missing 1\n",
            "1001/1400, missing 1\n",
            "1002/1400, missing 1\n",
            "1003/1400, missing 1\n",
            "1004/1400, missing 1\n",
            "1005/1400, missing 1\n",
            "1006/1400, missing 1\n",
            "1007/1400, missing 1\n",
            "1008/1400, missing 1\n",
            "1009/1400, missing 1\n",
            "1010/1400, missing 1\n",
            "1011/1400, missing 1\n",
            "1012/1400, missing 1\n",
            "1013/1400, missing 1\n",
            "1014/1400, missing 1\n",
            "1015/1400, missing 1\n",
            "1016/1400, missing 1\n",
            "1017/1400, missing 1\n",
            "1018/1400, missing 1\n",
            "1019/1400, missing 1\n",
            "1020/1400, missing 1\n",
            "1021/1400, missing 1\n",
            "1022/1400, missing 1\n",
            "1023/1400, missing 1\n",
            "1024/1400, missing 1\n",
            "1025/1400, missing 1\n",
            "1026/1400, missing 1\n",
            "1027/1400, missing 1\n",
            "1028/1400, missing 1\n",
            "1029/1400, missing 1\n",
            "1030/1400, missing 1\n",
            "1031/1400, missing 1\n",
            "1032/1400, missing 1\n",
            "1033/1400, missing 1\n",
            "1034/1400, missing 1\n",
            "1035/1400, missing 1\n",
            "1036/1400, missing 1\n",
            "1037/1400, missing 1\n",
            "1038/1400, missing 1\n",
            "1039/1400, missing 1\n",
            "1040/1400, missing 1\n",
            "1041/1400, missing 1\n",
            "1042/1400, missing 1\n",
            "1043/1400, missing 1\n",
            "1044/1400, missing 1\n",
            "1045/1400, missing 1\n",
            "1046/1400, missing 1\n",
            "1047/1400, missing 1\n",
            "1048/1400, missing 1\n",
            "1049/1400, missing 1\n",
            "1050/1400, missing 1\n",
            "1051/1400, missing 1\n",
            "1052/1400, missing 1\n",
            "1053/1400, missing 1\n",
            "1054/1400, missing 1\n",
            "1055/1400, missing 1\n",
            "1056/1400, missing 1\n",
            "1057/1400, missing 1\n",
            "1058/1400, missing 1\n",
            "1059/1400, missing 1\n",
            "1060/1400, missing 1\n",
            "1061/1400, missing 1\n",
            "1062/1400, missing 1\n",
            "1063/1400, missing 1\n",
            "1064/1400, missing 1\n",
            "1065/1400, missing 1\n",
            "1066/1400, missing 1\n",
            "1067/1400, missing 1\n",
            "1068/1400, missing 1\n",
            "1069/1400, missing 1\n",
            "1070/1400, missing 1\n",
            "1071/1400, missing 1\n",
            "1072/1400, missing 1\n",
            "1073/1400, missing 1\n",
            "1074/1400, missing 1\n",
            "1075/1400, missing 1\n",
            "1076/1400, missing 1\n",
            "1077/1400, missing 1\n",
            "1078/1400, missing 1\n",
            "1079/1400, missing 1\n",
            "1080/1400, missing 1\n",
            "1081/1400, missing 1\n",
            "1082/1400, missing 1\n",
            "1083/1400, missing 1\n",
            "1084/1400, missing 1\n",
            "1085/1400, missing 1\n",
            "1086/1400, missing 1\n",
            "1087/1400, missing 1\n",
            "1088/1400, missing 1\n",
            "1089/1400, missing 1\n",
            "1090/1400, missing 1\n",
            "1091/1400, missing 1\n",
            "1092/1400, missing 1\n",
            "1093/1400, missing 1\n",
            "1094/1400, missing 1\n",
            "1095/1400, missing 1\n",
            "1096/1400, missing 1\n",
            "1097/1400, missing 1\n",
            "1098/1400, missing 1\n",
            "1099/1400, missing 1\n",
            "1100/1400, missing 1\n",
            "1101/1400, missing 1\n",
            "1102/1400, missing 1\n",
            "1103/1400, missing 1\n",
            "1104/1400, missing 1\n",
            "1105/1400, missing 1\n",
            "1106/1400, missing 1\n",
            "1107/1400, missing 1\n",
            "1108/1400, missing 1\n",
            "1109/1400, missing 1\n",
            "1110/1400, missing 1\n",
            "1111/1400, missing 1\n",
            "1112/1400, missing 1\n",
            "1113/1400, missing 1\n",
            "1114/1400, missing 1\n",
            "1115/1400, missing 1\n",
            "1116/1400, missing 1\n",
            "1117/1400, missing 1\n",
            "1118/1400, missing 1\n",
            "1119/1400, missing 1\n",
            "1120/1400, missing 1\n",
            "1121/1400, missing 1\n",
            "1122/1400, missing 1\n",
            "1123/1400, missing 1\n",
            "1124/1400, missing 1\n",
            "1125/1400, missing 1\n",
            "1126/1400, missing 1\n",
            "1127/1400, missing 1\n",
            "1128/1400, missing 1\n",
            "1129/1400, missing 1\n",
            "1130/1400, missing 1\n",
            "1131/1400, missing 1\n",
            "1132/1400, missing 1\n",
            "1133/1400, missing 1\n",
            "1134/1400, missing 1\n",
            "1135/1400, missing 1\n",
            "1136/1400, missing 1\n",
            "1137/1400, missing 1\n",
            "1138/1400, missing 1\n",
            "1139/1400, missing 1\n",
            "1140/1400, missing 1\n",
            "1141/1400, missing 1\n",
            "1142/1400, missing 1\n",
            "1143/1400, missing 1\n",
            "1144/1400, missing 1\n",
            "1145/1400, missing 1\n",
            "1146/1400, missing 1\n",
            "1147/1400, missing 1\n",
            "1148/1400, missing 1\n",
            "1149/1400, missing 1\n",
            "1150/1400, missing 1\n",
            "1151/1400, missing 1\n",
            "1152/1400, missing 1\n",
            "1153/1400, missing 1\n",
            "1154/1400, missing 1\n",
            "1155/1400, missing 1\n",
            "1156/1400, missing 1\n",
            "1157/1400, missing 1\n",
            "1158/1400, missing 1\n",
            "1159/1400, missing 1\n",
            "1160/1400, missing 1\n",
            "1161/1400, missing 1\n",
            "1162/1400, missing 1\n",
            "1163/1400, missing 1\n",
            "1164/1400, missing 1\n",
            "1165/1400, missing 1\n",
            "1166/1400, missing 1\n",
            "1167/1400, missing 1\n",
            "1168/1400, missing 1\n",
            "1169/1400, missing 1\n",
            "1170/1400, missing 1\n",
            "1171/1400, missing 1\n",
            "1172/1400, missing 1\n",
            "1173/1400, missing 1\n",
            "1174/1400, missing 1\n",
            "1175/1400, missing 1\n",
            "1176/1400, missing 1\n",
            "1177/1400, missing 1\n",
            "1178/1400, missing 1\n",
            "1179/1400, missing 1\n",
            "1180/1400, missing 1\n",
            "1181/1400, missing 1\n",
            "1182/1400, missing 1\n",
            "1183/1400, missing 1\n",
            "1184/1400, missing 1\n",
            "1185/1400, missing 1\n",
            "1186/1400, missing 1\n",
            "1187/1400, missing 1\n",
            "1188/1400, missing 1\n",
            "1189/1400, missing 1\n",
            "1190/1400, missing 1\n",
            "1191/1400, missing 1\n",
            "1192/1400, missing 1\n",
            "1193/1400, missing 1\n",
            "1194/1400, missing 1\n",
            "1195/1400, missing 1\n",
            "1196/1400, missing 1\n",
            "1197/1400, missing 1\n",
            "1198/1400, missing 1\n",
            "1199/1400, missing 1\n",
            "1200/1400, missing 1\n",
            "1201/1400, missing 1\n",
            "1202/1400, missing 1\n",
            "1203/1400, missing 1\n",
            "1204/1400, missing 1\n",
            "1205/1400, missing 1\n",
            "1206/1400, missing 1\n",
            "1207/1400, missing 1\n",
            "1208/1400, missing 1\n",
            "1209/1400, missing 1\n",
            "1210/1400, missing 1\n",
            "1211/1400, missing 1\n",
            "1212/1400, missing 1\n",
            "1213/1400, missing 1\n",
            "1214/1400, missing 1\n",
            "1215/1400, missing 1\n",
            "1216/1400, missing 1\n",
            "1217/1400, missing 1\n",
            "1218/1400, missing 1\n",
            "1219/1400, missing 1\n",
            "1220/1400, missing 1\n",
            "1221/1400, missing 1\n",
            "1222/1400, missing 1\n",
            "1223/1400, missing 1\n",
            "1224/1400, missing 1\n",
            "1225/1400, missing 1\n",
            "1226/1400, missing 1\n",
            "1227/1400, missing 1\n",
            "1228/1400, missing 1\n",
            "1229/1400, missing 1\n",
            "1230/1400, missing 1\n",
            "1231/1400, missing 1\n",
            "1232/1400, missing 1\n",
            "1233/1400, missing 1\n",
            "1234/1400, missing 1\n",
            "1235/1400, missing 1\n",
            "1236/1400, missing 1\n",
            "1237/1400, missing 1\n",
            "1238/1400, missing 1\n",
            "1239/1400, missing 1\n",
            "1240/1400, missing 1\n",
            "1241/1400, missing 1\n",
            "1242/1400, missing 1\n",
            "1243/1400, missing 1\n",
            "1244/1400, missing 1\n",
            "1245/1400, missing 1\n",
            "1246/1400, missing 1\n",
            "1247/1400, missing 1\n",
            "1248/1400, missing 1\n",
            "1249/1400, missing 1\n",
            "1250/1400, missing 1\n",
            "1251/1400, missing 1\n",
            "1252/1400, missing 1\n",
            "1253/1400, missing 1\n",
            "1254/1400, missing 1\n",
            "1255/1400, missing 1\n",
            "1256/1400, missing 1\n",
            "1257/1400, missing 1\n",
            "1258/1400, missing 1\n",
            "1259/1400, missing 1\n",
            "1260/1400, missing 1\n",
            "1261/1400, missing 1\n",
            "1262/1400, missing 1\n",
            "1263/1400, missing 1\n",
            "1264/1400, missing 1\n",
            "1265/1400, missing 1\n",
            "1266/1400, missing 1\n",
            "1267/1400, missing 1\n",
            "1268/1400, missing 1\n",
            "1269/1400, missing 1\n",
            "1270/1400, missing 1\n",
            "1271/1400, missing 1\n",
            "1272/1400, missing 1\n",
            "1273/1400, missing 1\n",
            "1274/1400, missing 1\n",
            "1275/1400, missing 1\n",
            "1276/1400, missing 1\n",
            "1277/1400, missing 1\n",
            "1278/1400, missing 1\n",
            "1279/1400, missing 1\n",
            "1280/1400, missing 1\n",
            "1281/1400, missing 1\n",
            "1282/1400, missing 1\n",
            "1283/1400, missing 1\n",
            "1284/1400, missing 1\n",
            "1285/1400, missing 1\n",
            "1286/1400, missing 1\n",
            "1287/1400, missing 1\n",
            "1288/1400, missing 1\n",
            "1289/1400, missing 1\n",
            "1290/1400, missing 1\n",
            "1291/1400, missing 1\n",
            "1292/1400, missing 1\n",
            "1293/1400, missing 1\n",
            "1294/1400, missing 1\n",
            "1295/1400, missing 1\n",
            "1296/1400, missing 1\n",
            "1297/1400, missing 1\n",
            "1298/1400, missing 1\n",
            "1299/1400, missing 1\n",
            "1300/1400, missing 1\n",
            "1301/1400, missing 1\n",
            "1302/1400, missing 1\n",
            "1303/1400, missing 1\n",
            "1304/1400, missing 1\n",
            "1305/1400, missing 1\n",
            "1306/1400, missing 1\n",
            "1307/1400, missing 1\n",
            "1308/1400, missing 1\n",
            "1309/1400, missing 1\n",
            "1310/1400, missing 1\n",
            "1311/1400, missing 1\n",
            "1312/1400, missing 1\n",
            "1313/1400, missing 1\n",
            "1314/1400, missing 1\n",
            "1315/1400, missing 1\n",
            "1316/1400, missing 1\n",
            "1317/1400, missing 1\n",
            "1318/1400, missing 1\n",
            "1319/1400, missing 1\n",
            "1320/1400, missing 1\n",
            "1321/1400, missing 1\n",
            "1322/1400, missing 1\n",
            "1323/1400, missing 1\n",
            "1324/1400, missing 1\n",
            "1325/1400, missing 1\n",
            "1326/1400, missing 1\n",
            "1327/1400, missing 1\n",
            "1328/1400, missing 1\n",
            "1329/1400, missing 1\n",
            "1330/1400, missing 1\n",
            "1331/1400, missing 1\n",
            "1332/1400, missing 1\n",
            "1333/1400, missing 1\n",
            "1334/1400, missing 1\n",
            "1335/1400, missing 1\n",
            "1336/1400, missing 1\n",
            "1337/1400, missing 1\n",
            "1338/1400, missing 1\n",
            "1339/1400, missing 1\n",
            "1340/1400, missing 1\n",
            "1341/1400, missing 1\n",
            "1342/1400, missing 1\n",
            "1343/1400, missing 1\n",
            "1344/1400, missing 1\n",
            "1345/1400, missing 1\n",
            "1346/1400, missing 1\n",
            "1347/1400, missing 1\n",
            "1348/1400, missing 1\n",
            "1349/1400, missing 1\n",
            "1350/1400, missing 1\n",
            "1351/1400, missing 1\n",
            "1352/1400, missing 1\n",
            "1353/1400, missing 1\n",
            "1354/1400, missing 1\n",
            "1355/1400, missing 1\n",
            "1356/1400, missing 1\n",
            "1357/1400, missing 1\n",
            "1358/1400, missing 1\n",
            "1359/1400, missing 1\n",
            "1360/1400, missing 1\n",
            "1361/1400, missing 1\n",
            "1362/1400, missing 1\n",
            "1363/1400, missing 1\n",
            "1364/1400, missing 1\n",
            "1365/1400, missing 1\n",
            "1366/1400, missing 1\n",
            "1367/1400, missing 1\n",
            "1368/1400, missing 1\n",
            "1369/1400, missing 1\n",
            "1370/1400, missing 1\n",
            "1371/1400, missing 1\n",
            "1372/1400, missing 1\n",
            "1373/1400, missing 1\n",
            "1374/1400, missing 1\n",
            "1375/1400, missing 1\n",
            "1376/1400, missing 1\n",
            "1377/1400, missing 1\n",
            "1378/1400, missing 1\n",
            "1379/1400, missing 1\n",
            "1380/1400, missing 1\n",
            "1381/1400, missing 1\n",
            "1382/1400, missing 1\n",
            "1383/1400, missing 1\n",
            "1384/1400, missing 1\n",
            "1385/1400, missing 1\n",
            "1386/1400, missing 1\n",
            "1387/1400, missing 1\n",
            "1388/1400, missing 1\n",
            "1389/1400, missing 1\n",
            "1390/1400, missing 1\n",
            "1391/1400, missing 1\n",
            "1392/1400, missing 1\n",
            "1393/1400, missing 1\n",
            "1394/1400, missing 1\n",
            "1395/1400, missing 1\n",
            "1396/1400, missing 1\n",
            "1397/1400, missing 1\n",
            "1398/1400, missing 1\n",
            "1399/1400, missing 1\n",
            "10\n",
            "0/43, missing 0\n",
            "1/43, missing 0\n",
            "2/43, missing 0\n",
            "3/43, missing 0\n",
            "4/43, missing 0\n",
            "5/43, missing 0\n",
            "6/43, missing 0\n",
            "7/43, missing 0\n",
            "8/43, missing 0\n",
            "9/43, missing 0\n",
            "10/43, missing 0\n",
            "11/43, missing 0\n",
            "12/43, missing 0\n",
            "13/43, missing 0\n",
            "14/43, missing 0\n",
            "15/43, missing 0\n",
            "16/43, missing 0\n",
            "17/43, missing 0\n",
            "18/43, missing 0\n",
            "19/43, missing 0\n",
            "20/43, missing 0\n",
            "21/43, missing 0\n",
            "22/43, missing 0\n",
            "23/43, missing 0\n",
            "24/43, missing 1\n",
            "25/43, missing 2\n",
            "26/43, missing 2\n",
            "27/43, missing 2\n",
            "28/43, missing 2\n",
            "29/43, missing 2\n",
            "30/43, missing 2\n",
            "31/43, missing 2\n",
            "32/43, missing 3\n",
            "33/43, missing 3\n",
            "34/43, missing 3\n",
            "35/43, missing 3\n",
            "36/43, missing 3\n",
            "37/43, missing 3\n",
            "38/43, missing 3\n",
            "39/43, missing 3\n",
            "40/43, missing 3\n",
            "41/43, missing 3\n",
            "42/43, missing 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vyILy2pyTNI"
      },
      "source": [
        "import os\n",
        "\n",
        "ROOT_DATASET = '/content/drive/My Drive/Samsung/'  # '/data/jilin/'\n",
        "\n",
        "\n",
        "def return_kinetics(modality):\n",
        "    filename_categories = 5\n",
        "    if modality == 'RGB':\n",
        "        root_data = ROOT_DATASET + 'frames'\n",
        "        filename_imglist_train = 'labels/train_videofolder.txt'\n",
        "        filename_imglist_val = 'labels/val_videofolder.txt'\n",
        "        prefix = 'img_{:05d}.jpg'\n",
        "    else:\n",
        "        raise NotImplementedError('no such modality:' + modality)\n",
        "    return filename_categories, filename_imglist_train, filename_imglist_val, root_data, prefix\n",
        "\n",
        "def return_dataset(dataset, modality):\n",
        "    dict_single = {'kinetics': return_kinetics }\n",
        "    if dataset in dict_single:\n",
        "        file_categories, file_imglist_train, file_imglist_val, root_data, prefix = dict_single[dataset](modality)\n",
        "    else:\n",
        "        raise ValueError('Unknown dataset '+dataset)\n",
        "\n",
        "    file_imglist_train = os.path.join(ROOT_DATASET, file_imglist_train)\n",
        "    file_imglist_val = os.path.join(ROOT_DATASET, file_imglist_val)\n",
        "    if isinstance(file_categories, str):\n",
        "        file_categories = os.path.join(ROOT_DATASET, file_categories)\n",
        "        with open(file_categories) as f:\n",
        "            lines = f.readlines()\n",
        "        categories = [item.rstrip() for item in lines]\n",
        "    else:  # number of categories\n",
        "        categories = [None] * file_categories\n",
        "    n_class = len(categories)\n",
        "    print('{}: {} classes'.format(dataset, n_class))\n",
        "    return n_class, file_imglist_train, file_imglist_val, root_data, prefix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiAAM8WZl9Y4"
      },
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "class VideoRecord(object):\n",
        "    def __init__(self, row):\n",
        "        self._data = row\n",
        "\n",
        "    @property\n",
        "    def path(self):\n",
        "        return self._data[0]\n",
        "\n",
        "    @property\n",
        "    def num_frames(self):\n",
        "        return int(self._data[1])\n",
        "\n",
        "    @property\n",
        "    def label(self):\n",
        "        return int(self._data[2])\n",
        "\n",
        "\n",
        "class TSNDataSet(data.Dataset):\n",
        "    def __init__(self, root_path, list_file,\n",
        "                 num_segments=3, new_length=1, modality='RGB',\n",
        "                 image_tmpl='img_{:05d}.jpg', transform=None,\n",
        "                 random_shift=True, test_mode=False,\n",
        "                 remove_missing=False, dense_sample=False, twice_sample=False):\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.list_file = list_file\n",
        "        self.num_segments = num_segments\n",
        "        self.new_length = new_length\n",
        "        self.modality = modality\n",
        "        self.image_tmpl = image_tmpl\n",
        "        self.transform = transform\n",
        "        self.random_shift = random_shift\n",
        "        self.test_mode = test_mode\n",
        "        self.remove_missing = remove_missing\n",
        "        self.dense_sample = dense_sample  # using dense sample as I3D\n",
        "        self.twice_sample = twice_sample  # twice sample for more validation\n",
        "        if self.dense_sample:\n",
        "            print('=> Using dense sample for the dataset...')\n",
        "        if self.twice_sample:\n",
        "            print('=> Using twice sample for the dataset...')\n",
        "\n",
        "        if self.modality == 'RGBDiff':\n",
        "            self.new_length += 1  # Diff needs one more image to calculate diff\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _load_image(self, directory, idx):\n",
        "        if self.modality == 'RGB' or self.modality == 'RGBDiff':\n",
        "            try:\n",
        "                return [Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format(idx))).convert('RGB')]\n",
        "            except Exception:\n",
        "                print('error loading image:', os.path.join(self.root_path, directory, self.image_tmpl.format(idx)))\n",
        "                return [Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format(1))).convert('RGB')]\n",
        "        elif self.modality == 'Flow':\n",
        "            if self.image_tmpl == 'flow_{}_{:05d}.jpg':  # ucf\n",
        "                x_img = Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format('x', idx))).convert(\n",
        "                    'L')\n",
        "                y_img = Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format('y', idx))).convert(\n",
        "                    'L')\n",
        "            elif self.image_tmpl == '{:06d}-{}_{:05d}.jpg':  # something v1 flow\n",
        "                x_img = Image.open(os.path.join(self.root_path, '{:06d}'.format(int(directory)), self.image_tmpl.\n",
        "                                                format(int(directory), 'x', idx))).convert('L')\n",
        "                y_img = Image.open(os.path.join(self.root_path, '{:06d}'.format(int(directory)), self.image_tmpl.\n",
        "                                                format(int(directory), 'y', idx))).convert('L')\n",
        "            else:\n",
        "                try:\n",
        "                    # idx_skip = 1 + (idx-1)*5\n",
        "                    flow = Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format(idx))).convert(\n",
        "                        'RGB')\n",
        "                except Exception:\n",
        "                    print('error loading flow file:',\n",
        "                          os.path.join(self.root_path, directory, self.image_tmpl.format(idx)))\n",
        "                    flow = Image.open(os.path.join(self.root_path, directory, self.image_tmpl.format(1))).convert('RGB')\n",
        "                # the input flow file is RGB image with (flow_x, flow_y, blank) for each channel\n",
        "                flow_x, flow_y, _ = flow.split()\n",
        "                x_img = flow_x.convert('L')\n",
        "                y_img = flow_y.convert('L')\n",
        "\n",
        "            return [x_img, y_img]\n",
        "\n",
        "    def _parse_list(self):\n",
        "        # check the frame number is large >3:\n",
        "        tmp = [x.strip().split(' ') for x in open(self.list_file)]\n",
        "        if not self.test_mode or self.remove_missing:\n",
        "            tmp = [item for item in tmp if int(item[1]) >= 3]\n",
        "        self.video_list = [VideoRecord(item) for item in tmp]\n",
        "\n",
        "        if self.image_tmpl == '{:06d}-{}_{:05d}.jpg':\n",
        "            for v in self.video_list:\n",
        "                v._data[1] = int(v._data[1]) / 2\n",
        "        print('video number:%d' % (len(self.video_list)))\n",
        "\n",
        "    def _sample_indices(self, record):\n",
        "        \"\"\"\n",
        "        :param record: VideoRecord\n",
        "        :return: list\n",
        "        \"\"\"\n",
        "        if self.dense_sample:  # i3d dense sample\n",
        "            sample_pos = max(1, 1 + record.num_frames - 64)\n",
        "            t_stride = 64 // self.num_segments\n",
        "            start_idx = 0 if sample_pos == 1 else np.random.randint(0, sample_pos - 1)\n",
        "            offsets = [(idx * t_stride + start_idx) % record.num_frames for idx in range(self.num_segments)]\n",
        "            return np.array(offsets) + 1\n",
        "        else:  # normal sample\n",
        "            average_duration = (record.num_frames - self.new_length + 1) // self.num_segments\n",
        "            if average_duration > 0:\n",
        "                offsets = np.multiply(list(range(self.num_segments)), average_duration) + randint(average_duration,\n",
        "                                                                                                  size=self.num_segments)\n",
        "            elif record.num_frames > self.num_segments:\n",
        "                offsets = np.sort(randint(record.num_frames - self.new_length + 1, size=self.num_segments))\n",
        "            else:\n",
        "                offsets = np.zeros((self.num_segments,))\n",
        "            return offsets + 1\n",
        "\n",
        "    def _get_val_indices(self, record):\n",
        "        if self.dense_sample:  # i3d dense sample\n",
        "            sample_pos = max(1, 1 + record.num_frames - 64)\n",
        "            t_stride = 64 // self.num_segments\n",
        "            start_idx = 0 if sample_pos == 1 else np.random.randint(0, sample_pos - 1)\n",
        "            offsets = [(idx * t_stride + start_idx) % record.num_frames for idx in range(self.num_segments)]\n",
        "            return np.array(offsets) + 1\n",
        "        else:\n",
        "            if record.num_frames > self.num_segments + self.new_length - 1:\n",
        "                tick = (record.num_frames - self.new_length + 1) / float(self.num_segments)\n",
        "                offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)])\n",
        "            else:\n",
        "                offsets = np.zeros((self.num_segments,))\n",
        "            return offsets + 1\n",
        "\n",
        "    def _get_test_indices(self, record):\n",
        "        if self.dense_sample:\n",
        "            sample_pos = max(1, 1 + record.num_frames - 64)\n",
        "            t_stride = 64 // self.num_segments\n",
        "            start_list = np.linspace(0, sample_pos - 1, num=10, dtype=int)\n",
        "            offsets = []\n",
        "            for start_idx in start_list.tolist():\n",
        "                offsets += [(idx * t_stride + start_idx) % record.num_frames for idx in range(self.num_segments)]\n",
        "            return np.array(offsets) + 1\n",
        "        elif self.twice_sample:\n",
        "            tick = (record.num_frames - self.new_length + 1) / float(self.num_segments)\n",
        "\n",
        "            offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)] +\n",
        "                               [int(tick * x) for x in range(self.num_segments)])\n",
        "\n",
        "            return offsets + 1\n",
        "        else:\n",
        "            tick = (record.num_frames - self.new_length + 1) / float(self.num_segments)\n",
        "            offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)])\n",
        "            return offsets + 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        record = self.video_list[index]\n",
        "        # check this is a legit video folder\n",
        "\n",
        "        if self.image_tmpl == 'flow_{}_{:05d}.jpg':\n",
        "            file_name = self.image_tmpl.format('x', 1)\n",
        "            full_path = os.path.join(self.root_path, record.path, file_name)\n",
        "        elif self.image_tmpl == '{:06d}-{}_{:05d}.jpg':\n",
        "            file_name = self.image_tmpl.format(int(record.path), 'x', 1)\n",
        "            full_path = os.path.join(self.root_path, '{:06d}'.format(int(record.path)), file_name)\n",
        "        else:\n",
        "            file_name = self.image_tmpl.format(1)\n",
        "            full_path = os.path.join(self.root_path, record.path, file_name)\n",
        "\n",
        "        while not os.path.exists(full_path):\n",
        "            print('################## Not Found:', os.path.join(self.root_path, record.path, file_name))\n",
        "            index = np.random.randint(len(self.video_list))\n",
        "            record = self.video_list[index]\n",
        "            if self.image_tmpl == 'flow_{}_{:05d}.jpg':\n",
        "                file_name = self.image_tmpl.format('x', 1)\n",
        "                full_path = os.path.join(self.root_path, record.path, file_name)\n",
        "            elif self.image_tmpl == '{:06d}-{}_{:05d}.jpg':\n",
        "                file_name = self.image_tmpl.format(int(record.path), 'x', 1)\n",
        "                full_path = os.path.join(self.root_path, '{:06d}'.format(int(record.path)), file_name)\n",
        "            else:\n",
        "                file_name = self.image_tmpl.format(1)\n",
        "                full_path = os.path.join(self.root_path, record.path, file_name)\n",
        "\n",
        "        if not self.test_mode:\n",
        "            segment_indices = self._sample_indices(record) if self.random_shift else self._get_val_indices(record)\n",
        "        else:\n",
        "            segment_indices = self._get_test_indices(record)\n",
        "        return self.get(record, segment_indices)\n",
        "\n",
        "    def get(self, record, indices):\n",
        "\n",
        "        images = list()\n",
        "        for seg_ind in indices:\n",
        "            p = int(seg_ind)\n",
        "            for i in range(self.new_length):\n",
        "                seg_imgs = self._load_image(record.path, p)\n",
        "                images.extend(seg_imgs)\n",
        "                if p < record.num_frames:\n",
        "                    p += 1\n",
        "\n",
        "        process_data = self.transform(images)\n",
        "        return process_data, record.label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpew5OSoX58E"
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Identity(torch.nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input\n",
        "\n",
        "\n",
        "class SegmentConsensus(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, consensus_type, dim=1):\n",
        "        super(SegmentConsensus, self).__init__()\n",
        "        self.consensus_type = consensus_type\n",
        "        self.dim = dim\n",
        "        self.shape = None\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        self.shape = input_tensor.size()\n",
        "        if self.consensus_type == 'avg':\n",
        "            output = input_tensor.mean(dim=self.dim, keepdim=True)\n",
        "        elif self.consensus_type == 'identity':\n",
        "            output = input_tensor\n",
        "        else:\n",
        "            output = None\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class ConsensusModule(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, consensus_type, dim=1):\n",
        "        super(ConsensusModule, self).__init__()\n",
        "        self.consensus_type = consensus_type if consensus_type != 'rnn' else 'identity'\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        return SegmentConsensus(self.consensus_type, self.dim)(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EGkhuQlYJi4",
        "outputId": "49ee10b3-8227-4c75-e84f-14e2f2e02ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "source": [
        "import torchvision\n",
        "import random\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import numbers\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "class GroupRandomCrop(object):\n",
        "    def __init__(self, size):\n",
        "        if isinstance(size, numbers.Number):\n",
        "            self.size = (int(size), int(size))\n",
        "        else:\n",
        "            self.size = size\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "\n",
        "        w, h = img_group[0].size\n",
        "        th, tw = self.size\n",
        "\n",
        "        out_images = list()\n",
        "\n",
        "        x1 = random.randint(0, w - tw)\n",
        "        y1 = random.randint(0, h - th)\n",
        "\n",
        "        for img in img_group:\n",
        "            assert(img.size[0] == w and img.size[1] == h)\n",
        "            if w == tw and h == th:\n",
        "                out_images.append(img)\n",
        "            else:\n",
        "                out_images.append(img.crop((x1, y1, x1 + tw, y1 + th)))\n",
        "\n",
        "        return out_images\n",
        "\n",
        "\n",
        "class GroupCenterCrop(object):\n",
        "    def __init__(self, size):\n",
        "        self.worker = torchvision.transforms.CenterCrop(size)\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "        return [self.worker(img) for img in img_group]\n",
        "\n",
        "\n",
        "class GroupRandomHorizontalFlip(object):\n",
        "    \"\"\"Randomly horizontally flips the given PIL.Image with a probability of 0.5\n",
        "    \"\"\"\n",
        "    def __init__(self, is_flow=False):\n",
        "        self.is_flow = is_flow\n",
        "\n",
        "    def __call__(self, img_group, is_flow=False):\n",
        "        v = random.random()\n",
        "        if v < 0.5:\n",
        "            ret = [img.transpose(Image.FLIP_LEFT_RIGHT) for img in img_group]\n",
        "            if self.is_flow:\n",
        "                for i in range(0, len(ret), 2):\n",
        "                    ret[i] = ImageOps.invert(ret[i])  # invert flow pixel values when flipping\n",
        "            return ret\n",
        "        else:\n",
        "            return img_group\n",
        "\n",
        "\n",
        "class GroupNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        rep_mean = self.mean * (tensor.size()[0]//len(self.mean))\n",
        "        rep_std = self.std * (tensor.size()[0]//len(self.std))\n",
        "\n",
        "        # TODO: make efficient\n",
        "        for t, m, s in zip(tensor, rep_mean, rep_std):\n",
        "            t.sub_(m).div_(s)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class GroupScale(object):\n",
        "    \"\"\" Rescales the input PIL.Image to the given 'size'.\n",
        "    'size' will be the size of the smaller edge.\n",
        "    For example, if height > width, then image will be\n",
        "    rescaled to (size * height / width, size)\n",
        "    size: size of the smaller edge\n",
        "    interpolation: Default: PIL.Image.BILINEAR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
        "        self.worker = torchvision.transforms.Resize(size, interpolation)\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "        return [self.worker(img) for img in img_group]\n",
        "\n",
        "\n",
        "class GroupOverSample(object):\n",
        "    def __init__(self, crop_size, scale_size=None, flip=True):\n",
        "        self.crop_size = crop_size if not isinstance(crop_size, int) else (crop_size, crop_size)\n",
        "\n",
        "        if scale_size is not None:\n",
        "            self.scale_worker = GroupScale(scale_size)\n",
        "        else:\n",
        "            self.scale_worker = None\n",
        "        self.flip = flip\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "\n",
        "        if self.scale_worker is not None:\n",
        "            img_group = self.scale_worker(img_group)\n",
        "\n",
        "        image_w, image_h = img_group[0].size\n",
        "        crop_w, crop_h = self.crop_size\n",
        "\n",
        "        offsets = GroupMultiScaleCrop.fill_fix_offset(False, image_w, image_h, crop_w, crop_h)\n",
        "        oversample_group = list()\n",
        "        for o_w, o_h in offsets:\n",
        "            normal_group = list()\n",
        "            flip_group = list()\n",
        "            for i, img in enumerate(img_group):\n",
        "                crop = img.crop((o_w, o_h, o_w + crop_w, o_h + crop_h))\n",
        "                normal_group.append(crop)\n",
        "                flip_crop = crop.copy().transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "                if img.mode == 'L' and i % 2 == 0:\n",
        "                    flip_group.append(ImageOps.invert(flip_crop))\n",
        "                else:\n",
        "                    flip_group.append(flip_crop)\n",
        "\n",
        "            oversample_group.extend(normal_group)\n",
        "            if self.flip:\n",
        "                oversample_group.extend(flip_group)\n",
        "        return oversample_group\n",
        "\n",
        "\n",
        "class GroupFullResSample(object):\n",
        "    def __init__(self, crop_size, scale_size=None, flip=True):\n",
        "        self.crop_size = crop_size if not isinstance(crop_size, int) else (crop_size, crop_size)\n",
        "\n",
        "        if scale_size is not None:\n",
        "            self.scale_worker = GroupScale(scale_size)\n",
        "        else:\n",
        "            self.scale_worker = None\n",
        "        self.flip = flip\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "\n",
        "        if self.scale_worker is not None:\n",
        "            img_group = self.scale_worker(img_group)\n",
        "\n",
        "        image_w, image_h = img_group[0].size\n",
        "        crop_w, crop_h = self.crop_size\n",
        "\n",
        "        w_step = (image_w - crop_w) // 4\n",
        "        h_step = (image_h - crop_h) // 4\n",
        "\n",
        "        offsets = list()\n",
        "        offsets.append((0 * w_step, 2 * h_step))  # left\n",
        "        offsets.append((4 * w_step, 2 * h_step))  # right\n",
        "        offsets.append((2 * w_step, 2 * h_step))  # center\n",
        "\n",
        "        oversample_group = list()\n",
        "        for o_w, o_h in offsets:\n",
        "            normal_group = list()\n",
        "            flip_group = list()\n",
        "            for i, img in enumerate(img_group):\n",
        "                crop = img.crop((o_w, o_h, o_w + crop_w, o_h + crop_h))\n",
        "                normal_group.append(crop)\n",
        "                if self.flip:\n",
        "                    flip_crop = crop.copy().transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "                    if img.mode == 'L' and i % 2 == 0:\n",
        "                        flip_group.append(ImageOps.invert(flip_crop))\n",
        "                    else:\n",
        "                        flip_group.append(flip_crop)\n",
        "\n",
        "            oversample_group.extend(normal_group)\n",
        "            oversample_group.extend(flip_group)\n",
        "        return oversample_group\n",
        "\n",
        "\n",
        "class GroupMultiScaleCrop(object):\n",
        "\n",
        "    def __init__(self, input_size, scales=None, max_distort=1, fix_crop=True, more_fix_crop=True):\n",
        "        self.scales = scales if scales is not None else [1, .875, .75, .66]\n",
        "        self.max_distort = max_distort\n",
        "        self.fix_crop = fix_crop\n",
        "        self.more_fix_crop = more_fix_crop\n",
        "        self.input_size = input_size if not isinstance(input_size, int) else [input_size, input_size]\n",
        "        self.interpolation = Image.BILINEAR\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "\n",
        "        im_size = img_group[0].size\n",
        "\n",
        "        crop_w, crop_h, offset_w, offset_h = self._sample_crop_size(im_size)\n",
        "        crop_img_group = [img.crop((offset_w, offset_h, offset_w + crop_w, offset_h + crop_h)) for img in img_group]\n",
        "        ret_img_group = [img.resize((self.input_size[0], self.input_size[1]), self.interpolation)\n",
        "                         for img in crop_img_group]\n",
        "        return ret_img_group\n",
        "\n",
        "    def _sample_crop_size(self, im_size):\n",
        "        image_w, image_h = im_size[0], im_size[1]\n",
        "\n",
        "        # find a crop size\n",
        "        base_size = min(image_w, image_h)\n",
        "        crop_sizes = [int(base_size * x) for x in self.scales]\n",
        "        crop_h = [self.input_size[1] if abs(x - self.input_size[1]) < 3 else x for x in crop_sizes]\n",
        "        crop_w = [self.input_size[0] if abs(x - self.input_size[0]) < 3 else x for x in crop_sizes]\n",
        "\n",
        "        pairs = []\n",
        "        for i, h in enumerate(crop_h):\n",
        "            for j, w in enumerate(crop_w):\n",
        "                if abs(i - j) <= self.max_distort:\n",
        "                    pairs.append((w, h))\n",
        "\n",
        "        crop_pair = random.choice(pairs)\n",
        "        if not self.fix_crop:\n",
        "            w_offset = random.randint(0, image_w - crop_pair[0])\n",
        "            h_offset = random.randint(0, image_h - crop_pair[1])\n",
        "        else:\n",
        "            w_offset, h_offset = self._sample_fix_offset(image_w, image_h, crop_pair[0], crop_pair[1])\n",
        "\n",
        "        return crop_pair[0], crop_pair[1], w_offset, h_offset\n",
        "\n",
        "    def _sample_fix_offset(self, image_w, image_h, crop_w, crop_h):\n",
        "        offsets = self.fill_fix_offset(self.more_fix_crop, image_w, image_h, crop_w, crop_h)\n",
        "        return random.choice(offsets)\n",
        "\n",
        "    @staticmethod\n",
        "    def fill_fix_offset(more_fix_crop, image_w, image_h, crop_w, crop_h):\n",
        "        w_step = (image_w - crop_w) // 4\n",
        "        h_step = (image_h - crop_h) // 4\n",
        "\n",
        "        ret = list()\n",
        "        ret.append((0, 0))  # upper left\n",
        "        ret.append((4 * w_step, 0))  # upper right\n",
        "        ret.append((0, 4 * h_step))  # lower left\n",
        "        ret.append((4 * w_step, 4 * h_step))  # lower right\n",
        "        ret.append((2 * w_step, 2 * h_step))  # center\n",
        "\n",
        "        if more_fix_crop:\n",
        "            ret.append((0, 2 * h_step))  # center left\n",
        "            ret.append((4 * w_step, 2 * h_step))  # center right\n",
        "            ret.append((2 * w_step, 4 * h_step))  # lower center\n",
        "            ret.append((2 * w_step, 0 * h_step))  # upper center\n",
        "\n",
        "            ret.append((1 * w_step, 1 * h_step))  # upper left quarter\n",
        "            ret.append((3 * w_step, 1 * h_step))  # upper right quarter\n",
        "            ret.append((1 * w_step, 3 * h_step))  # lower left quarter\n",
        "            ret.append((3 * w_step, 3 * h_step))  # lower righ quarter\n",
        "\n",
        "        return ret\n",
        "\n",
        "\n",
        "class GroupRandomSizedCrop(object):\n",
        "    \"\"\"Random crop the given PIL.Image to a random size of (0.08 to 1.0) of the original size\n",
        "    and and a random aspect ratio of 3/4 to 4/3 of the original aspect ratio\n",
        "    This is popularly used to train the Inception networks\n",
        "    size: size of the smaller edge\n",
        "    interpolation: Default: PIL.Image.BILINEAR\n",
        "    \"\"\"\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "        for attempt in range(10):\n",
        "            area = img_group[0].size[0] * img_group[0].size[1]\n",
        "            target_area = random.uniform(0.08, 1.0) * area\n",
        "            aspect_ratio = random.uniform(3. / 4, 4. / 3)\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                w, h = h, w\n",
        "\n",
        "            if w <= img_group[0].size[0] and h <= img_group[0].size[1]:\n",
        "                x1 = random.randint(0, img_group[0].size[0] - w)\n",
        "                y1 = random.randint(0, img_group[0].size[1] - h)\n",
        "                found = True\n",
        "                break\n",
        "        else:\n",
        "            found = False\n",
        "            x1 = 0\n",
        "            y1 = 0\n",
        "\n",
        "        if found:\n",
        "            out_group = list()\n",
        "            for img in img_group:\n",
        "                img = img.crop((x1, y1, x1 + w, y1 + h))\n",
        "                assert(img.size == (w, h))\n",
        "                out_group.append(img.resize((self.size, self.size), self.interpolation))\n",
        "            return out_group\n",
        "        else:\n",
        "            # Fallback\n",
        "            scale = GroupScale(self.size, interpolation=self.interpolation)\n",
        "            crop = GroupRandomCrop(self.size)\n",
        "            return crop(scale(img_group))\n",
        "\n",
        "\n",
        "class Stack(object):\n",
        "\n",
        "    def __init__(self, roll=False):\n",
        "        self.roll = roll\n",
        "\n",
        "    def __call__(self, img_group):\n",
        "        if img_group[0].mode == 'L':\n",
        "            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n",
        "        elif img_group[0].mode == 'RGB':\n",
        "            if self.roll:\n",
        "                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
        "            else:\n",
        "                return np.concatenate(img_group, axis=2)\n",
        "\n",
        "\n",
        "class ToTorchFormatTensor(object):\n",
        "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
        "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
        "    def __init__(self, div=True):\n",
        "        self.div = div\n",
        "\n",
        "    def __call__(self, pic):\n",
        "        if isinstance(pic, np.ndarray):\n",
        "            # handle numpy array\n",
        "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
        "        else:\n",
        "            # handle PIL Image\n",
        "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
        "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
        "            # put it from HWC to CHW format\n",
        "            # yikes, this transpose takes 80% of the loading time/CPU\n",
        "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
        "        return img.float().div(255) if self.div else img.float()\n",
        "\n",
        "\n",
        "class IdentityTransform(object):\n",
        "\n",
        "    def __call__(self, data):\n",
        "        return data\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    trans = torchvision.transforms.Compose([\n",
        "        GroupScale(256),\n",
        "        GroupRandomCrop(224),\n",
        "        Stack(),\n",
        "        ToTorchFormatTensor(),\n",
        "        GroupNormalize(\n",
        "            mean=[.485, .456, .406],\n",
        "            std=[.229, .224, .225]\n",
        "        )]\n",
        "    )\n",
        "\n",
        "    im = Image.open('./frames/blowing_candles/1/img_00001.jpg')\n",
        "\n",
        "    color_group = [im] * 3\n",
        "    rst = trans(color_group)\n",
        "\n",
        "    gray_group = [im.convert('L')] * 9\n",
        "    gray_rst = trans(gray_group)\n",
        "\n",
        "    trans2 = torchvision.transforms.Compose([\n",
        "        GroupRandomSizedCrop(256),\n",
        "        Stack(),\n",
        "        ToTorchFormatTensor(),\n",
        "        GroupNormalize(\n",
        "            mean=[.485, .456, .406],\n",
        "            std=[.229, .224, .225])\n",
        "    ])\n",
        "    print(trans2(color_group))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.4954,  1.4954,  1.4954,  ...,  2.2318,  2.2147,  2.2147],\n",
            "         [ 1.4954,  1.4954,  1.4954,  ...,  2.2147,  2.2147,  2.2147],\n",
            "         [ 1.4954,  1.4954,  1.4954,  ...,  2.1119,  2.1119,  2.1119],\n",
            "         ...,\n",
            "         [ 1.4440,  1.5125,  1.5468,  ..., -1.7069, -1.8097, -2.0323],\n",
            "         [ 1.6153,  1.6153,  1.6667,  ..., -1.7412, -1.9124, -2.0665],\n",
            "         [ 1.3584,  1.4269,  1.4612,  ..., -1.7583, -1.9467, -2.0494]],\n",
            "\n",
            "        [[ 1.4832,  1.4832,  1.4832,  ...,  2.4286,  2.4286,  2.4286],\n",
            "         [ 1.4832,  1.4832,  1.4832,  ...,  2.4286,  2.4286,  2.4286],\n",
            "         [ 1.4832,  1.4832,  1.4832,  ...,  2.3235,  2.3235,  2.3235],\n",
            "         ...,\n",
            "         [-1.1779, -1.1954, -1.1954,  ..., -0.1275, -0.4776, -1.0553],\n",
            "         [-1.2829, -1.4055, -1.4405,  ..., -0.1099, -0.5126, -1.0553],\n",
            "         [-1.2829, -1.3529, -1.4055,  ..., -0.0574, -0.4951, -1.0728]],\n",
            "\n",
            "        [[ 1.5245,  1.5245,  1.5245,  ...,  2.5703,  2.5529,  2.5529],\n",
            "         [ 1.5245,  1.5245,  1.5245,  ...,  2.5529,  2.5529,  2.5529],\n",
            "         [ 1.5245,  1.5245,  1.5245,  ...,  2.4483,  2.4483,  2.4483],\n",
            "         ...,\n",
            "         [-0.8981, -0.8981, -0.8981,  ..., -0.4450, -0.6890, -1.1247],\n",
            "         [-0.9853, -1.0376, -1.0550,  ..., -0.4275, -0.7587, -1.1421],\n",
            "         [-1.1421, -1.2293, -1.2990,  ..., -0.4101, -0.7587, -1.1421]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.4954,  1.4954,  1.4954,  ...,  2.2318,  2.2147,  2.2147],\n",
            "         [ 1.4954,  1.4954,  1.4954,  ...,  2.2147,  2.2147,  2.2147],\n",
            "         [ 1.4954,  1.4954,  1.4954,  ...,  2.1119,  2.1119,  2.1119],\n",
            "         ...,\n",
            "         [ 1.4440,  1.5125,  1.5468,  ..., -1.7069, -1.8097, -2.0323],\n",
            "         [ 1.6153,  1.6153,  1.6667,  ..., -1.7412, -1.9124, -2.0665],\n",
            "         [ 1.3584,  1.4269,  1.4612,  ..., -1.7583, -1.9467, -2.0494]],\n",
            "\n",
            "        [[ 1.4832,  1.4832,  1.4832,  ...,  2.4286,  2.4286,  2.4286],\n",
            "         [ 1.4832,  1.4832,  1.4832,  ...,  2.4286,  2.4286,  2.4286],\n",
            "         [ 1.4832,  1.4832,  1.4832,  ...,  2.3235,  2.3235,  2.3235],\n",
            "         ...,\n",
            "         [-1.1779, -1.1954, -1.1954,  ..., -0.1275, -0.4776, -1.0553],\n",
            "         [-1.2829, -1.4055, -1.4405,  ..., -0.1099, -0.5126, -1.0553],\n",
            "         [-1.2829, -1.3529, -1.4055,  ..., -0.0574, -0.4951, -1.0728]],\n",
            "\n",
            "        [[ 1.5245,  1.5245,  1.5245,  ...,  2.5703,  2.5529,  2.5529],\n",
            "         [ 1.5245,  1.5245,  1.5245,  ...,  2.5529,  2.5529,  2.5529],\n",
            "         [ 1.5245,  1.5245,  1.5245,  ...,  2.4483,  2.4483,  2.4483],\n",
            "         ...,\n",
            "         [-0.8981, -0.8981, -0.8981,  ..., -0.4450, -0.6890, -1.1247],\n",
            "         [-0.9853, -1.0376, -1.0550,  ..., -0.4275, -0.7587, -1.1421],\n",
            "         [-1.1421, -1.2293, -1.2990,  ..., -0.4101, -0.7587, -1.1421]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaiBWYwmC1z"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "from torch.nn.init import normal_, constant_\n",
        "\n",
        "\n",
        "class TSN(nn.Module):\n",
        "    def __init__(self, num_class, num_segments, modality,\n",
        "                 base_model='mobilenetv2', new_length=None,\n",
        "                 consensus_type='avg', before_softmax=True,\n",
        "                 dropout=0.8, img_feature_dim=256,\n",
        "                 crop_num=1, partial_bn=True, print_spec=True, pretrain='imagenet',\n",
        "                 is_shift=False, shift_div=8, shift_place='blockres', fc_lr5=False,\n",
        "                 temporal_pool=False, non_local=False):\n",
        "        super(TSN, self).__init__()\n",
        "        self.modality = modality\n",
        "        self.num_segments = num_segments\n",
        "        self.reshape = True\n",
        "        self.before_softmax = before_softmax\n",
        "        self.dropout = dropout\n",
        "        self.crop_num = crop_num\n",
        "        self.consensus_type = consensus_type\n",
        "        self.img_feature_dim = img_feature_dim  # the dimension of the CNN feature to represent each frame\n",
        "        self.pretrain = pretrain\n",
        "\n",
        "        self.is_shift = is_shift\n",
        "        self.shift_div = shift_div\n",
        "        self.shift_place = shift_place\n",
        "        self.base_model_name = base_model\n",
        "        self.fc_lr5 = fc_lr5\n",
        "        self.temporal_pool = temporal_pool\n",
        "        self.non_local = non_local\n",
        "\n",
        "        if not before_softmax and consensus_type != 'avg':\n",
        "            raise ValueError(\"Only avg consensus can be used after Softmax\")\n",
        "\n",
        "        if new_length is None:\n",
        "            self.new_length = 1 if modality == \"RGB\" else 5\n",
        "        else:\n",
        "            self.new_length = new_length\n",
        "        if print_spec:\n",
        "            print((\"\"\"\n",
        "    Initializing TSN with base model: {}.\n",
        "    TSN Configurations:\n",
        "        input_modality:     {}\n",
        "        num_segments:       {}\n",
        "        new_length:         {}\n",
        "        consensus_module:   {}\n",
        "        dropout_ratio:      {}\n",
        "        img_feature_dim:    {}\n",
        "            \"\"\".format(base_model, self.modality, self.num_segments, self.new_length, consensus_type, self.dropout, self.img_feature_dim)))\n",
        "\n",
        "        self._prepare_base_model(base_model)\n",
        "\n",
        "        feature_dim = self._prepare_tsn(num_class)\n",
        "\n",
        "        if self.modality == 'Flow':\n",
        "            print(\"Converting the ImageNet model to a flow init model\")\n",
        "            self.base_model = self._construct_flow_model(self.base_model)\n",
        "            print(\"Done. Flow model ready...\")\n",
        "        elif self.modality == 'RGBDiff':\n",
        "            print(\"Converting the ImageNet model to RGB+Diff init model\")\n",
        "            self.base_model = self._construct_diff_model(self.base_model)\n",
        "            print(\"Done. RGBDiff model ready.\")\n",
        "\n",
        "        self.consensus = ConsensusModule(consensus_type)\n",
        "\n",
        "        if not self.before_softmax:\n",
        "            self.softmax = nn.Softmax()\n",
        "\n",
        "        self._enable_pbn = partial_bn\n",
        "        if partial_bn:\n",
        "            self.partialBN(True)\n",
        "\n",
        "    def _prepare_tsn(self, num_class):\n",
        "        feature_dim = getattr(self.base_model, self.base_model.last_layer_name).in_features\n",
        "        if self.dropout == 0:\n",
        "            setattr(self.base_model, self.base_model.last_layer_name, nn.Linear(feature_dim, num_class))\n",
        "            self.new_fc = None\n",
        "        else:\n",
        "            setattr(self.base_model, self.base_model.last_layer_name, nn.Dropout(p=self.dropout))\n",
        "            self.new_fc = nn.Linear(feature_dim, num_class)\n",
        "\n",
        "        std = 0.001\n",
        "        if self.new_fc is None:\n",
        "            normal_(getattr(self.base_model, self.base_model.last_layer_name).weight, 0, std)\n",
        "            constant_(getattr(self.base_model, self.base_model.last_layer_name).bias, 0)\n",
        "        else:\n",
        "            if hasattr(self.new_fc, 'weight'):\n",
        "                normal_(self.new_fc.weight, 0, std)\n",
        "                constant_(self.new_fc.bias, 0)\n",
        "        return feature_dim\n",
        "\n",
        "    def _prepare_base_model(self, base_model):\n",
        "        print('=> base model: {}'.format(base_model))\n",
        "\n",
        "        if 'resnet' in base_model:\n",
        "            self.base_model = getattr(torchvision.models, base_model)(True if self.pretrain == 'imagenet' else False)\n",
        "            if self.is_shift:\n",
        "                print('Adding temporal shift...')\n",
        "                make_temporal_shift(self.base_model, self.num_segments,\n",
        "                                    n_div=self.shift_div, place=self.shift_place, temporal_pool=self.temporal_pool)\n",
        "\n",
        "            if self.non_local:\n",
        "                print('Adding non-local module...')\n",
        "                make_non_local(self.base_model, self.num_segments)\n",
        "\n",
        "            self.base_model.last_layer_name = 'fc'\n",
        "            self.input_size = 224\n",
        "            self.input_mean = [0.485, 0.456, 0.406]\n",
        "            self.input_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "            self.base_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "            if self.modality == 'Flow':\n",
        "                self.input_mean = [0.5]\n",
        "                self.input_std = [np.mean(self.input_std)]\n",
        "            elif self.modality == 'RGBDiff':\n",
        "                self.input_mean = [0.485, 0.456, 0.406] + [0] * 3 * self.new_length\n",
        "                self.input_std = self.input_std + [np.mean(self.input_std) * 2] * 3 * self.new_length\n",
        "\n",
        "        elif base_model == 'mobilenetv2':\n",
        "            self.base_model = mobilenet_v2(True if self.pretrain == 'imagenet' else False)\n",
        "\n",
        "            self.base_model.last_layer_name = 'classifier'\n",
        "            self.input_size = 224\n",
        "            self.input_mean = [0.485, 0.456, 0.406]\n",
        "            self.input_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "            self.base_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "            if self.is_shift:\n",
        "                for m in self.base_model.modules():\n",
        "                    if isinstance(m, InvertedResidual) and len(m.conv) == 8 and m.use_res_connect:\n",
        "                        if True:\n",
        "                            print('Adding temporal shift... {}'.format(m.use_res_connect))\n",
        "                        m.conv[0] = TemporalShift(m.conv[0], n_segment=self.num_segments, n_div=self.shift_div)\n",
        "            if self.modality == 'Flow':\n",
        "                self.input_mean = [0.5]\n",
        "                self.input_std = [np.mean(self.input_std)]\n",
        "            elif self.modality == 'RGBDiff':\n",
        "                self.input_mean = [0.485, 0.456, 0.406] + [0] * 3 * self.new_length\n",
        "                self.input_std = self.input_std + [np.mean(self.input_std) * 2] * 3 * self.new_length\n",
        "\n",
        "        elif base_model == 'BNInception':\n",
        "            self.base_model = bninception(pretrained=self.pretrain)\n",
        "            self.input_size = self.base_model.input_size\n",
        "            self.input_mean = self.base_model.mean\n",
        "            self.input_std = self.base_model.std\n",
        "            self.base_model.last_layer_name = 'fc'\n",
        "            if self.modality == 'Flow':\n",
        "                self.input_mean = [128]\n",
        "            elif self.modality == 'RGBDiff':\n",
        "                self.input_mean = self.input_mean * (1 + self.new_length)\n",
        "            if self.is_shift:\n",
        "                print('Adding temporal shift...')\n",
        "                self.base_model.build_temporal_ops(\n",
        "                    self.num_segments, is_temporal_shift=self.shift_place, shift_div=self.shift_div)\n",
        "        else:\n",
        "            raise ValueError('Unknown base model: {}'.format(base_model))\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        \"\"\"\n",
        "        Override the default train() to freeze the BN parameters\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        super(TSN, self).train(mode)\n",
        "        count = 0\n",
        "        if self._enable_pbn and mode:\n",
        "            print(\"Freezing BatchNorm2D except the first one.\")\n",
        "            for m in self.base_model.modules():\n",
        "                if isinstance(m, nn.BatchNorm2d):\n",
        "                    count += 1\n",
        "                    if count >= (2 if self._enable_pbn else 1):\n",
        "                        m.eval()\n",
        "                        # shutdown update in frozen mode\n",
        "                        m.weight.requires_grad = False\n",
        "                        m.bias.requires_grad = False\n",
        "\n",
        "    def partialBN(self, enable):\n",
        "        self._enable_pbn = enable\n",
        "\n",
        "    def get_optim_policies(self):\n",
        "        first_conv_weight = []\n",
        "        first_conv_bias = []\n",
        "        normal_weight = []\n",
        "        normal_bias = []\n",
        "        lr5_weight = []\n",
        "        lr10_bias = []\n",
        "        bn = []\n",
        "        custom_ops = []\n",
        "\n",
        "        conv_cnt = 0\n",
        "        bn_cnt = 0\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Conv1d) or isinstance(m, torch.nn.Conv3d):\n",
        "                ps = list(m.parameters())\n",
        "                conv_cnt += 1\n",
        "                if conv_cnt == 1:\n",
        "                    first_conv_weight.append(ps[0])\n",
        "                    if len(ps) == 2:\n",
        "                        first_conv_bias.append(ps[1])\n",
        "                else:\n",
        "                    normal_weight.append(ps[0])\n",
        "                    if len(ps) == 2:\n",
        "                        normal_bias.append(ps[1])\n",
        "            elif isinstance(m, torch.nn.Linear):\n",
        "                ps = list(m.parameters())\n",
        "                if self.fc_lr5:\n",
        "                    lr5_weight.append(ps[0])\n",
        "                else:\n",
        "                    normal_weight.append(ps[0])\n",
        "                if len(ps) == 2:\n",
        "                    if self.fc_lr5:\n",
        "                        lr10_bias.append(ps[1])\n",
        "                    else:\n",
        "                        normal_bias.append(ps[1])\n",
        "\n",
        "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
        "                bn_cnt += 1\n",
        "                # later BN's are frozen\n",
        "                if not self._enable_pbn or bn_cnt == 1:\n",
        "                    bn.extend(list(m.parameters()))\n",
        "            elif isinstance(m, torch.nn.BatchNorm3d):\n",
        "                bn_cnt += 1\n",
        "                # later BN's are frozen\n",
        "                if not self._enable_pbn or bn_cnt == 1:\n",
        "                    bn.extend(list(m.parameters()))\n",
        "            elif len(m._modules) == 0:\n",
        "                if len(list(m.parameters())) > 0:\n",
        "                    raise ValueError(\"New atomic module type: {}. Need to give it a learning policy\".format(type(m)))\n",
        "\n",
        "        return [\n",
        "            {'params': first_conv_weight, 'lr_mult': 5 if self.modality == 'Flow' else 1, 'decay_mult': 1,\n",
        "             'name': \"first_conv_weight\"},\n",
        "            {'params': first_conv_bias, 'lr_mult': 10 if self.modality == 'Flow' else 2, 'decay_mult': 0,\n",
        "             'name': \"first_conv_bias\"},\n",
        "            {'params': normal_weight, 'lr_mult': 1, 'decay_mult': 1,\n",
        "             'name': \"normal_weight\"},\n",
        "            {'params': normal_bias, 'lr_mult': 2, 'decay_mult': 0,\n",
        "             'name': \"normal_bias\"},\n",
        "            {'params': bn, 'lr_mult': 1, 'decay_mult': 0,\n",
        "             'name': \"BN scale/shift\"},\n",
        "            {'params': custom_ops, 'lr_mult': 1, 'decay_mult': 1,\n",
        "             'name': \"custom_ops\"},\n",
        "            # for fc\n",
        "            {'params': lr5_weight, 'lr_mult': 5, 'decay_mult': 1,\n",
        "             'name': \"lr5_weight\"},\n",
        "            {'params': lr10_bias, 'lr_mult': 10, 'decay_mult': 0,\n",
        "             'name': \"lr10_bias\"},\n",
        "        ]\n",
        "\n",
        "    def forward(self, input, no_reshape=False):\n",
        "        if not no_reshape:\n",
        "            sample_len = (3 if self.modality == \"RGB\" else 2) * self.new_length\n",
        "\n",
        "            if self.modality == 'RGBDiff':\n",
        "                sample_len = 3 * self.new_length\n",
        "                input = self._get_diff(input)\n",
        "\n",
        "            base_out = self.base_model(input.view((-1, sample_len) + input.size()[-2:]))\n",
        "        else:\n",
        "            base_out = self.base_model(input)\n",
        "\n",
        "        if self.dropout > 0:\n",
        "            base_out = self.new_fc(base_out)\n",
        "\n",
        "        if not self.before_softmax:\n",
        "            base_out = self.softmax(base_out)\n",
        "\n",
        "        if self.reshape:\n",
        "            if self.is_shift and self.temporal_pool:\n",
        "                base_out = base_out.view((-1, self.num_segments // 2) + base_out.size()[1:])\n",
        "            else:\n",
        "                base_out = base_out.view((-1, self.num_segments) + base_out.size()[1:])\n",
        "            output = self.consensus(base_out)\n",
        "            return output.squeeze(1)\n",
        "\n",
        "    def _get_diff(self, input, keep_rgb=False):\n",
        "        input_c = 3 if self.modality in [\"RGB\", \"RGBDiff\"] else 2\n",
        "        input_view = input.view((-1, self.num_segments, self.new_length + 1, input_c,) + input.size()[2:])\n",
        "        if keep_rgb:\n",
        "            new_data = input_view.clone()\n",
        "        else:\n",
        "            new_data = input_view[:, :, 1:, :, :, :].clone()\n",
        "\n",
        "        for x in reversed(list(range(1, self.new_length + 1))):\n",
        "            if keep_rgb:\n",
        "                new_data[:, :, x, :, :, :] = input_view[:, :, x, :, :, :] - input_view[:, :, x - 1, :, :, :]\n",
        "            else:\n",
        "                new_data[:, :, x - 1, :, :, :] = input_view[:, :, x, :, :, :] - input_view[:, :, x - 1, :, :, :]\n",
        "\n",
        "        return new_data\n",
        "\n",
        "    def _construct_flow_model(self, base_model):\n",
        "        # modify the convolution layers\n",
        "        # Torch models are usually defined in a hierarchical way.\n",
        "        # nn.modules.children() return all sub modules in a DFS manner\n",
        "        modules = list(self.base_model.modules())\n",
        "        first_conv_idx = list(filter(lambda x: isinstance(modules[x], nn.Conv2d), list(range(len(modules)))))[0]\n",
        "        conv_layer = modules[first_conv_idx]\n",
        "        container = modules[first_conv_idx - 1]\n",
        "\n",
        "        # modify parameters, assume the first blob contains the convolution kernels\n",
        "        params = [x.clone() for x in conv_layer.parameters()]\n",
        "        kernel_size = params[0].size()\n",
        "        new_kernel_size = kernel_size[:1] + (2 * self.new_length, ) + kernel_size[2:]\n",
        "        new_kernels = params[0].data.mean(dim=1, keepdim=True).expand(new_kernel_size).contiguous()\n",
        "\n",
        "        new_conv = nn.Conv2d(2 * self.new_length, conv_layer.out_channels,\n",
        "                             conv_layer.kernel_size, conv_layer.stride, conv_layer.padding,\n",
        "                             bias=True if len(params) == 2 else False)\n",
        "        new_conv.weight.data = new_kernels\n",
        "        if len(params) == 2:\n",
        "            new_conv.bias.data = params[1].data # add bias if neccessary\n",
        "        layer_name = list(container.state_dict().keys())[0][:-7] # remove .weight suffix to get the layer name\n",
        "\n",
        "        # replace the first convlution layer\n",
        "        setattr(container, layer_name, new_conv)\n",
        "\n",
        "        if self.base_model_name == 'BNInception':\n",
        "            import torch.utils.model_zoo as model_zoo\n",
        "            sd = model_zoo.load_url('https://www.dropbox.com/s/35ftw2t4mxxgjae/BNInceptionFlow-ef652051.pth.tar?dl=1')\n",
        "            base_model.load_state_dict(sd)\n",
        "            print('=> Loading pretrained Flow weight done...')\n",
        "        else:\n",
        "            print('#' * 30, 'Warning! No Flow pretrained model is found')\n",
        "        return base_model\n",
        "\n",
        "    def _construct_diff_model(self, base_model, keep_rgb=False):\n",
        "        # modify the convolution layers\n",
        "        # Torch models are usually defined in a hierarchical way.\n",
        "        # nn.modules.children() return all sub modules in a DFS manner\n",
        "        modules = list(self.base_model.modules())\n",
        "        first_conv_idx = filter(lambda x: isinstance(modules[x], nn.Conv2d), list(range(len(modules))))[0]\n",
        "        conv_layer = modules[first_conv_idx]\n",
        "        container = modules[first_conv_idx - 1]\n",
        "\n",
        "        # modify parameters, assume the first blob contains the convolution kernels\n",
        "        params = [x.clone() for x in conv_layer.parameters()]\n",
        "        kernel_size = params[0].size()\n",
        "        if not keep_rgb:\n",
        "            new_kernel_size = kernel_size[:1] + (3 * self.new_length,) + kernel_size[2:]\n",
        "            new_kernels = params[0].data.mean(dim=1, keepdim=True).expand(new_kernel_size).contiguous()\n",
        "        else:\n",
        "            new_kernel_size = kernel_size[:1] + (3 * self.new_length,) + kernel_size[2:]\n",
        "            new_kernels = torch.cat((params[0].data, params[0].data.mean(dim=1, keepdim=True).expand(new_kernel_size).contiguous()),\n",
        "                                    1)\n",
        "            new_kernel_size = kernel_size[:1] + (3 + 3 * self.new_length,) + kernel_size[2:]\n",
        "\n",
        "        new_conv = nn.Conv2d(new_kernel_size[1], conv_layer.out_channels,\n",
        "                             conv_layer.kernel_size, conv_layer.stride, conv_layer.padding,\n",
        "                             bias=True if len(params) == 2 else False)\n",
        "        new_conv.weight.data = new_kernels\n",
        "        if len(params) == 2:\n",
        "            new_conv.bias.data = params[1].data  # add bias if neccessary\n",
        "        layer_name = list(container.state_dict().keys())[0][:-7]  # remove .weight suffix to get the layer name\n",
        "\n",
        "        # replace the first convolution layer\n",
        "        setattr(container, layer_name, new_conv)\n",
        "        return base_model\n",
        "\n",
        "    @property\n",
        "    def crop_size(self):\n",
        "        return self.input_size\n",
        "\n",
        "    @property\n",
        "    def scale_size(self):\n",
        "        return self.input_size * 256 // 224\n",
        "\n",
        "    def get_augmentation(self, flip=True):\n",
        "        if self.modality == 'RGB':\n",
        "            if flip:\n",
        "                return torchvision.transforms.Compose([GroupMultiScaleCrop(self.input_size, [1, .875, .75, .66]),\n",
        "                                                       GroupRandomHorizontalFlip(is_flow=False)])\n",
        "            else:\n",
        "                print('#' * 20, 'NO FLIP!!!')\n",
        "                return torchvision.transforms.Compose([GroupMultiScaleCrop(self.input_size, [1, .875, .75, .66])])\n",
        "        elif self.modality == 'Flow':\n",
        "            return torchvision.transforms.Compose([GroupMultiScaleCrop(self.input_size, [1, .875, .75]),\n",
        "                                                   GroupRandomHorizontalFlip(is_flow=True)])\n",
        "        elif self.modality == 'RGBDiff':\n",
        "            return torchvision.transforms.Compose([GroupMultiScaleCrop(self.input_size, [1, .875, .75]),\n",
        "                                                   GroupRandomHorizontalFlip(is_flow=False)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DgF9ybNDQlH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(scores):\n",
        "    es = np.exp(scores - scores.max(axis=-1)[..., None])\n",
        "    return es / es.sum(axis=-1)[..., None]\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqXACIIyb21l",
        "outputId": "579eeeb9-93ab-490c-f4f2-9fc1e40e3b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class _NonLocalBlockND(nn.Module):\n",
        "    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n",
        "        super(_NonLocalBlockND, self).__init__()\n",
        "\n",
        "        assert dimension in [1, 2, 3]\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.sub_sample = sub_sample\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.inter_channels = inter_channels\n",
        "\n",
        "        if self.inter_channels is None:\n",
        "            self.inter_channels = in_channels // 2\n",
        "            if self.inter_channels == 0:\n",
        "                self.inter_channels = 1\n",
        "\n",
        "        if dimension == 3:\n",
        "            conv_nd = nn.Conv3d\n",
        "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
        "            bn = nn.BatchNorm3d\n",
        "        elif dimension == 2:\n",
        "            conv_nd = nn.Conv2d\n",
        "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "            bn = nn.BatchNorm2d\n",
        "        else:\n",
        "            conv_nd = nn.Conv1d\n",
        "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
        "            bn = nn.BatchNorm1d\n",
        "\n",
        "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                         kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if bn_layer:\n",
        "            self.W = nn.Sequential(\n",
        "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                        kernel_size=1, stride=1, padding=0),\n",
        "                bn(self.in_channels)\n",
        "            )\n",
        "            nn.init.constant_(self.W[1].weight, 0)\n",
        "            nn.init.constant_(self.W[1].bias, 0)\n",
        "        else:\n",
        "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "            nn.init.constant_(self.W.weight, 0)\n",
        "            nn.init.constant_(self.W.bias, 0)\n",
        "\n",
        "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                           kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if sub_sample:\n",
        "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
        "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (b, c, t, h, w)\n",
        "        :return:\n",
        "        '''\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
        "        g_x = g_x.permute(0, 2, 1)\n",
        "\n",
        "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
        "        theta_x = theta_x.permute(0, 2, 1)\n",
        "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
        "        f = torch.matmul(theta_x, phi_x)\n",
        "        f_div_C = F.softmax(f, dim=-1)\n",
        "\n",
        "        y = torch.matmul(f_div_C, g_x)\n",
        "        y = y.permute(0, 2, 1).contiguous()\n",
        "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
        "        W_y = self.W(y)\n",
        "        z = W_y + x\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class NONLocalBlock1D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock1D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=1, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "class NONLocalBlock2D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock2D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=2, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "class NONLocalBlock3D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock3D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=3, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "class NL3DWrapper(nn.Module):\n",
        "    def __init__(self, block, n_segment):\n",
        "        super(NL3DWrapper, self).__init__()\n",
        "        self.block = block\n",
        "        self.nl = NONLocalBlock3D(block.bn3.num_features)\n",
        "        self.n_segment = n_segment\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "\n",
        "        nt, c, h, w = x.size()\n",
        "        x = x.view(nt // self.n_segment, self.n_segment, c, h, w).transpose(1, 2)  # n, c, t, h, w\n",
        "        x = self.nl(x)\n",
        "        x = x.transpose(1, 2).contiguous().view(nt, c, h, w)\n",
        "        return x\n",
        "\n",
        "\n",
        "def make_non_local(net, n_segment):\n",
        "    import torchvision\n",
        "    if isinstance(net, torchvision.models.ResNet):\n",
        "        net.layer2 = nn.Sequential(\n",
        "            NL3DWrapper(net.layer2[0], n_segment),\n",
        "            net.layer2[1],\n",
        "            NL3DWrapper(net.layer2[2], n_segment),\n",
        "            net.layer2[3],\n",
        "        )\n",
        "        net.layer3 = nn.Sequential(\n",
        "            NL3DWrapper(net.layer3[0], n_segment),\n",
        "            net.layer3[1],\n",
        "            NL3DWrapper(net.layer3[2], n_segment),\n",
        "            net.layer3[3],\n",
        "            NL3DWrapper(net.layer3[4], n_segment),\n",
        "            net.layer3[5],\n",
        "        )\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from torch.autograd import Variable\n",
        "    import torch\n",
        "\n",
        "    sub_sample = True\n",
        "    bn_layer = True\n",
        "\n",
        "    img = Variable(torch.zeros(2, 3, 20))\n",
        "    net = NONLocalBlock1D(3, sub_sample=sub_sample, bn_layer=bn_layer)\n",
        "    out = net(img)\n",
        "    print(out.size())\n",
        "\n",
        "    img = Variable(torch.zeros(2, 3, 20, 20))\n",
        "    net = NONLocalBlock2D(3, sub_sample=sub_sample, bn_layer=bn_layer)\n",
        "    out = net(img)\n",
        "    print(out.size())\n",
        "\n",
        "    img = Variable(torch.randn(2, 3, 10, 20, 20))\n",
        "    net = NONLocalBlock3D(3, sub_sample=sub_sample, bn_layer=bn_layer)\n",
        "    out = net(img)\n",
        "    print(out.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 20])\n",
            "torch.Size([2, 3, 20, 20])\n",
            "torch.Size([2, 3, 10, 20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ms4BIDVnsm-",
        "outputId": "07cf2fb3-5e5a-46da-dbb7-1aba96d5a9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class TemporalShift(nn.Module):\n",
        "    def __init__(self, net, n_segment=3, n_div=8, inplace=False):\n",
        "        super(TemporalShift, self).__init__()\n",
        "        self.net = net\n",
        "        self.n_segment = n_segment\n",
        "        self.fold_div = n_div\n",
        "        self.inplace = inplace\n",
        "        if inplace:\n",
        "            print('=> Using in-place shift...')\n",
        "        print('=> Using fold div: {}'.format(self.fold_div))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shift(x, self.n_segment, fold_div=self.fold_div, inplace=self.inplace)\n",
        "        return self.net(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def shift(x, n_segment, fold_div=3, inplace=False):\n",
        "        nt, c, h, w = x.size()\n",
        "        n_batch = nt // n_segment\n",
        "        x = x.view(n_batch, n_segment, c, h, w)\n",
        "\n",
        "        fold = c // fold_div\n",
        "        if inplace:\n",
        "            # Due to some out of order error when performing parallel computing. \n",
        "            # May need to write a CUDA kernel.\n",
        "            raise NotImplementedError  \n",
        "            # out = InplaceShift.apply(x, fold)\n",
        "        else:\n",
        "            out = torch.zeros_like(x)\n",
        "            out[:, :-1, :fold] = x[:, 1:, :fold]  # shift left\n",
        "            out[:, 1:, fold: 2 * fold] = x[:, :-1, fold: 2 * fold]  # shift right\n",
        "            out[:, :, 2 * fold:] = x[:, :, 2 * fold:]  # not shift\n",
        "\n",
        "        return out.view(nt, c, h, w)\n",
        "\n",
        "\n",
        "class InplaceShift(torch.autograd.Function):\n",
        "    # Special thanks to @raoyongming for the help to this function\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, fold):\n",
        "        # not support higher order gradient\n",
        "        # input = input.detach_()\n",
        "        ctx.fold_ = fold\n",
        "        n, t, c, h, w = input.size()\n",
        "        buffer = input.data.new(n, t, fold, h, w).zero_()\n",
        "        buffer[:, :-1] = input.data[:, 1:, :fold]\n",
        "        input.data[:, :, :fold] = buffer\n",
        "        buffer.zero_()\n",
        "        buffer[:, 1:] = input.data[:, :-1, fold: 2 * fold]\n",
        "        input.data[:, :, fold: 2 * fold] = buffer\n",
        "        return input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # grad_output = grad_output.detach_()\n",
        "        fold = ctx.fold_\n",
        "        n, t, c, h, w = grad_output.size()\n",
        "        buffer = grad_output.data.new(n, t, fold, h, w).zero_()\n",
        "        buffer[:, 1:] = grad_output.data[:, :-1, :fold]\n",
        "        grad_output.data[:, :, :fold] = buffer\n",
        "        buffer.zero_()\n",
        "        buffer[:, :-1] = grad_output.data[:, 1:, fold: 2 * fold]\n",
        "        grad_output.data[:, :, fold: 2 * fold] = buffer\n",
        "        return grad_output, None\n",
        "\n",
        "\n",
        "class TemporalPool(nn.Module):\n",
        "    def __init__(self, net, n_segment):\n",
        "        super(TemporalPool, self).__init__()\n",
        "        self.net = net\n",
        "        self.n_segment = n_segment\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.temporal_pool(x, n_segment=self.n_segment)\n",
        "        return self.net(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def temporal_pool(x, n_segment):\n",
        "        nt, c, h, w = x.size()\n",
        "        n_batch = nt // n_segment\n",
        "        x = x.view(n_batch, n_segment, c, h, w).transpose(1, 2)  # n, c, t, h, w\n",
        "        x = F.max_pool3d(x, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
        "        x = x.transpose(1, 2).contiguous().view(nt // 2, c, h, w)\n",
        "        return x\n",
        "\n",
        "\n",
        "def make_temporal_shift(net, n_segment, n_div=8, place='blockres', temporal_pool=False):\n",
        "    if temporal_pool:\n",
        "        n_segment_list = [n_segment, n_segment // 2, n_segment // 2, n_segment // 2]\n",
        "    else:\n",
        "        n_segment_list = [n_segment] * 4\n",
        "    assert n_segment_list[-1] > 0\n",
        "    print('=> n_segment per stage: {}'.format(n_segment_list))\n",
        "\n",
        "    import torchvision\n",
        "    if isinstance(net, torchvision.models.ResNet):\n",
        "        if place == 'block':\n",
        "            def make_block_temporal(stage, this_segment):\n",
        "                blocks = list(stage.children())\n",
        "                print('=> Processing stage with {} blocks'.format(len(blocks)))\n",
        "                for i, b in enumerate(blocks):\n",
        "                    blocks[i] = TemporalShift(b, n_segment=this_segment, n_div=n_div)\n",
        "                return nn.Sequential(*(blocks))\n",
        "\n",
        "            net.layer1 = make_block_temporal(net.layer1, n_segment_list[0])\n",
        "            net.layer2 = make_block_temporal(net.layer2, n_segment_list[1])\n",
        "            net.layer3 = make_block_temporal(net.layer3, n_segment_list[2])\n",
        "            net.layer4 = make_block_temporal(net.layer4, n_segment_list[3])\n",
        "\n",
        "        elif 'blockres' in place:\n",
        "            n_round = 1\n",
        "            if len(list(net.layer3.children())) >= 23:\n",
        "                n_round = 2\n",
        "                print('=> Using n_round {} to insert temporal shift'.format(n_round))\n",
        "\n",
        "            def make_block_temporal(stage, this_segment):\n",
        "                blocks = list(stage.children())\n",
        "                print('=> Processing stage with {} blocks residual'.format(len(blocks)))\n",
        "                for i, b in enumerate(blocks):\n",
        "                    if i % n_round == 0:\n",
        "                        blocks[i].conv1 = TemporalShift(b.conv1, n_segment=this_segment, n_div=n_div)\n",
        "                return nn.Sequential(*blocks)\n",
        "\n",
        "            net.layer1 = make_block_temporal(net.layer1, n_segment_list[0])\n",
        "            net.layer2 = make_block_temporal(net.layer2, n_segment_list[1])\n",
        "            net.layer3 = make_block_temporal(net.layer3, n_segment_list[2])\n",
        "            net.layer4 = make_block_temporal(net.layer4, n_segment_list[3])\n",
        "    else:\n",
        "        raise NotImplementedError(place)\n",
        "\n",
        "\n",
        "def make_temporal_pool(net, n_segment):\n",
        "    import torchvision\n",
        "    if isinstance(net, torchvision.models.ResNet):\n",
        "        print('=> Injecting nonlocal pooling')\n",
        "        net.layer2 = TemporalPool(net.layer2, n_segment)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # test inplace shift v.s. vanilla shift\n",
        "    tsm1 = TemporalShift(nn.Sequential(), n_segment=8, n_div=8, inplace=False)\n",
        "    tsm2 = TemporalShift(nn.Sequential(), n_segment=8, n_div=8, inplace=False)\n",
        "\n",
        "    print('=> Testing CPU...')\n",
        "    # test forward\n",
        "    with torch.no_grad():\n",
        "        for i in range(10):\n",
        "            x = torch.rand(2 * 8, 3, 224, 224)\n",
        "            y1 = tsm1(x)\n",
        "            y2 = tsm2(x)\n",
        "            assert torch.norm(y1 - y2).item() < 1e-5\n",
        "\n",
        "    # test backward\n",
        "    with torch.enable_grad():\n",
        "        for i in range(10):\n",
        "            x1 = torch.rand(2 * 8, 3, 224, 224)\n",
        "            x1.requires_grad_()\n",
        "            x2 = x1.clone()\n",
        "            y1 = tsm1(x1)\n",
        "            y2 = tsm2(x2)\n",
        "            grad1 = torch.autograd.grad((y1 ** 2).mean(), [x1])[0]\n",
        "            grad2 = torch.autograd.grad((y2 ** 2).mean(), [x2])[0]\n",
        "            assert torch.norm(grad1 - grad2).item() < 1e-5\n",
        "\n",
        "    print('=> Testing GPU...')\n",
        "    tsm1.cuda()\n",
        "    tsm2.cuda()\n",
        "    # test forward\n",
        "    with torch.no_grad():\n",
        "        for i in range(10):\n",
        "            x = torch.rand(2 * 8, 3, 224, 224).cuda()\n",
        "            y1 = tsm1(x)\n",
        "            y2 = tsm2(x)\n",
        "            assert torch.norm(y1 - y2).item() < 1e-5\n",
        "\n",
        "    # test backward\n",
        "    with torch.enable_grad():\n",
        "        for i in range(10):\n",
        "            x1 = torch.rand(2 * 8, 3, 224, 224).cuda()\n",
        "            x1.requires_grad_()\n",
        "            x2 = x1.clone()\n",
        "            y1 = tsm1(x1)\n",
        "            y2 = tsm2(x2)\n",
        "            grad1 = torch.autograd.grad((y1 ** 2).mean(), [x1])[0]\n",
        "            grad2 = torch.autograd.grad((y2 ** 2).mean(), [x2])[0]\n",
        "            assert torch.norm(grad1 - grad2).item() < 1e-5\n",
        "    print('Test passed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Using fold div: 8\n",
            "=> Using fold div: 8\n",
            "=> Testing CPU...\n",
            "=> Testing GPU...\n",
            "Test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JINpFNe7e0T1",
        "outputId": "49b8482b-67ea-4528-893f-7c25d6a639a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d6a92ba86a8b4369a0b75215a7ff65f3",
            "60809f0c1ce2489cad27958981d6014a",
            "17d9dec2d7ac42cdbd9ad9c67ff7ee98",
            "f3a6ec373eb7454ba0861fd4ea572605",
            "5f729b38e31940f686a95823ce29d9a0",
            "1098d3eb2d394554b27a73451b3962f6",
            "f43cd04db0144679877eb113674dd997",
            "6e6ffe16b4ba4d05925dfc5c1751716b"
          ]
        }
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "__all__ = ['BNInception', 'bninception']\n",
        "\n",
        "pretrained_settings = {\n",
        "    'bninception': {\n",
        "        'imagenet': {\n",
        "            'url': 'https://www.dropbox.com/s/3cvod6kzwluijcw/BNInception-9baff57459f5a1744.pth?dl=1',\n",
        "            'input_space': 'BGR',\n",
        "            'input_size': 224,\n",
        "            'input_range': [0, 255],\n",
        "            'mean': [104, 117, 128],\n",
        "            'std': [1, 1, 1],\n",
        "            'num_classes': 1000\n",
        "        },\n",
        "        'kinetics': {\n",
        "            'url': 'https://www.dropbox.com/s/gx4u7itoyygix0c/BNInceptionKinetics-47f0695e.pth?dl=1',\n",
        "            'input_space': 'BGR',\n",
        "            'input_size': 224,\n",
        "            'input_range': [0, 255],\n",
        "            'mean': [104, 117, 128],  # [96.29023126, 103.16065604, 110.63666788]\n",
        "            'std': [1, 1, 1],  # [40.02898126, 37.88248729, 38.7568578],\n",
        "            'num_classes': 400\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "class BNInception(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(BNInception, self).__init__()\n",
        "        inplace = True\n",
        "        self._build_features(inplace, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # if self.input_space == 'BGR':\n",
        "        #     assert len(x.size()) == 4\n",
        "        #     x = x[:, (2, 1, 0)]\n",
        "        x = self.features(x)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "    def features(self, x):\n",
        "        # stage1\n",
        "        pool1_3x3_s2_out = self._temporal_forward_wrap(self._block_1, 0)(x)\n",
        "        # stage2\n",
        "        pool2_3x3_s2_out = self._temporal_forward_wrap(self._block_2, 1)(pool1_3x3_s2_out)\n",
        "\n",
        "        # stage3\n",
        "        inception_3a_output_out = self._temporal_forward_wrap(self._block_3a, 2)(pool2_3x3_s2_out)\n",
        "        inception_3b_output_out = self._temporal_forward_wrap(self._block_3b, 3)(inception_3a_output_out)\n",
        "        inception_3c_output_out = self._temporal_forward_wrap(self._block_3c, 4)(inception_3b_output_out)\n",
        "\n",
        "        inception_4a_output_out = self._temporal_forward_wrap(self._block_4a, 5)(inception_3c_output_out)\n",
        "        inception_4b_output_out = self._temporal_forward_wrap(self._block_4b, 6)(inception_4a_output_out)\n",
        "        inception_4c_output_out = self._temporal_forward_wrap(self._block_4c, 7)(inception_4b_output_out)\n",
        "        inception_4d_output_out = self._temporal_forward_wrap(self._block_4d, 8)(inception_4c_output_out)\n",
        "        inception_4e_output_out = self._temporal_forward_wrap(self._block_4e, 9)(inception_4d_output_out)\n",
        "\n",
        "        inception_5a_output_out = self._temporal_forward_wrap(self._block_5a, 10)(inception_4e_output_out)\n",
        "        inception_5b_output_out = self._temporal_forward_wrap(self._block_5b, 11)(inception_5a_output_out)\n",
        "\n",
        "        return inception_5b_output_out\n",
        "\n",
        "    def logits(self, features):\n",
        "        x = self.global_pool(features)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def build_temporal_ops(self, n_segment, is_temporal_shift='0' * 12, shift_div=8):\n",
        "        # must call after loading weights\n",
        "        self.n_segment = n_segment\n",
        "        self.residual = 'res' in is_temporal_shift\n",
        "        if self.residual:\n",
        "            print('=> Using residual shift functions...')\n",
        "        if is_temporal_shift in ['block', 'blockres']:\n",
        "            self.is_temporal_shift = '1' * 12\n",
        "        else:\n",
        "            self.is_temporal_shift = is_temporal_shift\n",
        "        self.is_temporal_shift = '0' + self.is_temporal_shift[1:]  # image input does not shift\n",
        "\n",
        "        assert len(self.is_temporal_shift) == 12\n",
        "\n",
        "        print('=> Injecting temporal shift with mask {}'.format(self.is_temporal_shift))\n",
        "        self.fold_div = shift_div\n",
        "        print('=> Using fold div: {}'.format(self.fold_div))\n",
        "\n",
        "    def _temporal_forward_wrap(self, layer_func, index):\n",
        "        if hasattr(self, 'is_temporal_shift') and self.is_temporal_shift[index] == '1':  # run temporal shuffling\n",
        "            from ops.temporal_shift import TemporalShift\n",
        "            def wrapped_func(x, is_residual, n_segment, fold_div):\n",
        "                if is_residual:\n",
        "                    x_shift = TemporalShift.shift(x, n_segment, fold_div=fold_div)\n",
        "                    return F.relu(x + layer_func(x_shift))\n",
        "                else:\n",
        "                    x = TemporalShift.shift(x, n_segment, fold_div=fold_div)\n",
        "                    return layer_func(x)\n",
        "            from functools import partial\n",
        "            return partial(wrapped_func, is_residual=self.residual, n_segment=self.n_segment,\n",
        "                           fold_div=self.fold_div)\n",
        "        else:\n",
        "            return layer_func\n",
        "\n",
        "    def _block_1(self, x):\n",
        "        conv1_7x7_s2_out = self.conv1_7x7_s2(x)\n",
        "        conv1_7x7_s2_bn_out = self.conv1_7x7_s2_bn(conv1_7x7_s2_out)\n",
        "        conv1_relu_7x7_out = self.conv1_relu_7x7(conv1_7x7_s2_bn_out)\n",
        "        pool1_3x3_s2_out = self.pool1_3x3_s2(conv1_7x7_s2_bn_out)\n",
        "        return pool1_3x3_s2_out\n",
        "\n",
        "    def _block_2(self, x):\n",
        "        conv2_3x3_reduce_out = self.conv2_3x3_reduce(x)\n",
        "        conv2_3x3_reduce_bn_out = self.conv2_3x3_reduce_bn(conv2_3x3_reduce_out)\n",
        "        conv2_relu_3x3_reduce_out = self.conv2_relu_3x3_reduce(conv2_3x3_reduce_bn_out)\n",
        "        conv2_3x3_out = self.conv2_3x3(conv2_3x3_reduce_bn_out)\n",
        "        conv2_3x3_bn_out = self.conv2_3x3_bn(conv2_3x3_out)\n",
        "        conv2_relu_3x3_out = self.conv2_relu_3x3(conv2_3x3_bn_out)\n",
        "        pool2_3x3_s2_out = self.pool2_3x3_s2(conv2_3x3_bn_out)\n",
        "        return pool2_3x3_s2_out\n",
        "\n",
        "    def _block_3a(self, pool2_3x3_s2_out):\n",
        "        inception_3a_1x1_out = self.inception_3a_1x1(pool2_3x3_s2_out)\n",
        "        inception_3a_1x1_bn_out = self.inception_3a_1x1_bn(inception_3a_1x1_out)\n",
        "        inception_3a_relu_1x1_out = self.inception_3a_relu_1x1(inception_3a_1x1_bn_out)\n",
        "        inception_3a_3x3_reduce_out = self.inception_3a_3x3_reduce(pool2_3x3_s2_out)\n",
        "        inception_3a_3x3_reduce_bn_out = self.inception_3a_3x3_reduce_bn(inception_3a_3x3_reduce_out)\n",
        "        inception_3a_relu_3x3_reduce_out = self.inception_3a_relu_3x3_reduce(inception_3a_3x3_reduce_bn_out)\n",
        "        inception_3a_3x3_out = self.inception_3a_3x3(inception_3a_3x3_reduce_bn_out)\n",
        "        inception_3a_3x3_bn_out = self.inception_3a_3x3_bn(inception_3a_3x3_out)\n",
        "        inception_3a_relu_3x3_out = self.inception_3a_relu_3x3(inception_3a_3x3_bn_out)\n",
        "        inception_3a_double_3x3_reduce_out = self.inception_3a_double_3x3_reduce(pool2_3x3_s2_out)\n",
        "        inception_3a_double_3x3_reduce_bn_out = self.inception_3a_double_3x3_reduce_bn(\n",
        "            inception_3a_double_3x3_reduce_out)\n",
        "        inception_3a_relu_double_3x3_reduce_out = self.inception_3a_relu_double_3x3_reduce(\n",
        "            inception_3a_double_3x3_reduce_bn_out)\n",
        "        inception_3a_double_3x3_1_out = self.inception_3a_double_3x3_1(inception_3a_double_3x3_reduce_bn_out)\n",
        "        inception_3a_double_3x3_1_bn_out = self.inception_3a_double_3x3_1_bn(inception_3a_double_3x3_1_out)\n",
        "        inception_3a_relu_double_3x3_1_out = self.inception_3a_relu_double_3x3_1(inception_3a_double_3x3_1_bn_out)\n",
        "        inception_3a_double_3x3_2_out = self.inception_3a_double_3x3_2(inception_3a_double_3x3_1_bn_out)\n",
        "        inception_3a_double_3x3_2_bn_out = self.inception_3a_double_3x3_2_bn(inception_3a_double_3x3_2_out)\n",
        "        inception_3a_relu_double_3x3_2_out = self.inception_3a_relu_double_3x3_2(inception_3a_double_3x3_2_bn_out)\n",
        "        inception_3a_pool_out = self.inception_3a_pool(pool2_3x3_s2_out)\n",
        "        inception_3a_pool_proj_out = self.inception_3a_pool_proj(inception_3a_pool_out)\n",
        "        inception_3a_pool_proj_bn_out = self.inception_3a_pool_proj_bn(inception_3a_pool_proj_out)\n",
        "        inception_3a_relu_pool_proj_out = self.inception_3a_relu_pool_proj(inception_3a_pool_proj_bn_out)\n",
        "        inception_3a_output_out = torch.cat(\n",
        "            [inception_3a_1x1_bn_out, inception_3a_3x3_bn_out, inception_3a_double_3x3_2_bn_out,\n",
        "             inception_3a_pool_proj_bn_out], 1)\n",
        "        return inception_3a_output_out\n",
        "\n",
        "    def _block_3b(self, inception_3a_output_out):\n",
        "        inception_3b_1x1_out = self.inception_3b_1x1(inception_3a_output_out)\n",
        "        inception_3b_1x1_bn_out = self.inception_3b_1x1_bn(inception_3b_1x1_out)\n",
        "        inception_3b_relu_1x1_out = self.inception_3b_relu_1x1(inception_3b_1x1_bn_out)\n",
        "        inception_3b_3x3_reduce_out = self.inception_3b_3x3_reduce(inception_3a_output_out)\n",
        "        inception_3b_3x3_reduce_bn_out = self.inception_3b_3x3_reduce_bn(inception_3b_3x3_reduce_out)\n",
        "        inception_3b_relu_3x3_reduce_out = self.inception_3b_relu_3x3_reduce(inception_3b_3x3_reduce_bn_out)\n",
        "        inception_3b_3x3_out = self.inception_3b_3x3(inception_3b_3x3_reduce_bn_out)\n",
        "        inception_3b_3x3_bn_out = self.inception_3b_3x3_bn(inception_3b_3x3_out)\n",
        "        inception_3b_relu_3x3_out = self.inception_3b_relu_3x3(inception_3b_3x3_bn_out)\n",
        "        inception_3b_double_3x3_reduce_out = self.inception_3b_double_3x3_reduce(inception_3a_output_out)\n",
        "        inception_3b_double_3x3_reduce_bn_out = self.inception_3b_double_3x3_reduce_bn(\n",
        "            inception_3b_double_3x3_reduce_out)\n",
        "        inception_3b_relu_double_3x3_reduce_out = self.inception_3b_relu_double_3x3_reduce(\n",
        "            inception_3b_double_3x3_reduce_bn_out)\n",
        "        inception_3b_double_3x3_1_out = self.inception_3b_double_3x3_1(inception_3b_double_3x3_reduce_bn_out)\n",
        "        inception_3b_double_3x3_1_bn_out = self.inception_3b_double_3x3_1_bn(inception_3b_double_3x3_1_out)\n",
        "        inception_3b_relu_double_3x3_1_out = self.inception_3b_relu_double_3x3_1(inception_3b_double_3x3_1_bn_out)\n",
        "        inception_3b_double_3x3_2_out = self.inception_3b_double_3x3_2(inception_3b_double_3x3_1_bn_out)\n",
        "        inception_3b_double_3x3_2_bn_out = self.inception_3b_double_3x3_2_bn(inception_3b_double_3x3_2_out)\n",
        "        inception_3b_relu_double_3x3_2_out = self.inception_3b_relu_double_3x3_2(inception_3b_double_3x3_2_bn_out)\n",
        "        inception_3b_pool_out = self.inception_3b_pool(inception_3a_output_out)\n",
        "        inception_3b_pool_proj_out = self.inception_3b_pool_proj(inception_3b_pool_out)\n",
        "        inception_3b_pool_proj_bn_out = self.inception_3b_pool_proj_bn(inception_3b_pool_proj_out)\n",
        "        inception_3b_relu_pool_proj_out = self.inception_3b_relu_pool_proj(inception_3b_pool_proj_bn_out)\n",
        "        inception_3b_output_out = torch.cat(\n",
        "            [inception_3b_1x1_bn_out, inception_3b_3x3_bn_out, inception_3b_double_3x3_2_bn_out,\n",
        "             inception_3b_pool_proj_bn_out], 1)\n",
        "        return inception_3b_output_out\n",
        "\n",
        "    def _block_3c(self, inception_3b_output_out):\n",
        "        inception_3c_3x3_reduce_out = self.inception_3c_3x3_reduce(inception_3b_output_out)\n",
        "        inception_3c_3x3_reduce_bn_out = self.inception_3c_3x3_reduce_bn(inception_3c_3x3_reduce_out)\n",
        "        inception_3c_relu_3x3_reduce_out = self.inception_3c_relu_3x3_reduce(inception_3c_3x3_reduce_bn_out)\n",
        "        inception_3c_3x3_out = self.inception_3c_3x3(inception_3c_3x3_reduce_bn_out)\n",
        "        inception_3c_3x3_bn_out = self.inception_3c_3x3_bn(inception_3c_3x3_out)\n",
        "        inception_3c_relu_3x3_out = self.inception_3c_relu_3x3(inception_3c_3x3_bn_out)\n",
        "        inception_3c_double_3x3_reduce_out = self.inception_3c_double_3x3_reduce(inception_3b_output_out)\n",
        "        inception_3c_double_3x3_reduce_bn_out = self.inception_3c_double_3x3_reduce_bn(\n",
        "            inception_3c_double_3x3_reduce_out)\n",
        "        inception_3c_relu_double_3x3_reduce_out = self.inception_3c_relu_double_3x3_reduce(\n",
        "            inception_3c_double_3x3_reduce_bn_out)\n",
        "        inception_3c_double_3x3_1_out = self.inception_3c_double_3x3_1(inception_3c_double_3x3_reduce_bn_out)\n",
        "        inception_3c_double_3x3_1_bn_out = self.inception_3c_double_3x3_1_bn(inception_3c_double_3x3_1_out)\n",
        "        inception_3c_relu_double_3x3_1_out = self.inception_3c_relu_double_3x3_1(inception_3c_double_3x3_1_bn_out)\n",
        "        inception_3c_double_3x3_2_out = self.inception_3c_double_3x3_2(inception_3c_double_3x3_1_bn_out)\n",
        "        inception_3c_double_3x3_2_bn_out = self.inception_3c_double_3x3_2_bn(inception_3c_double_3x3_2_out)\n",
        "        inception_3c_relu_double_3x3_2_out = self.inception_3c_relu_double_3x3_2(inception_3c_double_3x3_2_bn_out)\n",
        "        inception_3c_pool_out = self.inception_3c_pool(inception_3b_output_out)\n",
        "        inception_3c_output_out = torch.cat(\n",
        "            [inception_3c_3x3_bn_out, inception_3c_double_3x3_2_bn_out, inception_3c_pool_out], 1)\n",
        "        return inception_3c_output_out\n",
        "\n",
        "    def _block_4a(self, inception_3c_output_out):\n",
        "        inception_4a_1x1_out = self.inception_4a_1x1(inception_3c_output_out)\n",
        "        inception_4a_1x1_bn_out = self.inception_4a_1x1_bn(inception_4a_1x1_out)\n",
        "        inception_4a_relu_1x1_out = self.inception_4a_relu_1x1(inception_4a_1x1_bn_out)\n",
        "        inception_4a_3x3_reduce_out = self.inception_4a_3x3_reduce(inception_3c_output_out)\n",
        "        inception_4a_3x3_reduce_bn_out = self.inception_4a_3x3_reduce_bn(inception_4a_3x3_reduce_out)\n",
        "        inception_4a_relu_3x3_reduce_out = self.inception_4a_relu_3x3_reduce(inception_4a_3x3_reduce_bn_out)\n",
        "        inception_4a_3x3_out = self.inception_4a_3x3(inception_4a_3x3_reduce_bn_out)\n",
        "        inception_4a_3x3_bn_out = self.inception_4a_3x3_bn(inception_4a_3x3_out)\n",
        "        inception_4a_relu_3x3_out = self.inception_4a_relu_3x3(inception_4a_3x3_bn_out)\n",
        "        inception_4a_double_3x3_reduce_out = self.inception_4a_double_3x3_reduce(inception_3c_output_out)\n",
        "        inception_4a_double_3x3_reduce_bn_out = self.inception_4a_double_3x3_reduce_bn(\n",
        "            inception_4a_double_3x3_reduce_out)\n",
        "        inception_4a_relu_double_3x3_reduce_out = self.inception_4a_relu_double_3x3_reduce(\n",
        "            inception_4a_double_3x3_reduce_bn_out)\n",
        "        inception_4a_double_3x3_1_out = self.inception_4a_double_3x3_1(inception_4a_double_3x3_reduce_bn_out)\n",
        "        inception_4a_double_3x3_1_bn_out = self.inception_4a_double_3x3_1_bn(inception_4a_double_3x3_1_out)\n",
        "        inception_4a_relu_double_3x3_1_out = self.inception_4a_relu_double_3x3_1(inception_4a_double_3x3_1_bn_out)\n",
        "        inception_4a_double_3x3_2_out = self.inception_4a_double_3x3_2(inception_4a_double_3x3_1_bn_out)\n",
        "        inception_4a_double_3x3_2_bn_out = self.inception_4a_double_3x3_2_bn(inception_4a_double_3x3_2_out)\n",
        "        inception_4a_relu_double_3x3_2_out = self.inception_4a_relu_double_3x3_2(inception_4a_double_3x3_2_bn_out)\n",
        "        inception_4a_pool_out = self.inception_4a_pool(inception_3c_output_out)\n",
        "        inception_4a_pool_proj_out = self.inception_4a_pool_proj(inception_4a_pool_out)\n",
        "        inception_4a_pool_proj_bn_out = self.inception_4a_pool_proj_bn(inception_4a_pool_proj_out)\n",
        "        inception_4a_relu_pool_proj_out = self.inception_4a_relu_pool_proj(inception_4a_pool_proj_bn_out)\n",
        "        inception_4a_output_out = torch.cat(\n",
        "            [inception_4a_1x1_bn_out, inception_4a_3x3_bn_out, inception_4a_double_3x3_2_bn_out,\n",
        "             inception_4a_pool_proj_bn_out], 1)\n",
        "        return inception_4a_output_out\n",
        "\n",
        "    def _block_4b(self, inception_4a_output_out):\n",
        "        inception_4b_1x1_out = self.inception_4b_1x1(inception_4a_output_out)\n",
        "        inception_4b_1x1_bn_out = self.inception_4b_1x1_bn(inception_4b_1x1_out)\n",
        "        inception_4b_relu_1x1_out = self.inception_4b_relu_1x1(inception_4b_1x1_bn_out)\n",
        "        inception_4b_3x3_reduce_out = self.inception_4b_3x3_reduce(inception_4a_output_out)\n",
        "        inception_4b_3x3_reduce_bn_out = self.inception_4b_3x3_reduce_bn(inception_4b_3x3_reduce_out)\n",
        "        inception_4b_relu_3x3_reduce_out = self.inception_4b_relu_3x3_reduce(inception_4b_3x3_reduce_bn_out)\n",
        "        inception_4b_3x3_out = self.inception_4b_3x3(inception_4b_3x3_reduce_bn_out)\n",
        "        inception_4b_3x3_bn_out = self.inception_4b_3x3_bn(inception_4b_3x3_out)\n",
        "        inception_4b_relu_3x3_out = self.inception_4b_relu_3x3(inception_4b_3x3_bn_out)\n",
        "        inception_4b_double_3x3_reduce_out = self.inception_4b_double_3x3_reduce(inception_4a_output_out)\n",
        "        inception_4b_double_3x3_reduce_bn_out = self.inception_4b_double_3x3_reduce_bn(\n",
        "            inception_4b_double_3x3_reduce_out)\n",
        "        inception_4b_relu_double_3x3_reduce_out = self.inception_4b_relu_double_3x3_reduce(\n",
        "            inception_4b_double_3x3_reduce_bn_out)\n",
        "        inception_4b_double_3x3_1_out = self.inception_4b_double_3x3_1(inception_4b_double_3x3_reduce_bn_out)\n",
        "        inception_4b_double_3x3_1_bn_out = self.inception_4b_double_3x3_1_bn(inception_4b_double_3x3_1_out)\n",
        "        inception_4b_relu_double_3x3_1_out = self.inception_4b_relu_double_3x3_1(inception_4b_double_3x3_1_bn_out)\n",
        "        inception_4b_double_3x3_2_out = self.inception_4b_double_3x3_2(inception_4b_double_3x3_1_bn_out)\n",
        "        inception_4b_double_3x3_2_bn_out = self.inception_4b_double_3x3_2_bn(inception_4b_double_3x3_2_out)\n",
        "        inception_4b_relu_double_3x3_2_out = self.inception_4b_relu_double_3x3_2(inception_4b_double_3x3_2_bn_out)\n",
        "        inception_4b_pool_out = self.inception_4b_pool(inception_4a_output_out)\n",
        "        inception_4b_pool_proj_out = self.inception_4b_pool_proj(inception_4b_pool_out)\n",
        "        inception_4b_pool_proj_bn_out = self.inception_4b_pool_proj_bn(inception_4b_pool_proj_out)\n",
        "        inception_4b_relu_pool_proj_out = self.inception_4b_relu_pool_proj(inception_4b_pool_proj_bn_out)\n",
        "        inception_4b_output_out = torch.cat(\n",
        "            [inception_4b_1x1_bn_out, inception_4b_3x3_bn_out, inception_4b_double_3x3_2_bn_out,\n",
        "             inception_4b_pool_proj_bn_out], 1)\n",
        "        return inception_4b_output_out\n",
        "\n",
        "    def _block_4c(self, inception_4b_output_out):\n",
        "        inception_4c_1x1_out = self.inception_4c_1x1(inception_4b_output_out)\n",
        "        inception_4c_1x1_bn_out = self.inception_4c_1x1_bn(inception_4c_1x1_out)\n",
        "        inception_4c_relu_1x1_out = self.inception_4c_relu_1x1(inception_4c_1x1_bn_out)\n",
        "        inception_4c_3x3_reduce_out = self.inception_4c_3x3_reduce(inception_4b_output_out)\n",
        "        inception_4c_3x3_reduce_bn_out = self.inception_4c_3x3_reduce_bn(inception_4c_3x3_reduce_out)\n",
        "        inception_4c_relu_3x3_reduce_out = self.inception_4c_relu_3x3_reduce(inception_4c_3x3_reduce_bn_out)\n",
        "        inception_4c_3x3_out = self.inception_4c_3x3(inception_4c_3x3_reduce_bn_out)\n",
        "        inception_4c_3x3_bn_out = self.inception_4c_3x3_bn(inception_4c_3x3_out)\n",
        "        inception_4c_relu_3x3_out = self.inception_4c_relu_3x3(inception_4c_3x3_bn_out)\n",
        "        inception_4c_double_3x3_reduce_out = self.inception_4c_double_3x3_reduce(inception_4b_output_out)\n",
        "        inception_4c_double_3x3_reduce_bn_out = self.inception_4c_double_3x3_reduce_bn(\n",
        "            inception_4c_double_3x3_reduce_out)\n",
        "        inception_4c_relu_double_3x3_reduce_out = self.inception_4c_relu_double_3x3_reduce(\n",
        "            inception_4c_double_3x3_reduce_bn_out)\n",
        "        inception_4c_double_3x3_1_out = self.inception_4c_double_3x3_1(inception_4c_double_3x3_reduce_bn_out)\n",
        "        inception_4c_double_3x3_1_bn_out = self.inception_4c_double_3x3_1_bn(inception_4c_double_3x3_1_out)\n",
        "        inception_4c_relu_double_3x3_1_out = self.inception_4c_relu_double_3x3_1(inception_4c_double_3x3_1_bn_out)\n",
        "        inception_4c_double_3x3_2_out = self.inception_4c_double_3x3_2(inception_4c_double_3x3_1_bn_out)\n",
        "        inception_4c_double_3x3_2_bn_out = self.inception_4c_double_3x3_2_bn(inception_4c_double_3x3_2_out)\n",
        "        inception_4c_relu_double_3x3_2_out = self.inception_4c_relu_double_3x3_2(inception_4c_double_3x3_2_bn_out)\n",
        "        inception_4c_pool_out = self.inception_4c_pool(inception_4b_output_out)\n",
        "        inception_4c_pool_proj_out = self.inception_4c_pool_proj(inception_4c_pool_out)\n",
        "        inception_4c_pool_proj_bn_out = self.inception_4c_pool_proj_bn(inception_4c_pool_proj_out)\n",
        "        inception_4c_relu_pool_proj_out = self.inception_4c_relu_pool_proj(inception_4c_pool_proj_bn_out)\n",
        "        inception_4c_output_out = torch.cat(\n",
        "            [inception_4c_1x1_bn_out, inception_4c_3x3_bn_out, inception_4c_double_3x3_2_bn_out,\n",
        "             inception_4c_pool_proj_bn_out], 1)\n",
        "        return inception_4c_output_out\n",
        "\n",
        "    def _block_4d(self, inception_4c_output_out):\n",
        "        inception_4d_1x1_out = self.inception_4d_1x1(inception_4c_output_out)\n",
        "        inception_4d_1x1_bn_out = self.inception_4d_1x1_bn(inception_4d_1x1_out)\n",
        "        inception_4d_relu_1x1_out = self.inception_4d_relu_1x1(inception_4d_1x1_bn_out)\n",
        "        inception_4d_3x3_reduce_out = self.inception_4d_3x3_reduce(inception_4c_output_out)\n",
        "        inception_4d_3x3_reduce_bn_out = self.inception_4d_3x3_reduce_bn(inception_4d_3x3_reduce_out)\n",
        "        inception_4d_relu_3x3_reduce_out = self.inception_4d_relu_3x3_reduce(inception_4d_3x3_reduce_bn_out)\n",
        "        inception_4d_3x3_out = self.inception_4d_3x3(inception_4d_3x3_reduce_bn_out)\n",
        "        inception_4d_3x3_bn_out = self.inception_4d_3x3_bn(inception_4d_3x3_out)\n",
        "        inception_4d_relu_3x3_out = self.inception_4d_relu_3x3(inception_4d_3x3_bn_out)\n",
        "        inception_4d_double_3x3_reduce_out = self.inception_4d_double_3x3_reduce(inception_4c_output_out)\n",
        "        inception_4d_double_3x3_reduce_bn_out = self.inception_4d_double_3x3_reduce_bn(\n",
        "            inception_4d_double_3x3_reduce_out)\n",
        "        inception_4d_relu_double_3x3_reduce_out = self.inception_4d_relu_double_3x3_reduce(\n",
        "            inception_4d_double_3x3_reduce_bn_out)\n",
        "        inception_4d_double_3x3_1_out = self.inception_4d_double_3x3_1(inception_4d_double_3x3_reduce_bn_out)\n",
        "        inception_4d_double_3x3_1_bn_out = self.inception_4d_double_3x3_1_bn(inception_4d_double_3x3_1_out)\n",
        "        inception_4d_relu_double_3x3_1_out = self.inception_4d_relu_double_3x3_1(inception_4d_double_3x3_1_bn_out)\n",
        "        inception_4d_double_3x3_2_out = self.inception_4d_double_3x3_2(inception_4d_double_3x3_1_bn_out)\n",
        "        inception_4d_double_3x3_2_bn_out = self.inception_4d_double_3x3_2_bn(inception_4d_double_3x3_2_out)\n",
        "        inception_4d_relu_double_3x3_2_out = self.inception_4d_relu_double_3x3_2(inception_4d_double_3x3_2_bn_out)\n",
        "        inception_4d_pool_out = self.inception_4d_pool(inception_4c_output_out)\n",
        "        inception_4d_pool_proj_out = self.inception_4d_pool_proj(inception_4d_pool_out)\n",
        "        inception_4d_pool_proj_bn_out = self.inception_4d_pool_proj_bn(inception_4d_pool_proj_out)\n",
        "        inception_4d_relu_pool_proj_out = self.inception_4d_relu_pool_proj(inception_4d_pool_proj_bn_out)\n",
        "        inception_4d_output_out = torch.cat(\n",
        "            [inception_4d_1x1_bn_out, inception_4d_3x3_bn_out, inception_4d_double_3x3_2_bn_out,\n",
        "             inception_4d_pool_proj_bn_out], 1)\n",
        "        return inception_4d_output_out\n",
        "\n",
        "    def _block_4e(self, inception_4d_output_out):\n",
        "        inception_4e_3x3_reduce_out = self.inception_4e_3x3_reduce(inception_4d_output_out)\n",
        "        inception_4e_3x3_reduce_bn_out = self.inception_4e_3x3_reduce_bn(inception_4e_3x3_reduce_out)\n",
        "        inception_4e_relu_3x3_reduce_out = self.inception_4e_relu_3x3_reduce(inception_4e_3x3_reduce_bn_out)\n",
        "        inception_4e_3x3_out = self.inception_4e_3x3(inception_4e_3x3_reduce_bn_out)\n",
        "        inception_4e_3x3_bn_out = self.inception_4e_3x3_bn(inception_4e_3x3_out)\n",
        "        inception_4e_relu_3x3_out = self.inception_4e_relu_3x3(inception_4e_3x3_bn_out)\n",
        "        inception_4e_double_3x3_reduce_out = self.inception_4e_double_3x3_reduce(inception_4d_output_out)\n",
        "        inception_4e_double_3x3_reduce_bn_out = self.inception_4e_double_3x3_reduce_bn(\n",
        "            inception_4e_double_3x3_reduce_out)\n",
        "        inception_4e_relu_double_3x3_reduce_out = self.inception_4e_relu_double_3x3_reduce(\n",
        "            inception_4e_double_3x3_reduce_bn_out)\n",
        "        inception_4e_double_3x3_1_out = self.inception_4e_double_3x3_1(inception_4e_double_3x3_reduce_bn_out)\n",
        "        inception_4e_double_3x3_1_bn_out = self.inception_4e_double_3x3_1_bn(inception_4e_double_3x3_1_out)\n",
        "        inception_4e_relu_double_3x3_1_out = self.inception_4e_relu_double_3x3_1(inception_4e_double_3x3_1_bn_out)\n",
        "        inception_4e_double_3x3_2_out = self.inception_4e_double_3x3_2(inception_4e_double_3x3_1_bn_out)\n",
        "        inception_4e_double_3x3_2_bn_out = self.inception_4e_double_3x3_2_bn(inception_4e_double_3x3_2_out)\n",
        "        inception_4e_relu_double_3x3_2_out = self.inception_4e_relu_double_3x3_2(inception_4e_double_3x3_2_bn_out)\n",
        "        inception_4e_pool_out = self.inception_4e_pool(inception_4d_output_out)\n",
        "        inception_4e_output_out = torch.cat(\n",
        "            [inception_4e_3x3_bn_out, inception_4e_double_3x3_2_bn_out, inception_4e_pool_out], 1)\n",
        "        return inception_4e_output_out\n",
        "\n",
        "    def _block_5a(self, inception_4e_output_out):\n",
        "        inception_5a_1x1_out = self.inception_5a_1x1(inception_4e_output_out)\n",
        "        inception_5a_1x1_bn_out = self.inception_5a_1x1_bn(inception_5a_1x1_out)\n",
        "        inception_5a_relu_1x1_out = self.inception_5a_relu_1x1(inception_5a_1x1_bn_out)\n",
        "        inception_5a_3x3_reduce_out = self.inception_5a_3x3_reduce(inception_4e_output_out)\n",
        "        inception_5a_3x3_reduce_bn_out = self.inception_5a_3x3_reduce_bn(inception_5a_3x3_reduce_out)\n",
        "        inception_5a_relu_3x3_reduce_out = self.inception_5a_relu_3x3_reduce(inception_5a_3x3_reduce_bn_out)\n",
        "        inception_5a_3x3_out = self.inception_5a_3x3(inception_5a_3x3_reduce_bn_out)\n",
        "        inception_5a_3x3_bn_out = self.inception_5a_3x3_bn(inception_5a_3x3_out)\n",
        "        inception_5a_relu_3x3_out = self.inception_5a_relu_3x3(inception_5a_3x3_bn_out)\n",
        "        inception_5a_double_3x3_reduce_out = self.inception_5a_double_3x3_reduce(inception_4e_output_out)\n",
        "        inception_5a_double_3x3_reduce_bn_out = self.inception_5a_double_3x3_reduce_bn(\n",
        "            inception_5a_double_3x3_reduce_out)\n",
        "        inception_5a_relu_double_3x3_reduce_out = self.inception_5a_relu_double_3x3_reduce(\n",
        "            inception_5a_double_3x3_reduce_bn_out)\n",
        "        inception_5a_double_3x3_1_out = self.inception_5a_double_3x3_1(inception_5a_double_3x3_reduce_bn_out)\n",
        "        inception_5a_double_3x3_1_bn_out = self.inception_5a_double_3x3_1_bn(inception_5a_double_3x3_1_out)\n",
        "        inception_5a_relu_double_3x3_1_out = self.inception_5a_relu_double_3x3_1(inception_5a_double_3x3_1_bn_out)\n",
        "        inception_5a_double_3x3_2_out = self.inception_5a_double_3x3_2(inception_5a_double_3x3_1_bn_out)\n",
        "        inception_5a_double_3x3_2_bn_out = self.inception_5a_double_3x3_2_bn(inception_5a_double_3x3_2_out)\n",
        "        inception_5a_relu_double_3x3_2_out = self.inception_5a_relu_double_3x3_2(inception_5a_double_3x3_2_bn_out)\n",
        "        inception_5a_pool_out = self.inception_5a_pool(inception_4e_output_out)\n",
        "        inception_5a_pool_proj_out = self.inception_5a_pool_proj(inception_5a_pool_out)\n",
        "        inception_5a_pool_proj_bn_out = self.inception_5a_pool_proj_bn(inception_5a_pool_proj_out)\n",
        "        inception_5a_relu_pool_proj_out = self.inception_5a_relu_pool_proj(inception_5a_pool_proj_bn_out)\n",
        "        inception_5a_output_out = torch.cat(\n",
        "            [inception_5a_1x1_bn_out, inception_5a_3x3_bn_out, inception_5a_double_3x3_2_bn_out,\n",
        "             inception_5a_pool_proj_bn_out], 1)\n",
        "        return inception_5a_output_out\n",
        "\n",
        "    def _block_5b(self, inception_5a_output_out):\n",
        "        inception_5b_1x1_out = self.inception_5b_1x1(inception_5a_output_out)\n",
        "        inception_5b_1x1_bn_out = self.inception_5b_1x1_bn(inception_5b_1x1_out)\n",
        "        inception_5b_relu_1x1_out = self.inception_5b_relu_1x1(inception_5b_1x1_bn_out)\n",
        "        inception_5b_3x3_reduce_out = self.inception_5b_3x3_reduce(inception_5a_output_out)\n",
        "        inception_5b_3x3_reduce_bn_out = self.inception_5b_3x3_reduce_bn(inception_5b_3x3_reduce_out)\n",
        "        inception_5b_relu_3x3_reduce_out = self.inception_5b_relu_3x3_reduce(inception_5b_3x3_reduce_bn_out)\n",
        "        inception_5b_3x3_out = self.inception_5b_3x3(inception_5b_3x3_reduce_bn_out)\n",
        "        inception_5b_3x3_bn_out = self.inception_5b_3x3_bn(inception_5b_3x3_out)\n",
        "        inception_5b_relu_3x3_out = self.inception_5b_relu_3x3(inception_5b_3x3_bn_out)\n",
        "        inception_5b_double_3x3_reduce_out = self.inception_5b_double_3x3_reduce(inception_5a_output_out)\n",
        "        inception_5b_double_3x3_reduce_bn_out = self.inception_5b_double_3x3_reduce_bn(\n",
        "            inception_5b_double_3x3_reduce_out)\n",
        "        inception_5b_relu_double_3x3_reduce_out = self.inception_5b_relu_double_3x3_reduce(\n",
        "            inception_5b_double_3x3_reduce_bn_out)\n",
        "        inception_5b_double_3x3_1_out = self.inception_5b_double_3x3_1(inception_5b_double_3x3_reduce_bn_out)\n",
        "        inception_5b_double_3x3_1_bn_out = self.inception_5b_double_3x3_1_bn(inception_5b_double_3x3_1_out)\n",
        "        inception_5b_relu_double_3x3_1_out = self.inception_5b_relu_double_3x3_1(inception_5b_double_3x3_1_bn_out)\n",
        "        inception_5b_double_3x3_2_out = self.inception_5b_double_3x3_2(inception_5b_double_3x3_1_bn_out)\n",
        "        inception_5b_double_3x3_2_bn_out = self.inception_5b_double_3x3_2_bn(inception_5b_double_3x3_2_out)\n",
        "        inception_5b_relu_double_3x3_2_out = self.inception_5b_relu_double_3x3_2(inception_5b_double_3x3_2_bn_out)\n",
        "        inception_5b_pool_out = self.inception_5b_pool(inception_5a_output_out)\n",
        "        inception_5b_pool_proj_out = self.inception_5b_pool_proj(inception_5b_pool_out)\n",
        "        inception_5b_pool_proj_bn_out = self.inception_5b_pool_proj_bn(inception_5b_pool_proj_out)\n",
        "        inception_5b_relu_pool_proj_out = self.inception_5b_relu_pool_proj(inception_5b_pool_proj_bn_out)\n",
        "        inception_5b_output_out = torch.cat(\n",
        "            [inception_5b_1x1_bn_out, inception_5b_3x3_bn_out, inception_5b_double_3x3_2_bn_out,\n",
        "             inception_5b_pool_proj_bn_out], 1)\n",
        "        return inception_5b_output_out\n",
        "\n",
        "    def _build_features(self, inplace, num_classes):\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.conv1_relu_7x7 = nn.ReLU(inplace)\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.conv2_3x3_reduce = nn.Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv2_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.conv2_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.conv2_3x3 = nn.Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv2_3x3_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.conv2_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.pool2_3x3_s2 = nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_3a_1x1 = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_1x1_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_3a_3x3_reduce = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3a_3x3 = nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_3a_double_3x3_reduce = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_double_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3a_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_1_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_3a_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_2_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_3a_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_3a_pool_proj = nn.Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_pool_proj_bn = nn.BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3a_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_3b_1x1 = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_1x1_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_3b_3x3_reduce = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3b_3x3 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_3x3_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_3b_double_3x3_reduce = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_double_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3b_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_1_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_3b_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_2_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_3b_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_3b_pool_proj = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_pool_proj_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3b_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_3c_3x3_reduce = nn.Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_3x3_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3c_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3c_3x3 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_3c_3x3_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3c_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_3c_double_3x3_reduce = nn.Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_double_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_3c_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_1_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_3c_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_2_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_3c_pool = nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_4a_1x1 = nn.Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_1x1_bn = nn.BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_4a_3x3_reduce = nn.Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_3x3_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4a_3x3 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_3x3_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_4a_double_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_double_3x3_reduce_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4a_double_3x3_1 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_double_3x3_1_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_4a_double_3x3_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_double_3x3_2_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_4a_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4a_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4a_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_4b_1x1 = nn.Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_1x1_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_4b_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_3x3_reduce_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4b_3x3 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_4b_double_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_double_3x3_reduce_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4b_double_3x3_1 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_double_3x3_1_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_4b_double_3x3_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_double_3x3_2_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_4b_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4b_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4b_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_4c_1x1 = nn.Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_1x1_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_4c_3x3_reduce = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_3x3_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4c_3x3 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_3x3_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_4c_double_3x3_reduce = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_double_3x3_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4c_double_3x3_1 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_double_3x3_1_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_4c_double_3x3_2 = nn.Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_double_3x3_2_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_4c_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4c_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4c_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_4d_1x1 = nn.Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_1x1_bn = nn.BatchNorm2d(96, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_4d_3x3_reduce = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_3x3_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4d_3x3 = nn.Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_3x3_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_4d_double_3x3_reduce = nn.Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_double_3x3_reduce_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4d_double_3x3_1 = nn.Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_double_3x3_1_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_4d_double_3x3_2 = nn.Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_double_3x3_2_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_4d_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4d_pool_proj = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4d_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_4e_3x3_reduce = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4e_3x3_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4e_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4e_3x3 = nn.Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_4e_3x3_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4e_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_4e_double_3x3_reduce = nn.Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4e_double_3x3_reduce_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_4e_double_3x3_1 = nn.Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4e_double_3x3_1_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_4e_double_3x3_2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_4e_double_3x3_2_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_4e_pool = nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_5a_1x1 = nn.Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_1x1_bn = nn.BatchNorm2d(352, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_5a_3x3_reduce = nn.Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_3x3_reduce_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_5a_3x3 = nn.Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_3x3_bn = nn.BatchNorm2d(320, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_5a_double_3x3_reduce = nn.Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_double_3x3_reduce_bn = nn.BatchNorm2d(160, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_5a_double_3x3_1 = nn.Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_double_3x3_1_bn = nn.BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_5a_double_3x3_2 = nn.Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_double_3x3_2_bn = nn.BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_5a_pool = nn.AvgPool2d(3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_5a_pool_proj = nn.Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5a_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.inception_5b_1x1 = nn.Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_1x1_bn = nn.BatchNorm2d(352, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_1x1 = nn.ReLU(inplace)\n",
        "        self.inception_5b_3x3_reduce = nn.Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_3x3_reduce_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_5b_3x3 = nn.Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_3x3_bn = nn.BatchNorm2d(320, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_3x3 = nn.ReLU(inplace)\n",
        "        self.inception_5b_double_3x3_reduce = nn.Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_double_3x3_reduce_bn = nn.BatchNorm2d(192, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_reduce = nn.ReLU(inplace)\n",
        "        self.inception_5b_double_3x3_1 = nn.Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_double_3x3_1_bn = nn.BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_1 = nn.ReLU(inplace)\n",
        "        self.inception_5b_double_3x3_2 = nn.Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_double_3x3_2_bn = nn.BatchNorm2d(224, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_2 = nn.ReLU(inplace)\n",
        "        self.inception_5b_pool = nn.MaxPool2d((3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_5b_pool_proj = nn.Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_pool_proj_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True)\n",
        "        self.inception_5b_relu_pool_proj = nn.ReLU(inplace)\n",
        "        self.global_pool = nn.AvgPool2d(7, stride=1, padding=0, ceil_mode=True, count_include_pad=True)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "\n",
        "def bninception(pretrained='imagenet'):\n",
        "    r\"\"\"BNInception model architecture from <https://arxiv.org/pdf/1502.03167.pdf>`_ paper.\n",
        "    \"\"\"\n",
        "    if pretrained is not None:\n",
        "        print('=> Loading from pretrained model: {}'.format(pretrained))\n",
        "        settings = pretrained_settings['bninception'][pretrained]\n",
        "        num_classes = settings['num_classes']\n",
        "        model = BNInception(num_classes=num_classes)\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':    model = bninception()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading from pretrained model: imagenet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://www.dropbox.com/s/3cvod6kzwluijcw/BNInception-9baff57459f5a1744.pth?dl=1\" to /root/.cache/torch/checkpoints/BNInception-9baff57459f5a1744.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6a92ba86a8b4369a0b75215a7ff65f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45322792.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg5uYMXje3jR",
        "outputId": "2279bf4e-bba7-45fa-c9f0-24052d85ec3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "863b7aeef88f4213b4ae67f0ba1a5c5a",
            "cd35866ca0fd4885b7c484cd1a08e90c",
            "610edb787f8d4bde9e5c28bb19a12165",
            "4429f56faa1c4f0a85746f49e3083cc2",
            "d79d39501b054f008cc3f8ad2e898468",
            "0b72132e1a404409b49624dc84f00130",
            "84bdb83f0d1b436a8216a7c54dddcb45",
            "cc0a1b0a233d4f6397607eb58cb16add"
          ]
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def conv_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def make_divisible(x, divisible_by=8):\n",
        "    import numpy as np\n",
        "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = int(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "        interverted_residual_setting = [\n",
        "            # t, c, n, s\n",
        "            [1, 16, 1, 1],\n",
        "            [6, 24, 2, 2],\n",
        "            [6, 32, 3, 2],\n",
        "            [6, 64, 4, 2],\n",
        "            [6, 96, 3, 1],\n",
        "            [6, 160, 3, 2],\n",
        "            [6, 320, 1, 1],\n",
        "        ]\n",
        "\n",
        "        # building first layer\n",
        "        assert input_size % 32 == 0\n",
        "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
        "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
        "        self.features = [conv_bn(3, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in interverted_residual_setting:\n",
        "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
        "            for i in range(n):\n",
        "                if i == 0:\n",
        "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
        "                else:\n",
        "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Linear(self.last_channel, n_class)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean(3).mean(2)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                n = m.weight.size(1)\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def mobilenet_v2(pretrained=True):\n",
        "    model = MobileNetV2(width_mult=1)\n",
        "\n",
        "    if pretrained:\n",
        "        try:\n",
        "            from torch.hub import load_state_dict_from_url\n",
        "        except ImportError:\n",
        "            from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "        state_dict = load_state_dict_from_url(\n",
        "            'https://www.dropbox.com/s/47tyzpofuuyyv1b/mobilenetv2_1.0-f2a8633.pth.tar?dl=1', progress=True)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':    net = mobilenet_v2(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://www.dropbox.com/s/47tyzpofuuyyv1b/mobilenetv2_1.0-f2a8633.pth.tar?dl=1\" to /root/.cache/torch/checkpoints/mobilenetv2_1.0-f2a8633.pth.tar\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "863b7aeef88f4213b4ae67f0ba1a5c5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14196051.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RkZ3-fmO-1A",
        "outputId": "31991fc0-2663-4609-dbff-5f66027ce85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "best_prec1 = 0\n",
        "store_name=''\n",
        "\n",
        "def main():\n",
        "    global best_prec1, store_name\n",
        "    num_class, train_list, val_list, root_path, prefix = return_dataset('kinetics', 'RGB')\n",
        "    full_arch_name = 'mobilenetv2'\n",
        "    if True:\n",
        "        full_arch_name += '_shift{}_{}'.format(8, 'blockres')\n",
        "    if False:\n",
        "        full_arch_name += '_tpool'\n",
        "    store_name = '_'.join(\n",
        "        ['TSM', 'kinetics', 'RGB', full_arch_name, 'avg', 'segment%d' % 8,\n",
        "         'e{}'.format(20)])\n",
        "    pretrain='imagenet'\n",
        "    lr_type = 'step'\n",
        "    dense_sample=False\n",
        "    non_local=False\n",
        "    suffix=None\n",
        "    print('storing name: ' + store_name)\n",
        "\n",
        "    check_rootfolders()\n",
        "\n",
        "    model = TSN(num_class, 8, 'RGB',\n",
        "                base_model='mobilenetv2',\n",
        "                consensus_type='avg',\n",
        "                dropout=0.5,\n",
        "                img_feature_dim=256,\n",
        "                partial_bn=not True,\n",
        "                pretrain='imagenet',\n",
        "                is_shift=True, shift_div=8, shift_place='blockres',\n",
        "                fc_lr5=not (None and 'kinetics' in None),\n",
        "                temporal_pool=False,\n",
        "                non_local=False)\n",
        "\n",
        "    crop_size = model.crop_size\n",
        "    scale_size = model.scale_size\n",
        "    input_mean = model.input_mean\n",
        "    input_std = model.input_std\n",
        "    policies = model.get_optim_policies()\n",
        "    train_augmentation = model.get_augmentation(flip=False if 'something' in 'kinetics' or 'jester' in 'kinetics' else True)\n",
        "\n",
        "    model = torch.nn.DataParallel(model, device_ids=None).cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(policies,\n",
        "                                0.0025,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4)\n",
        "    start_epoch=0\n",
        "    if '':\n",
        "        if False:  # early temporal pool so that we can load the state_dict\n",
        "            make_temporal_pool(model.module.base_model, 8)\n",
        "        if os.path.isfile(''):\n",
        "            print((\"=> loading checkpoint '{}'\".format('')))\n",
        "            checkpoint = torch.load('')\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print((\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                   .format(True, checkpoint['epoch'])))\n",
        "        else:\n",
        "            print((\"=> no checkpoint found at '{}'\".format('')))\n",
        "\n",
        "    if None:\n",
        "        print((\"=> fine-tuning from '{}'\".format(None)))\n",
        "        sd = torch.load(None)\n",
        "        sd = sd['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        replace_dict = []\n",
        "        for k, v in sd.items():\n",
        "            if k not in model_dict and k.replace('.net', '') in model_dict:\n",
        "                print('=> Load after remove .net: ', k)\n",
        "                replace_dict.append((k, k.replace('.net', '')))\n",
        "        for k, v in model_dict.items():\n",
        "            if k not in sd and k.replace('.net', '') in sd:\n",
        "                print('=> Load after adding .net: ', k)\n",
        "                replace_dict.append((k.replace('.net', ''), k))\n",
        "\n",
        "        for k, k_new in replace_dict:\n",
        "            sd[k_new] = sd.pop(k)\n",
        "        keys1 = set(list(sd.keys()))\n",
        "        keys2 = set(list(model_dict.keys()))\n",
        "        set_diff = (keys1 - keys2) | (keys2 - keys1)\n",
        "        print('#### Notice: keys that failed to load: {}'.format(set_diff))\n",
        "        if 'kinetics' not in None:  # new dataset\n",
        "            print('=> New dataset, do not load fc weights')\n",
        "            sd = {k: v for k, v in sd.items() if 'fc' not in k}\n",
        "        if 'RGB' == 'Flow' and 'Flow' not in None:\n",
        "            sd = {k: v for k, v in sd.items() if 'conv1.weight' not in k}\n",
        "        model_dict.update(sd)\n",
        "        model.load_state_dict(model_dict)\n",
        "\n",
        "    if False and not '':\n",
        "        make_temporal_pool(model.module.base_model, 8)\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Data loading code\n",
        "    if 'RGB' != 'RGBDiff':\n",
        "        normalize = GroupNormalize(input_mean, input_std)\n",
        "    else:\n",
        "        normalize = IdentityTransform()\n",
        "\n",
        "    if 'RGB' == 'RGB':\n",
        "        data_length = 1\n",
        "    elif 'RGB' in ['Flow', 'RGBDiff']:\n",
        "        data_length = 5\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        TSNDataSet(root_path, train_list, num_segments=8,\n",
        "                   new_length=data_length,\n",
        "                   modality='RGB',\n",
        "                   image_tmpl=prefix,\n",
        "                   transform=torchvision.transforms.Compose([\n",
        "                       train_augmentation,\n",
        "                       Stack(roll=('mobilenetv2' in ['BNInception', 'InceptionV3'])),\n",
        "                       ToTorchFormatTensor(div=('mobilenetv2' not in ['BNInception', 'InceptionV3'])),\n",
        "                       normalize,\n",
        "                   ]), dense_sample=False),\n",
        "        batch_size=16, shuffle=True,\n",
        "        num_workers=16, pin_memory=True,\n",
        "        drop_last=True)  # prevent something not % n_GPU\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        TSNDataSet(root_path, val_list, num_segments=8,\n",
        "                   new_length=data_length,\n",
        "                   modality='RGB',\n",
        "                   image_tmpl=prefix,\n",
        "                   random_shift=False,\n",
        "                   transform=torchvision.transforms.Compose([\n",
        "                       GroupScale(int(scale_size)),\n",
        "                       GroupCenterCrop(crop_size),\n",
        "                       Stack(roll=('mobilenetv2' in ['BNInception', 'InceptionV3'])),\n",
        "                       ToTorchFormatTensor(div=('mobilenetv2' not in ['BNInception', 'InceptionV3'])),\n",
        "                       normalize,\n",
        "                   ]), dense_sample=False),\n",
        "        batch_size=16, shuffle=False,\n",
        "        num_workers=16, pin_memory=True)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    if 'nll' == 'nll':\n",
        "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown loss type\")\n",
        "\n",
        "    for group in policies:\n",
        "        print(('group: {} has {} params, lr_mult: {}, decay_mult: {}'.format(\n",
        "            group['name'], len(group['params']), group['lr_mult'], group['decay_mult'])))\n",
        "    if False:\n",
        "        validate(val_loader, model, criterion, 0)\n",
        "        return\n",
        "    \n",
        "    log_training = open(os.path.join('log', store_name, 'log.csv'), 'w')\n",
        "    with open(os.path.join('log', store_name, 'args.txt'), 'w') as f:\n",
        "        f.write(\"hi\")\n",
        "    tf_writer = SummaryWriter(log_dir=os.path.join('log', store_name))\n",
        "    for epoch in range(start_epoch, 20):\n",
        "        adjust_learning_rate(optimizer, epoch, lr_type, [20,40])\n",
        "\n",
        "        # train for one epoch\n",
        "        train(train_loader, model, criterion, optimizer, epoch, log_training, tf_writer)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        if (epoch + 1) % 1 == 0 or epoch == 20 - 1:\n",
        "            prec1 = validate(val_loader, model, criterion, epoch, log_training, tf_writer)\n",
        "\n",
        "            # remember best prec@1 and save checkpoint\n",
        "            is_best = prec1 > best_prec1\n",
        "            best_prec1 = max(prec1, best_prec1)\n",
        "            tf_writer.add_scalar('acc/test_top1_best', best_prec1, epoch)\n",
        "\n",
        "            output_best = 'Best Prec@1: %.3f\\n' % (best_prec1)\n",
        "            print(output_best)\n",
        "            log_training.write(output_best + '\\n')\n",
        "            log_training.flush()\n",
        "\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'arch': 'mobilenetv2',\n",
        "                'state_dict': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'best_prec1': best_prec1,\n",
        "            }, is_best)\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, log, tf_writer):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    if True:\n",
        "        model.module.partialBN(False)\n",
        "    else:\n",
        "        model.module.partialBN(True)\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        target = target.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "        top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        loss.backward()\n",
        "\n",
        "        if 20 is not None:\n",
        "            total_norm = clip_grad_norm_(model.parameters(), 20)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            output = ('Epoch: [{0}][{1}/{2}], lr: {lr:.5f}\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                data_time=data_time, loss=losses, top1=top1, top5=top5, lr=optimizer.param_groups[-1]['lr'] * 0.1))  # TODO\n",
        "            print(output)\n",
        "            log.write(output + '\\n')\n",
        "            log.flush()\n",
        "\n",
        "    tf_writer.add_scalar('loss/train', losses.avg, epoch)\n",
        "    tf_writer.add_scalar('acc/train_top1', top1.avg, epoch)\n",
        "    tf_writer.add_scalar('acc/train_top5', top5.avg, epoch)\n",
        "    tf_writer.add_scalar('lr', optimizer.param_groups[-1]['lr'], epoch)\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch, log=None, tf_writer=None):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
        "\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "            top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                output = ('Test: [{0}/{1}]\\t'\n",
        "                          'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                          'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                          'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                          'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                    i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                    top1=top1, top5=top5))\n",
        "                print(output)\n",
        "                if log is not None:\n",
        "                    log.write(output + '\\n')\n",
        "                    log.flush()\n",
        "\n",
        "    output = ('Testing Results: Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Loss {loss.avg:.5f}'\n",
        "              .format(top1=top1, top5=top5, loss=losses))\n",
        "    print(output)\n",
        "    if log is not None:\n",
        "        log.write(output + '\\n')\n",
        "        log.flush()\n",
        "\n",
        "    if tf_writer is not None:\n",
        "        tf_writer.add_scalar('loss/test', losses.avg, epoch)\n",
        "        tf_writer.add_scalar('acc/test_top1', top1.avg, epoch)\n",
        "        tf_writer.add_scalar('acc/test_top5', top5.avg, epoch)\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best):\n",
        "    filename = '%s/%s/ckpt.pth.tar' % ('checkpoint', store_name)\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, filename.replace('pth.tar', 'best.pth.tar'))\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr_type, lr_steps):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    if lr_type == 'step':\n",
        "        decay = 0.1 ** (sum(epoch >= np.array(lr_steps)))\n",
        "        lr = 0.0025 * decay\n",
        "        decay = 1e-4\n",
        "    elif lr_type == 'cos':\n",
        "        import math\n",
        "        lr = 0.5 * 0.0025 * (1 + math.cos(math.pi * epoch / 20))\n",
        "        decay = 1e-4\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr * param_group['lr_mult']\n",
        "        param_group['weight_decay'] = decay * param_group['decay_mult']\n",
        "\n",
        "\n",
        "def check_rootfolders():\n",
        "    \"\"\"Create log and model folder\"\"\"\n",
        "    global store_name\n",
        "    folders_util = ['log', 'checkpoint',\n",
        "                    os.path.join('log', store_name),\n",
        "                    os.path.join('checkpoint', store_name)]\n",
        "    for folder in folders_util:\n",
        "        if not os.path.exists(folder):\n",
        "            print('creating folder ' + folder)\n",
        "            os.mkdir(folder)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kinetics: 5 classes\n",
            "storing name: TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e20\n",
            "creating folder log\n",
            "creating folder checkpoint\n",
            "creating folder log/TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e20\n",
            "creating folder checkpoint/TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e20\n",
            "\n",
            "    Initializing TSN with base model: mobilenetv2.\n",
            "    TSN Configurations:\n",
            "        input_modality:     RGB\n",
            "        num_segments:       8\n",
            "        new_length:         1\n",
            "        consensus_module:   avg\n",
            "        dropout_ratio:      0.5\n",
            "        img_feature_dim:    256\n",
            "            \n",
            "=> base model: mobilenetv2\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "video number:1394\n",
            "video number:40\n",
            "group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1\n",
            "group: first_conv_bias has 0 params, lr_mult: 2, decay_mult: 0\n",
            "group: normal_weight has 51 params, lr_mult: 1, decay_mult: 1\n",
            "group: normal_bias has 0 params, lr_mult: 2, decay_mult: 0\n",
            "group: BN scale/shift has 104 params, lr_mult: 1, decay_mult: 0\n",
            "group: custom_ops has 0 params, lr_mult: 1, decay_mult: 1\n",
            "group: lr5_weight has 1 params, lr_mult: 5, decay_mult: 1\n",
            "group: lr10_bias has 1 params, lr_mult: 10, decay_mult: 0\n",
            "Epoch: [0][0/87], lr: 0.00250\tTime 41.605 (41.605)\tData 36.494 (36.494)\tLoss 1.6166 (1.6166)\tPrec@1 6.250 (6.250)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [0][20/87], lr: 0.00250\tTime 1.117 (4.102)\tData 0.108 (2.869)\tLoss 0.8504 (1.4966)\tPrec@1 75.000 (41.667)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [0][40/87], lr: 0.00250\tTime 1.014 (3.601)\tData 0.000 (2.468)\tLoss 0.8558 (1.3109)\tPrec@1 68.750 (55.335)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [0][60/87], lr: 0.00250\tTime 1.010 (3.055)\tData 0.000 (1.954)\tLoss 1.4019 (1.3967)\tPrec@1 68.750 (57.787)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [0][80/87], lr: 0.00250\tTime 4.510 (2.675)\tData 3.487 (1.591)\tLoss 0.7383 (1.3389)\tPrec@1 75.000 (60.108)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 42.118 (42.118)\tLoss 8.2874 (8.2874)\tPrec@1 25.000 (25.000)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 47.500 Prec@5 100.000 Loss 4.06401\n",
            "Best Prec@1: 47.500\n",
            "\n",
            "Epoch: [1][0/87], lr: 0.00250\tTime 39.394 (39.394)\tData 38.197 (38.197)\tLoss 1.7286 (1.7286)\tPrec@1 56.250 (56.250)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [1][20/87], lr: 0.00250\tTime 1.094 (4.658)\tData 0.000 (3.574)\tLoss 0.7546 (1.2163)\tPrec@1 75.000 (68.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [1][40/87], lr: 0.00250\tTime 2.660 (3.076)\tData 1.514 (1.996)\tLoss 2.3369 (1.2519)\tPrec@1 50.000 (67.835)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [1][60/87], lr: 0.00250\tTime 1.055 (2.908)\tData 0.000 (1.840)\tLoss 1.5291 (1.2072)\tPrec@1 68.750 (68.852)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [1][80/87], lr: 0.00250\tTime 2.293 (2.542)\tData 1.267 (1.481)\tLoss 1.7412 (1.1228)\tPrec@1 62.500 (70.833)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.223 (3.223)\tLoss 2.3198 (2.3198)\tPrec@1 56.250 (56.250)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 65.000 Prec@5 100.000 Loss 1.58926\n",
            "Best Prec@1: 65.000\n",
            "\n",
            "Epoch: [2][0/87], lr: 0.00250\tTime 46.599 (46.599)\tData 45.419 (45.419)\tLoss 0.4131 (0.4131)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [2][20/87], lr: 0.00250\tTime 9.150 (4.247)\tData 8.144 (3.201)\tLoss 0.3087 (0.6330)\tPrec@1 93.750 (82.738)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [2][40/87], lr: 0.00250\tTime 1.035 (3.918)\tData 0.000 (2.880)\tLoss 0.5527 (0.6941)\tPrec@1 81.250 (80.945)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [2][60/87], lr: 0.00250\tTime 22.712 (4.024)\tData 21.648 (2.988)\tLoss 0.4622 (0.6894)\tPrec@1 81.250 (79.201)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [2][80/87], lr: 0.00250\tTime 1.032 (3.327)\tData 0.000 (2.292)\tLoss 0.7331 (0.6716)\tPrec@1 81.250 (78.549)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.383 (3.383)\tLoss 0.2124 (0.2124)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 77.500 Prec@5 100.000 Loss 0.68296\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [3][0/87], lr: 0.00250\tTime 31.756 (31.756)\tData 30.623 (30.623)\tLoss 0.6632 (0.6632)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [3][20/87], lr: 0.00250\tTime 1.079 (5.901)\tData 0.007 (4.846)\tLoss 0.3324 (0.5830)\tPrec@1 87.500 (82.738)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [3][40/87], lr: 0.00250\tTime 1.037 (4.286)\tData 0.000 (3.232)\tLoss 0.7658 (0.5942)\tPrec@1 87.500 (82.012)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [3][60/87], lr: 0.00250\tTime 1.020 (4.419)\tData 0.000 (3.364)\tLoss 0.9533 (0.5954)\tPrec@1 75.000 (82.377)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [3][80/87], lr: 0.00250\tTime 1.026 (3.670)\tData 0.000 (2.617)\tLoss 1.1476 (0.5661)\tPrec@1 62.500 (82.253)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.658 (3.658)\tLoss 0.3548 (0.3548)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 1.16993\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [4][0/87], lr: 0.00250\tTime 33.546 (33.546)\tData 32.365 (32.365)\tLoss 0.1605 (0.1605)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [4][20/87], lr: 0.00250\tTime 1.000 (5.543)\tData 0.000 (4.518)\tLoss 0.1115 (0.3700)\tPrec@1 100.000 (88.095)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [4][40/87], lr: 0.00250\tTime 0.997 (4.697)\tData 0.000 (3.678)\tLoss 0.1771 (0.3737)\tPrec@1 100.000 (88.262)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [4][60/87], lr: 0.00250\tTime 44.958 (6.258)\tData 43.820 (5.234)\tLoss 0.2002 (0.3464)\tPrec@1 93.750 (89.139)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [4][80/87], lr: 0.00250\tTime 1.006 (6.010)\tData 0.000 (4.985)\tLoss 0.1333 (0.3340)\tPrec@1 93.750 (89.352)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.308 (3.308)\tLoss 0.1549 (0.1549)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 77.500 Prec@5 100.000 Loss 1.03184\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [5][0/87], lr: 0.00250\tTime 99.488 (99.488)\tData 98.326 (98.326)\tLoss 0.2147 (0.2147)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [5][20/87], lr: 0.00250\tTime 1.022 (10.847)\tData 0.000 (9.787)\tLoss 0.3623 (0.3153)\tPrec@1 81.250 (87.798)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [5][40/87], lr: 0.00250\tTime 1.005 (10.438)\tData 0.000 (9.388)\tLoss 0.3970 (0.3497)\tPrec@1 81.250 (86.433)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [5][60/87], lr: 0.00250\tTime 1.043 (9.668)\tData 0.000 (8.618)\tLoss 0.4477 (0.3461)\tPrec@1 87.500 (87.295)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [5][80/87], lr: 0.00250\tTime 1.024 (8.530)\tData 0.000 (7.478)\tLoss 0.1780 (0.3621)\tPrec@1 93.750 (87.114)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.701 (3.701)\tLoss 0.9413 (0.9413)\tPrec@1 68.750 (68.750)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 0.89100\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [6][0/87], lr: 0.00250\tTime 70.456 (70.456)\tData 69.330 (69.330)\tLoss 0.5595 (0.5595)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [6][20/87], lr: 0.00250\tTime 1.039 (8.277)\tData 0.000 (7.223)\tLoss 0.4022 (0.2741)\tPrec@1 81.250 (89.583)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [6][40/87], lr: 0.00250\tTime 1.033 (6.458)\tData 0.000 (5.407)\tLoss 0.1849 (0.3164)\tPrec@1 93.750 (89.482)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [6][60/87], lr: 0.00250\tTime 1.011 (5.377)\tData 0.000 (4.334)\tLoss 0.2794 (0.3226)\tPrec@1 87.500 (88.934)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [6][80/87], lr: 0.00250\tTime 1.010 (4.546)\tData 0.000 (3.507)\tLoss 0.4365 (0.3252)\tPrec@1 81.250 (88.966)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.597 (3.597)\tLoss 0.4626 (0.4626)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 1.00609\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [7][0/87], lr: 0.00250\tTime 49.719 (49.719)\tData 48.602 (48.602)\tLoss 0.2033 (0.2033)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [7][20/87], lr: 0.00250\tTime 1.133 (4.993)\tData 0.000 (3.935)\tLoss 0.0591 (0.2841)\tPrec@1 100.000 (89.881)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [7][40/87], lr: 0.00250\tTime 1.050 (3.844)\tData 0.000 (2.783)\tLoss 0.5462 (0.2477)\tPrec@1 81.250 (90.854)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [7][60/87], lr: 0.00250\tTime 1.057 (3.460)\tData 0.000 (2.396)\tLoss 0.2662 (0.2614)\tPrec@1 87.500 (91.189)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [7][80/87], lr: 0.00250\tTime 1.022 (2.961)\tData 0.000 (1.902)\tLoss 0.3435 (0.2909)\tPrec@1 81.250 (90.432)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.346 (3.346)\tLoss 2.7639 (2.7639)\tPrec@1 50.000 (50.000)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 70.000 Prec@5 100.000 Loss 1.52242\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [8][0/87], lr: 0.00250\tTime 31.160 (31.160)\tData 30.009 (30.009)\tLoss 0.8055 (0.8055)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [8][20/87], lr: 0.00250\tTime 1.064 (3.885)\tData 0.000 (2.822)\tLoss 0.0666 (0.3709)\tPrec@1 100.000 (88.393)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [8][40/87], lr: 0.00250\tTime 1.100 (3.134)\tData 0.000 (2.068)\tLoss 0.1614 (0.3336)\tPrec@1 93.750 (88.720)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [8][60/87], lr: 0.00250\tTime 1.082 (2.988)\tData 0.000 (1.923)\tLoss 0.0307 (0.3310)\tPrec@1 100.000 (88.832)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [8][80/87], lr: 0.00250\tTime 1.020 (2.680)\tData 0.000 (1.622)\tLoss 0.4874 (0.3219)\tPrec@1 75.000 (88.966)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 5.273 (5.273)\tLoss 1.4884 (1.4884)\tPrec@1 56.250 (56.250)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 70.000 Prec@5 100.000 Loss 1.20678\n",
            "Best Prec@1: 77.500\n",
            "\n",
            "Epoch: [9][0/87], lr: 0.00250\tTime 28.814 (28.814)\tData 27.678 (27.678)\tLoss 0.0773 (0.0773)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [9][20/87], lr: 0.00250\tTime 1.017 (3.791)\tData 0.000 (2.727)\tLoss 0.3601 (0.1928)\tPrec@1 87.500 (94.940)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [9][40/87], lr: 0.00250\tTime 1.041 (3.081)\tData 0.000 (2.022)\tLoss 0.0711 (0.2190)\tPrec@1 100.000 (94.055)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [9][60/87], lr: 0.00250\tTime 1.097 (2.892)\tData 0.000 (1.824)\tLoss 0.1972 (0.2132)\tPrec@1 93.750 (93.852)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [9][80/87], lr: 0.00250\tTime 1.039 (2.474)\tData 0.000 (1.404)\tLoss 0.0940 (0.2060)\tPrec@1 93.750 (94.136)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.262 (3.262)\tLoss 0.4303 (0.4303)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 82.500 Prec@5 100.000 Loss 0.62604\n",
            "Best Prec@1: 82.500\n",
            "\n",
            "Epoch: [10][0/87], lr: 0.00250\tTime 37.301 (37.301)\tData 36.184 (36.184)\tLoss 0.0940 (0.0940)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [10][20/87], lr: 0.00250\tTime 1.034 (4.140)\tData 0.000 (3.052)\tLoss 0.0219 (0.1420)\tPrec@1 100.000 (96.429)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [10][40/87], lr: 0.00250\tTime 8.404 (3.043)\tData 7.302 (1.970)\tLoss 0.0397 (0.1846)\tPrec@1 100.000 (94.817)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [10][60/87], lr: 0.00250\tTime 1.018 (2.563)\tData 0.000 (1.496)\tLoss 0.2446 (0.2089)\tPrec@1 87.500 (93.955)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [10][80/87], lr: 0.00250\tTime 1.016 (2.230)\tData 0.000 (1.172)\tLoss 0.0676 (0.2181)\tPrec@1 100.000 (93.441)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 5.982 (5.982)\tLoss 0.8250 (0.8250)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 0.92062\n",
            "Best Prec@1: 82.500\n",
            "\n",
            "Epoch: [11][0/87], lr: 0.00250\tTime 18.975 (18.975)\tData 17.833 (17.833)\tLoss 0.3570 (0.3570)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [11][20/87], lr: 0.00250\tTime 1.017 (2.875)\tData 0.000 (1.783)\tLoss 0.4150 (0.2171)\tPrec@1 87.500 (94.345)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [11][40/87], lr: 0.00250\tTime 1.185 (2.272)\tData 0.000 (1.173)\tLoss 0.1081 (0.2419)\tPrec@1 93.750 (92.683)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [11][60/87], lr: 0.00250\tTime 1.116 (1.954)\tData 0.000 (0.867)\tLoss 0.3008 (0.2657)\tPrec@1 93.750 (91.598)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [11][80/87], lr: 0.00250\tTime 1.034 (1.732)\tData 0.000 (0.657)\tLoss 0.1307 (0.2613)\tPrec@1 93.750 (91.821)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.251 (3.251)\tLoss 0.5237 (0.5237)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 72.500 Prec@5 100.000 Loss 1.23255\n",
            "Best Prec@1: 82.500\n",
            "\n",
            "Epoch: [12][0/87], lr: 0.00250\tTime 24.554 (24.554)\tData 23.416 (23.416)\tLoss 0.0561 (0.0561)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [12][20/87], lr: 0.00250\tTime 1.017 (2.469)\tData 0.000 (1.387)\tLoss 0.1078 (0.2195)\tPrec@1 93.750 (91.667)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [12][40/87], lr: 0.00250\tTime 1.080 (2.076)\tData 0.000 (0.998)\tLoss 0.0682 (0.1909)\tPrec@1 100.000 (93.598)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [12][60/87], lr: 0.00250\tTime 12.057 (2.083)\tData 10.949 (1.007)\tLoss 0.1938 (0.1983)\tPrec@1 93.750 (93.135)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [12][80/87], lr: 0.00250\tTime 1.022 (1.850)\tData 0.000 (0.783)\tLoss 0.4211 (0.1845)\tPrec@1 93.750 (93.519)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.482 (3.482)\tLoss 0.2406 (0.2406)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 80.000 Prec@5 100.000 Loss 0.77295\n",
            "Best Prec@1: 82.500\n",
            "\n",
            "Epoch: [13][0/87], lr: 0.00250\tTime 39.114 (39.114)\tData 38.026 (38.026)\tLoss 0.0429 (0.0429)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [13][20/87], lr: 0.00250\tTime 1.038 (5.335)\tData 0.000 (4.257)\tLoss 0.3000 (0.1896)\tPrec@1 87.500 (94.643)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [13][40/87], lr: 0.00250\tTime 1.147 (4.626)\tData 0.000 (3.544)\tLoss 0.3120 (0.1733)\tPrec@1 87.500 (94.665)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [13][60/87], lr: 0.00250\tTime 1.058 (4.424)\tData 0.000 (3.346)\tLoss 0.1488 (0.1610)\tPrec@1 93.750 (94.980)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [13][80/87], lr: 0.00250\tTime 1.032 (3.839)\tData 0.000 (2.764)\tLoss 0.0668 (0.1895)\tPrec@1 100.000 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.412 (3.412)\tLoss 0.3176 (0.3176)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 85.000 Prec@5 100.000 Loss 0.59868\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [14][0/87], lr: 0.00250\tTime 44.531 (44.531)\tData 43.408 (43.408)\tLoss 0.1443 (0.1443)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [14][20/87], lr: 0.00250\tTime 1.018 (7.436)\tData 0.001 (6.392)\tLoss 0.1163 (0.1400)\tPrec@1 93.750 (95.833)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [14][40/87], lr: 0.00250\tTime 1.004 (5.387)\tData 0.000 (4.343)\tLoss 0.2655 (0.1887)\tPrec@1 93.750 (94.817)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [14][60/87], lr: 0.00250\tTime 1.022 (4.959)\tData 0.000 (3.918)\tLoss 0.2448 (0.1913)\tPrec@1 87.500 (94.570)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [14][80/87], lr: 0.00250\tTime 1.014 (4.404)\tData 0.000 (3.365)\tLoss 0.2486 (0.1837)\tPrec@1 87.500 (94.444)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 5.778 (5.778)\tLoss 1.1976 (1.1976)\tPrec@1 68.750 (68.750)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 72.500 Prec@5 100.000 Loss 0.86418\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [15][0/87], lr: 0.00250\tTime 49.649 (49.649)\tData 48.521 (48.521)\tLoss 0.3273 (0.3273)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [15][20/87], lr: 0.00250\tTime 1.017 (6.981)\tData 0.000 (5.917)\tLoss 0.3623 (0.1810)\tPrec@1 93.750 (93.452)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [15][40/87], lr: 0.00250\tTime 0.998 (7.046)\tData 0.000 (5.991)\tLoss 0.2425 (0.1919)\tPrec@1 93.750 (93.293)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [15][60/87], lr: 0.00250\tTime 1.004 (6.102)\tData 0.000 (5.057)\tLoss 0.0738 (0.1907)\tPrec@1 93.750 (93.033)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [15][80/87], lr: 0.00250\tTime 1.003 (5.157)\tData 0.000 (4.116)\tLoss 0.0365 (0.1771)\tPrec@1 100.000 (93.441)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.080 (3.080)\tLoss 0.6775 (0.6775)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 72.500 Prec@5 100.000 Loss 0.86084\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [16][0/87], lr: 0.00250\tTime 72.159 (72.159)\tData 71.042 (71.042)\tLoss 0.0527 (0.0527)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [16][20/87], lr: 0.00250\tTime 1.004 (6.637)\tData 0.000 (5.602)\tLoss 0.0696 (0.1536)\tPrec@1 93.750 (93.452)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [16][40/87], lr: 0.00250\tTime 1.034 (5.519)\tData 0.000 (4.490)\tLoss 0.0185 (0.1472)\tPrec@1 100.000 (94.817)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [16][60/87], lr: 0.00250\tTime 1.027 (4.194)\tData 0.000 (3.167)\tLoss 0.1922 (0.1481)\tPrec@1 93.750 (94.672)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [16][80/87], lr: 0.00250\tTime 1.001 (3.635)\tData 0.000 (2.609)\tLoss 0.2088 (0.1475)\tPrec@1 93.750 (94.753)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 5.777 (5.777)\tLoss 1.9105 (1.9105)\tPrec@1 62.500 (62.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 67.500 Prec@5 100.000 Loss 1.21695\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [17][0/87], lr: 0.00250\tTime 40.191 (40.191)\tData 39.056 (39.056)\tLoss 0.0163 (0.0163)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][20/87], lr: 0.00250\tTime 1.033 (4.134)\tData 0.000 (3.080)\tLoss 0.2340 (0.1384)\tPrec@1 87.500 (95.238)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][40/87], lr: 0.00250\tTime 1.048 (3.183)\tData 0.000 (2.128)\tLoss 0.0745 (0.1436)\tPrec@1 93.750 (94.817)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][60/87], lr: 0.00250\tTime 1.103 (2.874)\tData 0.000 (1.815)\tLoss 0.0558 (0.1257)\tPrec@1 100.000 (95.389)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [17][80/87], lr: 0.00250\tTime 1.053 (2.500)\tData 0.000 (1.443)\tLoss 0.0145 (0.1223)\tPrec@1 100.000 (95.525)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.442 (3.442)\tLoss 1.5265 (1.5265)\tPrec@1 62.500 (62.500)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 1.04680\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [18][0/87], lr: 0.00250\tTime 27.999 (27.999)\tData 26.857 (26.857)\tLoss 0.2091 (0.2091)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][20/87], lr: 0.00250\tTime 1.013 (3.895)\tData 0.000 (2.846)\tLoss 0.5618 (0.1274)\tPrec@1 81.250 (96.131)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][40/87], lr: 0.00250\tTime 1.003 (2.729)\tData 0.000 (1.682)\tLoss 0.0536 (0.1013)\tPrec@1 100.000 (96.951)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][60/87], lr: 0.00250\tTime 1.058 (2.450)\tData 0.000 (1.400)\tLoss 0.0636 (0.0989)\tPrec@1 100.000 (96.824)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [18][80/87], lr: 0.00250\tTime 1.015 (2.160)\tData 0.000 (1.111)\tLoss 0.0077 (0.1197)\tPrec@1 100.000 (96.219)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 4.037 (4.037)\tLoss 1.7673 (1.7673)\tPrec@1 68.750 (68.750)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 70.000 Prec@5 100.000 Loss 1.35383\n",
            "Best Prec@1: 85.000\n",
            "\n",
            "Epoch: [19][0/87], lr: 0.00250\tTime 24.650 (24.650)\tData 23.350 (23.350)\tLoss 0.0267 (0.0267)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [19][20/87], lr: 0.00250\tTime 1.075 (2.695)\tData 0.000 (1.601)\tLoss 0.0685 (0.1374)\tPrec@1 93.750 (94.643)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [19][40/87], lr: 0.00250\tTime 1.056 (2.185)\tData 0.000 (1.104)\tLoss 1.5737 (0.1887)\tPrec@1 81.250 (94.360)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [19][60/87], lr: 0.00250\tTime 1.043 (1.967)\tData 0.000 (0.892)\tLoss 0.2198 (0.1775)\tPrec@1 93.750 (94.775)\tPrec@5 100.000 (100.000)\n",
            "Epoch: [19][80/87], lr: 0.00250\tTime 1.016 (1.805)\tData 0.000 (0.736)\tLoss 0.0643 (0.1723)\tPrec@1 93.750 (94.676)\tPrec@5 100.000 (100.000)\n",
            "Test: [0/3]\tTime 3.559 (3.559)\tLoss 1.9800 (1.9800)\tPrec@1 68.750 (68.750)\tPrec@5 100.000 (100.000)\n",
            "Testing Results: Prec@1 75.000 Prec@5 100.000 Loss 1.24703\n",
            "Best Prec@1: 85.000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMsy3zHNA6z0",
        "outputId": "e881afe7-a7eb-4682-8008-c4dc918812cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "import time\n",
        "\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    res = []\n",
        "    for k in topk:\n",
        "         correct_k = correct[:k].view(-1).float().sum(0)\n",
        "         res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "def parse_shift_option_from_log_name(log_name):\n",
        "    if 'shift' in log_name:\n",
        "        strings = log_name.split('_')\n",
        "        for i, s in enumerate(strings):\n",
        "            if 'shift' in s:\n",
        "                break\n",
        "        return True, int(strings[i].replace('shift', '')), strings[i + 1]\n",
        "    else:\n",
        "        return False, None, None\n",
        "\n",
        "weights='checkpoint/TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e20/ckpt.pth.tar'\n",
        "weights_list = weights.split(',')\n",
        "test_segments_list = [int(s) for s in '8'.split(',')]\n",
        "assert len(weights_list) == len(test_segments_list)\n",
        "if None is None:\n",
        "    coeff_list = [1] * len(weights_list)\n",
        "else:\n",
        "    coeff_list = [float(c) for c in None.split(',')]\n",
        "\n",
        "if None is not None:\n",
        "    test_file_list = None.split(',')\n",
        "else:\n",
        "    test_file_list = [None] * len(weights_list)\n",
        "\n",
        "\n",
        "data_iter_list = []\n",
        "net_list = []\n",
        "modality_list = []\n",
        "\n",
        "total_num = None\n",
        "for this_weights, this_test_segments, test_file in zip(weights_list, test_segments_list, test_file_list):\n",
        "    is_shift, shift_div, shift_place = parse_shift_option_from_log_name(this_weights)\n",
        "    if 'RGB' in this_weights:\n",
        "        modality = 'RGB'\n",
        "    else:\n",
        "        modality = 'Flow'\n",
        "    this_arch = this_weights.split('TSM_')[1].split('_')[2]\n",
        "    modality_list.append(modality)\n",
        "    num_class, train_list, val_list, root_path, prefix = return_dataset('kinetics', modality)\n",
        "    print('=> shift: {}, shift_div: {}, shift_place: {}'.format(is_shift, shift_div, shift_place))\n",
        "    net = TSN(num_class, this_test_segments if is_shift else 1, modality,\n",
        "              base_model=this_arch,\n",
        "              consensus_type='avg',\n",
        "              img_feature_dim=256,\n",
        "              pretrain='imagenet',\n",
        "              is_shift=is_shift, shift_div=shift_div, shift_place=shift_place,\n",
        "              non_local='_nl' in this_weights,\n",
        "              )\n",
        "\n",
        "    if 'tpool' in this_weights:\n",
        "        make_temporal_pool(net.base_model, this_test_segments)  # since DataParallel\n",
        "\n",
        "    checkpoint = torch.load(this_weights)\n",
        "    checkpoint = checkpoint['state_dict']\n",
        "\n",
        "    # base_dict = {('base_model.' + k).replace('base_model.fc', 'new_fc'): v for k, v in list(checkpoint.items())}\n",
        "    base_dict = {'.'.join(k.split('.')[1:]): v for k, v in list(checkpoint.items())}\n",
        "    replace_dict = {'base_model.classifier.weight': 'new_fc.weight',\n",
        "                    'base_model.classifier.bias': 'new_fc.bias',\n",
        "                    }\n",
        "    for k, v in replace_dict.items():\n",
        "        if k in base_dict:\n",
        "            base_dict[v] = base_dict.pop(k)\n",
        "\n",
        "    net.load_state_dict(base_dict)\n",
        "\n",
        "    input_size = net.scale_size if False else net.input_size\n",
        "    if 1 == 1:\n",
        "        cropping = torchvision.transforms.Compose([\n",
        "            GroupScale(net.scale_size),\n",
        "            GroupCenterCrop(input_size),\n",
        "        ])\n",
        "    elif 1 == 3:  # do not flip, so only 5 crops\n",
        "        cropping = torchvision.transforms.Compose([\n",
        "            GroupFullResSample(input_size, net.scale_size, flip=False)\n",
        "        ])\n",
        "    elif 1 == 5:  # do not flip, so only 5 crops\n",
        "        cropping = torchvision.transforms.Compose([\n",
        "            GroupOverSample(input_size, net.scale_size, flip=False)\n",
        "        ])\n",
        "    elif 1 == 10:\n",
        "        cropping = torchvision.transforms.Compose([\n",
        "            GroupOverSample(input_size, net.scale_size)\n",
        "        ])\n",
        "    else:\n",
        "        raise ValueError(\"Only 1, 5, 10 crops are supported while we got {}\".format(1))\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "            TSNDataSet(root_path, test_file if test_file is not None else val_list, num_segments=this_test_segments,\n",
        "                       new_length=1 if modality == \"RGB\" else 5,\n",
        "                       modality=modality,\n",
        "                       image_tmpl=prefix,\n",
        "                       test_mode=True,\n",
        "                       remove_missing=len(weights_list) == 1,\n",
        "                       transform=torchvision.transforms.Compose([\n",
        "                           cropping,\n",
        "                           Stack(roll=(this_arch in ['BNInception', 'InceptionV3'])),\n",
        "                           ToTorchFormatTensor(div=(this_arch not in ['BNInception', 'InceptionV3'])),\n",
        "                           GroupNormalize(net.input_mean, net.input_std),\n",
        "                       ]), dense_sample=False, twice_sample=False),\n",
        "            batch_size=16, shuffle=False,\n",
        "            num_workers=8, pin_memory=True,\n",
        "    )\n",
        "\n",
        "    if None is not None:\n",
        "        devices = [None[i] for i in range(8)]\n",
        "    else:\n",
        "        devices = list(range(8))\n",
        "\n",
        "    net = torch.nn.DataParallel(net.cuda())\n",
        "    net.eval()\n",
        "\n",
        "    data_gen = enumerate(data_loader)\n",
        "\n",
        "    if total_num is None:\n",
        "        total_num = len(data_loader.dataset)\n",
        "    else:\n",
        "        assert total_num == len(data_loader.dataset)\n",
        "\n",
        "    data_iter_list.append(data_gen)\n",
        "    net_list.append(net)\n",
        "\n",
        "\n",
        "output = []\n",
        "\n",
        "\n",
        "def eval_video(video_data, net, this_test_segments, modality):\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        i, data, label = video_data\n",
        "        batch_size = label.numel()\n",
        "        num_crop = 1\n",
        "        if False:\n",
        "            num_crop *= 10  # 10 clips for testing when using dense sample\n",
        "\n",
        "        if False:\n",
        "            num_crop *= 2\n",
        "\n",
        "        if modality == 'RGB':\n",
        "            length = 3\n",
        "        elif modality == 'Flow':\n",
        "            length = 10\n",
        "        elif modality == 'RGBDiff':\n",
        "            length = 18\n",
        "        else:\n",
        "            raise ValueError(\"Unknown modality \"+ modality)\n",
        "\n",
        "        data_in = data.view(-1, length, data.size(2), data.size(3))\n",
        "        if is_shift:\n",
        "            data_in = data_in.view(batch_size * num_crop, this_test_segments, length, data_in.size(2), data_in.size(3))\n",
        "        rst = net(data_in)\n",
        "        rst = rst.reshape(batch_size, num_crop, -1).mean(1)\n",
        "\n",
        "        if False:\n",
        "            # take the softmax to normalize the output to probability\n",
        "            rst = F.softmax(rst, dim=1)\n",
        "\n",
        "        rst = rst.data.cpu().numpy().copy()\n",
        "\n",
        "        if net.module.is_shift:\n",
        "            rst = rst.reshape(batch_size, num_class)\n",
        "        else:\n",
        "            rst = rst.reshape((batch_size, -1, num_class)).mean(axis=1).reshape((batch_size, num_class))\n",
        "\n",
        "        return i, rst, label\n",
        "\n",
        "\n",
        "proc_start_time = time.time()\n",
        "max_num = -1 if -1 > 0 else total_num\n",
        "\n",
        "top1 = AverageMeter()\n",
        "top5 = AverageMeter()\n",
        "\n",
        "for i, data_label_pairs in enumerate(zip(*data_iter_list)):\n",
        "    with torch.no_grad():\n",
        "        if i >= max_num:\n",
        "            break\n",
        "        this_rst_list = []\n",
        "        this_label = None\n",
        "        for n_seg, (_, (data, label)), net, modality in zip(test_segments_list, data_label_pairs, net_list, modality_list):\n",
        "            rst = eval_video((i, data, label), net, n_seg, modality)\n",
        "            this_rst_list.append(rst[1])\n",
        "            this_label = label\n",
        "        assert len(this_rst_list) == len(coeff_list)\n",
        "        for i_coeff in range(len(this_rst_list)):\n",
        "            this_rst_list[i_coeff] *= coeff_list[i_coeff]\n",
        "        ensembled_predict = sum(this_rst_list) / len(this_rst_list)\n",
        "\n",
        "        for p, g in zip(ensembled_predict, this_label.cpu().numpy()):\n",
        "            output.append([p[None, ...], g])\n",
        "        cnt_time = time.time() - proc_start_time\n",
        "        prec1, prec5 = accuracy(torch.from_numpy(ensembled_predict), this_label, topk=(1, 5))\n",
        "        top1.update(prec1.item(), this_label.numel())\n",
        "        top5.update(prec5.item(), this_label.numel())\n",
        "        if i % 20 == 0:\n",
        "            print('video {} done, total {}/{}, average {:.3f} sec/video, '\n",
        "                  'moving Prec@1 {:.3f} Prec@5 {:.3f}'.format(i * 16, i * 16, total_num,\n",
        "                                                              float(cnt_time) / (i+1) / 16, top1.avg, top5.avg))\n",
        "\n",
        "video_pred = [np.argmax(x[0]) for x in output]\n",
        "video_pred_top5 = [np.argsort(np.mean(x[0], axis=0).reshape(-1))[::-1][:5] for x in output]\n",
        "\n",
        "video_labels = [x[1] for x in output]\n",
        "\n",
        "if 'result.csv' is not None:\n",
        "    print('=> Writing result to csv file: {}'.format('result.csv'))\n",
        "    categories=['cake_cutting','blowing_candles','hugging','laughing','screaming']\n",
        "    categories = [f.strip() for f in categories]\n",
        "    with open('labels/val_videofolder.txt') as f:\n",
        "        vid_names = f.readlines()\n",
        "    vid_names = [n.split(' ')[0] for n in vid_names]\n",
        "    assert len(vid_names) == len(video_pred)\n",
        "    if 'kinetics' != 'somethingv2':  # only output top1\n",
        "        with open('result.csv', 'w') as f:\n",
        "            for n, pred in zip(vid_names, video_pred):\n",
        "                f.write('{};{}\\n'.format(n, categories[pred]))\n",
        "    else:\n",
        "        with open('result.csv', 'w') as f:\n",
        "            for n, pred5 in zip(vid_names, video_pred_top5):\n",
        "                fill = [n]\n",
        "                for p in list(pred5):\n",
        "                    fill.append(p)\n",
        "                f.write('{};{};{};{};{};{}\\n'.format(*fill))\n",
        "\n",
        "\n",
        "cf = confusion_matrix(video_labels, video_pred).astype(float)\n",
        "\n",
        "np.save('cm.npy', cf)\n",
        "cls_cnt = cf.sum(axis=1)\n",
        "cls_hit = np.diag(cf)\n",
        "\n",
        "cls_acc = cls_hit / cls_cnt\n",
        "print(cls_acc)\n",
        "upper = np.mean(np.max(cf, axis=1) / cls_cnt)\n",
        "print('upper bound: {}'.format(upper))\n",
        "\n",
        "print('-----Evaluation is finished------')\n",
        "print('Class Accuracy {:.02f}%'.format(np.mean(cls_acc) * 100))\n",
        "print('Overall Prec@1 {:.02f}% Prec@5 {:.02f}%'.format(top1.avg, top5.avg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kinetics: 5 classes\n",
            "=> shift: True, shift_div: 8, shift_place: blockres\n",
            "\n",
            "    Initializing TSN with base model: mobilenetv2.\n",
            "    TSN Configurations:\n",
            "        input_modality:     RGB\n",
            "        num_segments:       8\n",
            "        new_length:         1\n",
            "        consensus_module:   avg\n",
            "        dropout_ratio:      0.8\n",
            "        img_feature_dim:    256\n",
            "            \n",
            "=> base model: mobilenetv2\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "Adding temporal shift... True\n",
            "=> Using fold div: 8\n",
            "video number:40\n",
            "video 0 done, total 0/40, average 0.182 sec/video, moving Prec@1 68.750 Prec@5 100.000\n",
            "=> Writing result to csv file: result.csv\n",
            "[0.9        0.9        0.42857143 0.85714286 0.5       ]\n",
            "upper bound: 0.7171428571428572\n",
            "-----Evaluation is finished------\n",
            "Class Accuracy 71.71%\n",
            "Overall Prec@1 75.00% Prec@5 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}